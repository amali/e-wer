{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#load lib\n",
    "import numpy as np\n",
    "import re, sys, glob\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from keras.preprocessing import text\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk import ngrams\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.models import load_model\n",
    "import math\n",
    "import scipy\n",
    "_EPOCHS=50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "\n",
    "'''\n",
    "Features order in the data look like this \n",
    "print STDOUT \"S:\".$uttranceInfo{\"id\"}.\"\\t\".$wordcount.\" \".$graphemecount.\" \".$uttranceInfo{\"total_frames\"}.\n",
    "      \" \".$uttranceInfo{\"avg_loglike\"}.\" \".$uttranceInfo{\"total_AMloglike\"}.\" \".\n",
    "\t  $uttranceInfo{\"total_LMloglike\"}.\" \".$uttranceInfo{\"duration\"}.\" \".\n",
    "\t  $uttranceInfo{\"GER\"}.\"\\t\".$uttranceInfo{\"sentence\"}.\"\\t\".$uttranceInfo{\"grapheme\"}.\n",
    "\t  \"\\t\".$uttranceInfo{\"WER\"}.\"\\n\";\n",
    "'''\n",
    "\n",
    "test1=\"data/dev.mgb2/wer.feats\"\n",
    "train=\"data/eval.mgb2/wer.feats\"\n",
    "test2=\"data/summa_test20170317/wer.feats\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file (file,type='glass'):\n",
    "    f=open(file,\"r\")\n",
    "    lines=f.readlines()\n",
    "    _id=[]\n",
    "    _text=[]\n",
    "    _numerical=[]\n",
    "    _char=[]\n",
    "    _ref=[]\n",
    "    for x in lines:\n",
    "        _id.append(x.split('\\t')[0])\n",
    "        _text.append(x.split('\\t')[2])\n",
    "        _char.append(x.split('\\t')[3])\n",
    "        _ref.append(x.split('\\t')[4])\n",
    "        if type == 'glass': \n",
    "            _numerical.append(x.split('\\t')[1])\n",
    "        else:\n",
    "            blac_box_numerical=x.split('\\t')[1].split(' ')\n",
    "            numerical2=' '.join(blac_box_numerical[0:2]+blac_box_numerical[6:])\n",
    "            _numerical.append(numerical2)\n",
    "        \n",
    "    f.close()\n",
    "    return _id, _numerical, _text, _char, _ref\n",
    "\n",
    "def word_grams(words, min=1, max=4):\n",
    "    s = []\n",
    "    for n in range(min, max):\n",
    "        for ngram in ngrams(words, n):\n",
    "            s.append(' '.join(str(i) for i in ngram))\n",
    "    return s\n",
    "\n",
    "def return_word_char_list (_text,_char):\n",
    "    _unigram_word_list = [] \n",
    "    _trigram_char_list = []\n",
    "    for i,j in enumerate(_char):\n",
    "        \n",
    "        _char_3gram = word_grams (_char[i].split(),1,3)\n",
    "        for tri in _char_3gram: \n",
    "             if tri not in _trigram_char_list: _trigram_char_list.append(tri)\n",
    "    \n",
    "        _words_1gram = word_grams (_text[i].split(),1,2)\n",
    "        for uni in _words_1gram: \n",
    "             if uni not in _unigram_word_list: _unigram_word_list.append(uni)\n",
    "    return _unigram_word_list, _trigram_char_list \n",
    "                    \n",
    "def vectorize (words,chars,word_list,char_list):\n",
    "    feature_vector = []\n",
    "    index=0\n",
    "    \n",
    "    temp_words = [0] * len(word_list)\n",
    "    for word in word_grams (words.split(),1,2): \n",
    "        for index, word2 in enumerate(word_list): \n",
    "            if word == word2:\n",
    "                #print (index, word2)\n",
    "                temp_words[index]+=1\n",
    "                break\n",
    "    \n",
    "    temp_chars = [0] * len(char_list)\n",
    "    for _char in word_grams (chars.split(),1,3): \n",
    "        for index, _char2 in enumerate(char_list): \n",
    "            if _char == _char2:\n",
    "                #print (index, _char2)\n",
    "                temp_chars[index]+=1\n",
    "                break            \n",
    "    return temp_words+temp_chars\n",
    "\n",
    "def make_features (numerical, text, char, word_list, char_list ):\n",
    "    allfeats= []\n",
    "    for i, _id in enumerate (text):\n",
    "        feat = vectorize (text[i],char[i],word_list,char_list)\n",
    "        allfeats.append (numerical[i].split()+feat)\n",
    "        if i % 1000 == 0: print (\"Processing: \", i)\n",
    "    nn=np.array(allfeats)\n",
    "    #nn_minmax = preprocessing.scale(nn)\n",
    "       \n",
    "    print (nn.shape)\n",
    "    return (nn)\n",
    "    \n",
    "def get_wc_err (file,dump):\n",
    "    print (\"Processing: \", file)\n",
    "    f=open(file,\"r\")\n",
    "    lines=f.readlines()\n",
    "    _wc=[]\n",
    "    _err=[]\n",
    "    _real_wc =[]\n",
    "    _real_err =[]\n",
    "    for x in lines:\n",
    "        err = int(x.split('\\t')[4].split(' ')[1])\n",
    "        wc  = int(x.split('\\t')[4].split(' ')[2])\n",
    "        _real_wc.append (wc)    \n",
    "        _real_err.append (err)\n",
    "        \n",
    "        if wc > 20: wc =20\n",
    "        if err > 20: err =20\n",
    "        wc = wc - 1 # for whatever reason keras like to start counting from zer\n",
    "        \n",
    "        _wc.append (wc)    \n",
    "        _err.append (err)\n",
    "    \n",
    "    unique, counts = np.unique(_wc, return_counts=True)\n",
    "    print (\"wc:unique: \",unique)\n",
    "    print (\"wc:counts: \",counts)\n",
    "    \n",
    "    unique, counts = np.unique(_err, return_counts=True)\n",
    "    print (\"err:unique: \",unique)\n",
    "    print (\"err:counts: \",counts)\n",
    "    \n",
    "    one_hot_labels_wc = to_categorical(np.array(_wc), num_classes=20)\n",
    "    one_hot_labels_err = to_categorical(np.array(_err), num_classes=21)\n",
    "        \n",
    "    np.savetxt(dump+'.err', np.array(_real_err), fmt='%d')\n",
    "    np.savetxt(dump+'.wc', np.array(_real_wc), fmt='%d')\n",
    "    \n",
    "    print (one_hot_labels_wc.shape,one_hot_labels_err.shape)\n",
    "    return one_hot_labels_wc, one_hot_labels_err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "    \n",
    "\n",
    "def report (test_vec,test_labels,test,ext):\n",
    "    \n",
    "    prob_out='prob.out.'+test+'.'+ext\n",
    "    pred_out='pred.out.'+test+'.'+ext\n",
    "    class_out='class.out.'+test+'.'+ext\n",
    "    \n",
    "    _shift=0\n",
    "    if ext == \"wc\" : _shift=2\n",
    "    #load models\n",
    "    model = load_model('./my_model.h5')\n",
    "    \n",
    "    #save predictions\n",
    "    pred = model.predict(test_vec)\n",
    "    np.savetxt(pred_out, pred, delimiter=' ')    \n",
    "    \n",
    "    prob = np.copy(pred)\n",
    "    i=0\n",
    "    for row in prob: \n",
    "      raw = [sigmoid(i) for i in row]\n",
    "      norm = [float(i)/sum(raw) for i in raw]\n",
    "      prob[int(i)]=norm\n",
    "      i=i+1\n",
    "    \n",
    "    #save prob\n",
    "    np.savetxt(prob_out, prob, delimiter=' ',fmt='%f') \n",
    "    \n",
    "    \n",
    "    test_classes = np.argmax(prob, axis=1)+_shift\n",
    "    #save classes\n",
    "    np.savetxt(class_out, test_classes, delimiter=' ',fmt='%d')\n",
    "    \n",
    "\n",
    "    test_labels = np.argmax(test_labels, axis=1) # to remove the Keras to_categorical\n",
    "    \n",
    "    \n",
    "\n",
    "    #print confusion matrix \n",
    "    confusion_matrix(test_labels, test_classes)\n",
    "\n",
    "    #print classification report\n",
    "    print(classification_report(test_labels, test_classes))\n",
    "\n",
    "\n",
    "    #print prec, recall and f1\n",
    "    print (\"Precision:\\t{:0.3f}\".format(precision_score(test_labels, test_classes,average='weighted')))\n",
    "    print (\"Recall:  \\t{:0.3f}\".format(recall_score(test_labels, test_classes,average='weighted')))\n",
    "    print (\"F1 Score:\\t{:0.3f}\".format(f1_score(test_labels, test_classes,average='weighted')))\n",
    "    print (\"Accuracy:\\t{:0.3f}\".format(accuracy_score(test_labels, test_classes)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature dimension:  15372\n",
      "Processing:  0\n",
      "Processing:  1000\n",
      "Processing:  2000\n",
      "Processing:  3000\n",
      "Processing:  4000\n",
      "Processing:  5000\n",
      "(5655, 15372)\n",
      "Processing:  data/eval.mgb2/wer.feats\n",
      "wc:unique:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "wc:counts:  [  1   9  21  76 128 219 305 413 462 509 519 509 481 435 363 328 235 185\n",
      " 125 332]\n",
      "err:unique:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "err:counts:  [619 886 868 800 588 498 358 217 208 160 106  89  60  39  31  29  18  17\n",
      "  14   7  43]\n",
      "(5655, 20) (5655, 21)\n",
      "Processing:  0\n",
      "Processing:  1000\n",
      "Processing:  2000\n",
      "Processing:  3000\n",
      "Processing:  4000\n",
      "Processing:  5000\n",
      "(5842, 15372)\n",
      "Processing:  data/dev.mgb2/wer.feats\n",
      "wc:unique:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "wc:counts:  [  2   7  33 101 166 237 326 372 459 455 446 454 429 390 362 283 290 228\n",
      " 184 618]\n",
      "err:unique:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "err:counts:  [661 776 740 612 565 438 333 265 228 193 127 138 123  90  77  70  73  50\n",
      "  43  34 206]\n",
      "(5842, 20) (5842, 21)\n",
      "Processing:  0\n",
      "Processing:  1000\n",
      "(1410, 15372)\n",
      "Processing:  data/summa_test20170317/wer.feats\n",
      "wc:unique:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "wc:counts:  [  1   2   6   5  16  18  34  52  65  87 105 115 140 135 116  97  95  74\n",
      "  65 182]\n",
      "err:unique:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "err:counts:  [200 256 228 197 136  88  51  41  35  23  24  18  14   7  16  10  13   9\n",
      "   8   7  29]\n",
      "(1410, 20) (1410, 21)\n"
     ]
    }
   ],
   "source": [
    "id, numerical, text, char, ref =load_file (train,'glass')\n",
    "\n",
    "word_list, char_list = return_word_char_list (text, char)\n",
    "numerical_len=len(numerical[0].split())\n",
    "\n",
    "feat_len=(len(word_list+char_list)+numerical_len)\n",
    "print (\"Feature dimension: \", feat_len)\n",
    "\n",
    "\n",
    "\n",
    "train_feats = make_features (numerical, text, char, word_list, char_list )\n",
    "train_wc, train_err = get_wc_err (train,'train')\n",
    "\n",
    "\n",
    "\n",
    "id, numerical, text, char, ref =load_file (test1,'glass')\n",
    "test1_feats = make_features (numerical, text, char, word_list, char_list )\n",
    "test1_wc, test1_err = get_wc_err (test1,'test1')\n",
    "\n",
    "\n",
    "id, numerical, text, char, ref =load_file (test2,'glass')\n",
    "test2_feats = make_features (numerical, text, char, word_list, char_list )\n",
    "test2_wc, test2_err = get_wc_err (test2,'test2')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5655/5655 [==============================] - 57s - loss: 3.0608 - acc: 0.0914    \n",
      "Epoch 2/50\n",
      "5655/5655 [==============================] - 46s - loss: 2.4913 - acc: 0.1521    \n",
      "Epoch 3/50\n",
      "5655/5655 [==============================] - 41s - loss: 2.3114 - acc: 0.1813    \n",
      "Epoch 4/50\n",
      "5655/5655 [==============================] - 44s - loss: 2.2050 - acc: 0.1952    \n",
      "Epoch 5/50\n",
      "5655/5655 [==============================] - 42s - loss: 2.1307 - acc: 0.2074    \n",
      "Epoch 6/50\n",
      "5655/5655 [==============================] - 41s - loss: 2.0725 - acc: 0.2278    \n",
      "Epoch 7/50\n",
      "5655/5655 [==============================] - 42s - loss: 2.0198 - acc: 0.2329    \n",
      "Epoch 8/50\n",
      "5655/5655 [==============================] - 44s - loss: 1.9482 - acc: 0.2543    \n",
      "Epoch 9/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.9193 - acc: 0.2508    \n",
      "Epoch 10/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.9090 - acc: 0.2553    \n",
      "Epoch 11/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.8685 - acc: 0.2626    \n",
      "Epoch 12/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.8242 - acc: 0.2789    \n",
      "Epoch 13/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.7981 - acc: 0.2905    \n",
      "Epoch 14/50\n",
      "5655/5655 [==============================] - 43s - loss: 1.7722 - acc: 0.2934    \n",
      "Epoch 15/50\n",
      "5655/5655 [==============================] - 44s - loss: 1.7667 - acc: 0.2997    \n",
      "Epoch 16/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.7369 - acc: 0.3146    \n",
      "Epoch 17/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.7106 - acc: 0.3247    \n",
      "Epoch 18/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.6998 - acc: 0.3247    \n",
      "Epoch 19/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.6973 - acc: 0.3277    \n",
      "Epoch 20/50\n",
      "5655/5655 [==============================] - 42s - loss: 1.6655 - acc: 0.3316    \n",
      "Epoch 21/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.6591 - acc: 0.3438    \n",
      "Epoch 22/50\n",
      "5655/5655 [==============================] - 42s - loss: 1.6499 - acc: 0.3524    \n",
      "Epoch 23/50\n",
      "5655/5655 [==============================] - 42s - loss: 1.6368 - acc: 0.3498    \n",
      "Epoch 24/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.6219 - acc: 0.3652    \n",
      "Epoch 25/50\n",
      "5655/5655 [==============================] - 42s - loss: 1.6110 - acc: 0.3623    \n",
      "Epoch 26/50\n",
      "5655/5655 [==============================] - 42s - loss: 1.5837 - acc: 0.3696    \n",
      "Epoch 27/50\n",
      "5655/5655 [==============================] - 42s - loss: 1.5774 - acc: 0.3818    \n",
      "Epoch 28/50\n",
      "5655/5655 [==============================] - 42s - loss: 1.5562 - acc: 0.3867    \n",
      "Epoch 29/50\n",
      "5655/5655 [==============================] - 42s - loss: 1.5450 - acc: 0.3926    \n",
      "Epoch 30/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.5211 - acc: 0.4095    \n",
      "Epoch 31/50\n",
      "5655/5655 [==============================] - 44s - loss: 1.5495 - acc: 0.3956    \n",
      "Epoch 32/50\n",
      "5655/5655 [==============================] - 43s - loss: 1.5023 - acc: 0.4088    \n",
      "Epoch 33/50\n",
      "5655/5655 [==============================] - 42s - loss: 1.5060 - acc: 0.4016    \n",
      "Epoch 34/50\n",
      "5655/5655 [==============================] - 42s - loss: 1.4888 - acc: 0.4149    \n",
      "Epoch 35/50\n",
      "5655/5655 [==============================] - 42s - loss: 1.4827 - acc: 0.4145    \n",
      "Epoch 36/50\n",
      "5655/5655 [==============================] - 42s - loss: 1.4775 - acc: 0.4196    \n",
      "Epoch 37/50\n",
      "5655/5655 [==============================] - 42s - loss: 1.4467 - acc: 0.4276    \n",
      "Epoch 38/50\n",
      "5655/5655 [==============================] - 42s - loss: 1.4317 - acc: 0.4385    \n",
      "Epoch 39/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.4448 - acc: 0.4336    \n",
      "Epoch 40/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.4276 - acc: 0.4437    \n",
      "Epoch 41/50\n",
      "5655/5655 [==============================] - 46s - loss: 1.4158 - acc: 0.4479    \n",
      "Epoch 42/50\n",
      "5655/5655 [==============================] - 43s - loss: 1.3931 - acc: 0.4562    \n",
      "Epoch 43/50\n",
      "5655/5655 [==============================] - 42s - loss: 1.3916 - acc: 0.4564    \n",
      "Epoch 44/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.3640 - acc: 0.4630    \n",
      "Epoch 45/50\n",
      "5655/5655 [==============================] - 43s - loss: 1.3708 - acc: 0.4727    \n",
      "Epoch 46/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.3506 - acc: 0.4844    \n",
      "Epoch 47/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.3312 - acc: 0.4872    \n",
      "Epoch 48/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.3165 - acc: 0.4900    \n",
      "Epoch 49/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.3445 - acc: 0.4916    \n",
      "Epoch 50/50\n",
      "5655/5655 [==============================] - 42s - loss: 1.3156 - acc: 0.4996    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         2\n",
      "          1       0.00      0.00      0.00         7\n",
      "          2       0.00      0.00      0.00        33\n",
      "          3       0.00      0.00      0.00       101\n",
      "          4       0.20      0.02      0.04       166\n",
      "          5       0.06      0.01      0.01       237\n",
      "          6       0.10      0.09      0.09       326\n",
      "          7       0.12      0.04      0.06       372\n",
      "          8       0.09      0.09      0.09       459\n",
      "          9       0.12      0.10      0.11       455\n",
      "         10       0.12      0.12      0.12       446\n",
      "         11       0.15      0.17      0.16       454\n",
      "         12       0.13      0.15      0.14       429\n",
      "         13       0.13      0.12      0.12       390\n",
      "         14       0.13      0.23      0.17       362\n",
      "         15       0.18      0.32      0.23       283\n",
      "         16       0.18      0.19      0.18       290\n",
      "         17       0.21      0.27      0.24       228\n",
      "         18       0.21      0.15      0.18       184\n",
      "         19       0.39      0.01      0.03       618\n",
      "         20       0.00      0.00      0.00         0\n",
      "         21       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.16      0.12      0.12      5842\n",
      "\n",
      "Precision:\t0.158\n",
      "Recall:  \t0.121\n",
      "F1 Score:\t0.115\n",
      "Accuracy:\t0.121\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         1\n",
      "          1       0.00      0.00      0.00         2\n",
      "          2       0.00      0.00      0.00         6\n",
      "          3       0.00      0.00      0.00         5\n",
      "          4       0.22      0.12      0.16        16\n",
      "          5       0.00      0.00      0.00        18\n",
      "          6       0.22      0.18      0.20        34\n",
      "          7       0.10      0.02      0.03        52\n",
      "          8       0.13      0.09      0.11        65\n",
      "          9       0.12      0.08      0.10        87\n",
      "         10       0.15      0.07      0.09       105\n",
      "         11       0.21      0.26      0.23       115\n",
      "         12       0.15      0.11      0.13       140\n",
      "         13       0.20      0.15      0.17       135\n",
      "         14       0.17      0.34      0.23       116\n",
      "         15       0.18      0.29      0.22        97\n",
      "         16       0.20      0.31      0.24        95\n",
      "         17       0.24      0.30      0.27        74\n",
      "         18       0.19      0.14      0.16        65\n",
      "         19       0.20      0.01      0.02       182\n",
      "         20       0.00      0.00      0.00         0\n",
      "         21       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.17      0.16      0.15      1410\n",
      "\n",
      "Precision:\t0.175\n",
      "Recall:  \t0.160\n",
      "F1 Score:\t0.148\n",
      "Accuracy:\t0.160\n"
     ]
    }
   ],
   "source": [
    "#def dnn (feats,labels):\n",
    "#estimate glass-box word count (make sure to add one to your estimation)\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_dim=feat_len))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(20, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_feats,train_wc, epochs=_EPOCHS,batch_size=32)\n",
    "model.save('./my_model.h5', overwrite=True)\n",
    "\n",
    "report (test1_feats,test1_wc,'test1.glass','wc')\n",
    "report (test2_feats,test2_wc,'test2.glass','wc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5655/5655 [==============================] - 57s - loss: 2.8650 - acc: 0.1330    \n",
      "Epoch 2/50\n",
      "5655/5655 [==============================] - 45s - loss: 2.3347 - acc: 0.1668    \n",
      "Epoch 3/50\n",
      "5655/5655 [==============================] - 41s - loss: 2.2455 - acc: 0.1708    \n",
      "Epoch 4/50\n",
      "5655/5655 [==============================] - 44s - loss: 2.1780 - acc: 0.1816    \n",
      "Epoch 5/50\n",
      "5655/5655 [==============================] - 41s - loss: 2.1479 - acc: 0.1843    \n",
      "Epoch 6/50\n",
      "5655/5655 [==============================] - 40s - loss: 2.1033 - acc: 0.2005    \n",
      "Epoch 7/50\n",
      "5655/5655 [==============================] - 40s - loss: 2.0880 - acc: 0.2193    \n",
      "Epoch 8/50\n",
      "5655/5655 [==============================] - 40s - loss: 2.0503 - acc: 0.2164    \n",
      "Epoch 9/50\n",
      "5655/5655 [==============================] - 40s - loss: 2.0423 - acc: 0.2182    \n",
      "Epoch 10/50\n",
      "5655/5655 [==============================] - 40s - loss: 2.0191 - acc: 0.2235    \n",
      "Epoch 11/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.9973 - acc: 0.2216    \n",
      "Epoch 12/50\n",
      "5655/5655 [==============================] - 40s - loss: 1.9899 - acc: 0.2447    \n",
      "Epoch 13/50\n",
      "5655/5655 [==============================] - 42s - loss: 1.9678 - acc: 0.2435    \n",
      "Epoch 14/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.9652 - acc: 0.2474    \n",
      "Epoch 15/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.9400 - acc: 0.2552    \n",
      "Epoch 16/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.9333 - acc: 0.2645    \n",
      "Epoch 17/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.9280 - acc: 0.2573    \n",
      "Epoch 18/50\n",
      "5655/5655 [==============================] - 42s - loss: 1.9009 - acc: 0.2638    \n",
      "Epoch 19/50\n",
      "5655/5655 [==============================] - 42s - loss: 1.8924 - acc: 0.2750    \n",
      "Epoch 20/50\n",
      "5655/5655 [==============================] - 42s - loss: 1.8807 - acc: 0.2720    \n",
      "Epoch 21/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.8723 - acc: 0.2806    \n",
      "Epoch 22/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.8508 - acc: 0.2881    \n",
      "Epoch 23/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.8455 - acc: 0.2930    \n",
      "Epoch 24/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.8401 - acc: 0.2990    \n",
      "Epoch 25/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.8190 - acc: 0.3008    \n",
      "Epoch 26/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.8048 - acc: 0.3130    \n",
      "Epoch 27/50\n",
      "5655/5655 [==============================] - 43s - loss: 1.8024 - acc: 0.3105    \n",
      "Epoch 28/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.7858 - acc: 0.3289    \n",
      "Epoch 29/50\n",
      "5655/5655 [==============================] - 40s - loss: 1.7797 - acc: 0.3250    \n",
      "Epoch 30/50\n",
      "5655/5655 [==============================] - 40s - loss: 1.7547 - acc: 0.3296    \n",
      "Epoch 31/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.7473 - acc: 0.3358    \n",
      "Epoch 32/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.7379 - acc: 0.3471    \n",
      "Epoch 33/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.7274 - acc: 0.3432    \n",
      "Epoch 34/50\n",
      "5655/5655 [==============================] - 42s - loss: 1.7253 - acc: 0.3431    \n",
      "Epoch 35/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.7082 - acc: 0.3616    \n",
      "Epoch 36/50\n",
      "5655/5655 [==============================] - 42s - loss: 1.7027 - acc: 0.3475    \n",
      "Epoch 37/50\n",
      "5655/5655 [==============================] - 42s - loss: 1.6771 - acc: 0.3721    \n",
      "Epoch 38/50\n",
      "5655/5655 [==============================] - 42s - loss: 1.6644 - acc: 0.3747    \n",
      "Epoch 39/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.6704 - acc: 0.3899    \n",
      "Epoch 40/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.6491 - acc: 0.3837    \n",
      "Epoch 41/50\n",
      "5655/5655 [==============================] - 42s - loss: 1.6475 - acc: 0.3758    \n",
      "Epoch 42/50\n",
      "5655/5655 [==============================] - 42s - loss: 1.6150 - acc: 0.3959    \n",
      "Epoch 43/50\n",
      "5655/5655 [==============================] - 42s - loss: 1.6119 - acc: 0.3989    \n",
      "Epoch 44/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.6045 - acc: 0.3954    \n",
      "Epoch 45/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.5922 - acc: 0.3981    \n",
      "Epoch 46/50\n",
      "5655/5655 [==============================] - 42s - loss: 1.5776 - acc: 0.4177    \n",
      "Epoch 47/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.5828 - acc: 0.4141    \n",
      "Epoch 48/50\n",
      "5655/5655 [==============================] - 45s - loss: 1.5538 - acc: 0.4251    \n",
      "Epoch 49/50\n",
      "5655/5655 [==============================] - 42s - loss: 1.5437 - acc: 0.4290    \n",
      "Epoch 50/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.5479 - acc: 0.4338    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.41      0.44      0.42       661\n",
      "          1       0.26      0.30      0.28       776\n",
      "          2       0.22      0.32      0.26       740\n",
      "          3       0.18      0.08      0.11       612\n",
      "          4       0.18      0.14      0.15       565\n",
      "          5       0.16      0.13      0.14       438\n",
      "          6       0.16      0.28      0.20       333\n",
      "          7       0.05      0.00      0.01       265\n",
      "          8       0.12      0.22      0.15       228\n",
      "          9       0.16      0.17      0.16       193\n",
      "         10       0.00      0.00      0.00       127\n",
      "         11       0.14      0.27      0.18       138\n",
      "         12       0.00      0.00      0.00       123\n",
      "         13       0.09      0.10      0.10        90\n",
      "         14       0.14      0.23      0.18        77\n",
      "         15       0.00      0.00      0.00        70\n",
      "         16       0.00      0.00      0.00        73\n",
      "         17       0.00      0.00      0.00        50\n",
      "         18       0.00      0.00      0.00        43\n",
      "         19       0.00      0.00      0.00        34\n",
      "         20       0.65      0.93      0.76       206\n",
      "\n",
      "avg / total       0.21      0.24      0.21      5842\n",
      "\n",
      "Precision:\t0.206\n",
      "Recall:  \t0.236\n",
      "F1 Score:\t0.213\n",
      "Accuracy:\t0.236\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.33      0.36      0.34       200\n",
      "          1       0.27      0.23      0.25       256\n",
      "          2       0.20      0.31      0.24       228\n",
      "          3       0.17      0.06      0.09       197\n",
      "          4       0.19      0.19      0.19       136\n",
      "          5       0.13      0.10      0.11        88\n",
      "          6       0.10      0.20      0.13        51\n",
      "          7       0.00      0.00      0.00        41\n",
      "          8       0.08      0.26      0.12        35\n",
      "          9       0.08      0.09      0.08        23\n",
      "         10       0.00      0.00      0.00        24\n",
      "         11       0.10      0.22      0.13        18\n",
      "         12       0.00      0.00      0.00        14\n",
      "         13       0.09      0.14      0.11         7\n",
      "         14       0.09      0.12      0.10        16\n",
      "         15       0.00      0.00      0.00        10\n",
      "         16       0.00      0.00      0.00        13\n",
      "         17       0.00      0.00      0.00         9\n",
      "         18       0.00      0.00      0.00         8\n",
      "         19       0.00      0.00      0.00         7\n",
      "         20       0.80      0.69      0.74        29\n",
      "\n",
      "avg / total       0.20      0.21      0.20      1410\n",
      "\n",
      "Precision:\t0.204\n",
      "Recall:  \t0.211\n",
      "F1 Score:\t0.200\n",
      "Accuracy:\t0.211\n"
     ]
    }
   ],
   "source": [
    "#def dnn (feats,labels):\n",
    "#estimate glass-box error count\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_dim=feat_len))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(21, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_feats,train_err, epochs=_EPOCHS,batch_size=32)\n",
    "model.save('./my_model.h5', overwrite=True)\n",
    "\n",
    "report (test1_feats,test1_err,'test1.glass','err')\n",
    "report (test2_feats,test2_err,'test2.glass','err')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "def MAE (txt,glass,black,ref): \n",
    "    MAE_glass=mean_absolute_error(glass, ref)\n",
    "    MAE_black=mean_absolute_error(black, ref)\n",
    "\n",
    "    RMS_glass = sqrt(mean_squared_error(ref, glass))\n",
    "    RMS_black = sqrt(mean_squared_error(ref, black))\n",
    "    \n",
    "    personWER_glass = scipy.stats.pearsonr(glass, ref)\n",
    "    personWER_black = scipy.stats.pearsonr(black, ref)\n",
    "    \n",
    "    print  ('MAE:', txt,  \"%.2f\" % MAE_glass,  \"%.2f\" % MAE_black)\n",
    "    print  ('RMSE:', txt,  \"%.2f\" % RMS_glass,  \"%.2f\" % RMS_black, '\\n')\n",
    "    print ('Person Correlation:', txt, \"%.2f\" % personWER_glass[0], \"%.2f\" % personWER_black[0])\n",
    "    \n",
    "\n",
    "def parse_results(onetwo):\n",
    "    one_two = str (onetwo)\n",
    "    print (\"Analysis for: \", one_two)\n",
    "    #wc per sentence\n",
    "    glass_file_wc = 'class.out.test'+one_two+'.glass.wc'\n",
    "    black_file_wc = 'class.out.test'+one_two+'.black.wc'\n",
    "    ref_file_wc   =  'test'+one_two+'.wc'\n",
    "\n",
    "    glass_np_wc = np.loadtxt(glass_file_wc,usecols=range(0,1),dtype='float32')+1\n",
    "    black_np_wc = np.loadtxt(black_file_wc,usecols=range(0,1),dtype='float32')+1\n",
    "    ref_np_wc   = np.loadtxt(ref_file_wc,usecols=range(0,1),dtype='float32')\n",
    "\n",
    "    MAE ('glass/black: WC :',glass_np_wc,black_np_wc,ref_np_wc)\n",
    "    \n",
    "\n",
    "    #err per sentence\n",
    "    glass_file_err = 'class.out.test'+one_two+'.glass.err'\n",
    "    black_file_err = 'class.out.test'+one_two+'.black.err'\n",
    "    ref_file_err   = 'test'+one_two+'.err'\n",
    "\n",
    "    glass_np_err = np.loadtxt(glass_file_err,usecols=range(0,1),dtype='float32')\n",
    "    black_np_err = np.loadtxt(black_file_err,usecols=range(0,1),dtype='float32')\n",
    "    ref_np_err   = np.loadtxt(ref_file_err,usecols=range(0,1),dtype='float32')\n",
    "\n",
    "\n",
    "    \n",
    "    MAE ('glass/black: ERR :',glass_np_err,black_np_err,ref_np_err)\n",
    "    \n",
    "\n",
    "    #wer per sentence\n",
    "    glass_np_wer=np.divide(glass_np_err,glass_np_wc)*100\n",
    "    black_np_wer=np.divide(black_np_err,black_np_wc)*100\n",
    "    ref_np_wer=np.divide(ref_np_err,ref_np_wc)*100\n",
    "\n",
    "    MAE ('glass/black: WER :',glass_np_wer,black_np_err,ref_np_wer)\n",
    "    \n",
    "    \n",
    "    #Overall WER\n",
    "    wer_ref   = np.sum(ref_np_err)/np.sum(ref_np_wc)*100\n",
    "    wer_glass = np.sum(glass_np_err)/np.sum(glass_np_wc)*100\n",
    "    wer_black = np.sum(black_np_err)/np.sum(black_np_wc)*100\n",
    "    print ('Overall WER: glass/black:', \"%.2f\" % wer_ref, \"%.2f\" % wer_glass, \"%.2f\" % wer_black)\n",
    "    print ('###########')\n",
    "\n",
    "    #dump WER for more analysis\n",
    "    np.savetxt('wer_ref.'+one_two, ref_np_wer,fmt='%.2f') \n",
    "    np.savetxt('wer_black.'+one_two, black_np_wer,fmt='%.2f') \n",
    "    np.savetxt('wer_glass.'+one_two, glass_np_wer,fmt='%.2f') \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature dimension:  15368\n",
      "Processing:  0\n",
      "Processing:  1000\n",
      "Processing:  2000\n",
      "Processing:  3000\n",
      "Processing:  4000\n",
      "Processing:  5000\n",
      "(5655, 15368)\n",
      "Processing:  data/eval.mgb2/wer.feats\n",
      "wc:unique:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "wc:counts:  [  1   9  21  76 128 219 305 413 462 509 519 509 481 435 363 328 235 185\n",
      " 125 332]\n",
      "err:unique:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "err:counts:  [619 886 868 800 588 498 358 217 208 160 106  89  60  39  31  29  18  17\n",
      "  14   7  43]\n",
      "(5655, 20) (5655, 21)\n",
      "Processing:  0\n",
      "Processing:  1000\n",
      "Processing:  2000\n",
      "Processing:  3000\n",
      "Processing:  4000\n",
      "Processing:  5000\n",
      "(5842, 15368)\n",
      "Processing:  data/dev.mgb2/wer.feats\n",
      "wc:unique:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "wc:counts:  [  2   7  33 101 166 237 326 372 459 455 446 454 429 390 362 283 290 228\n",
      " 184 618]\n",
      "err:unique:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "err:counts:  [661 776 740 612 565 438 333 265 228 193 127 138 123  90  77  70  73  50\n",
      "  43  34 206]\n",
      "(5842, 20) (5842, 21)\n",
      "Processing:  0\n",
      "Processing:  1000\n",
      "(1410, 15368)\n",
      "Processing:  data/summa_test20170317/wer.feats\n",
      "wc:unique:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "wc:counts:  [  1   2   6   5  16  18  34  52  65  87 105 115 140 135 116  97  95  74\n",
      "  65 182]\n",
      "err:unique:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "err:counts:  [200 256 228 197 136  88  51  41  35  23  24  18  14   7  16  10  13   9\n",
      "   8   7  29]\n",
      "(1410, 20) (1410, 21)\n"
     ]
    }
   ],
   "source": [
    "##Process the black-box features:\n",
    "id, numerical, text, char, ref =load_file (train,'black')\n",
    "\n",
    "word_list, char_list = return_word_char_list (text, char)\n",
    "numerical_len=len(numerical[0].split())\n",
    "\n",
    "feat_len=(len(word_list+char_list)+numerical_len)\n",
    "print (\"Feature dimension: \", feat_len)\n",
    "\n",
    "\n",
    "\n",
    "train_feats = make_features (numerical, text, char, word_list, char_list )\n",
    "train_wc, train_err = get_wc_err (train,'train')\n",
    "\n",
    "\n",
    "\n",
    "id, numerical, text, char, ref =load_file (test1,'black')\n",
    "test1_feats = make_features (numerical, text, char, word_list, char_list )\n",
    "test1_wc, test1_err = get_wc_err (test1,'test1')\n",
    "\n",
    "\n",
    "id, numerical, text, char, ref =load_file (test2,'black')\n",
    "test2_feats = make_features (numerical, text, char, word_list, char_list )\n",
    "test2_wc, test2_err = get_wc_err (test2,'test2')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5655/5655 [==============================] - 57s - loss: 2.6314 - acc: 0.1332    \n",
      "Epoch 2/50\n",
      "5655/5655 [==============================] - 41s - loss: 2.1867 - acc: 0.2101    \n",
      "Epoch 3/50\n",
      "5655/5655 [==============================] - 40s - loss: 1.9864 - acc: 0.2573    \n",
      "Epoch 4/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.8202 - acc: 0.3073    \n",
      "Epoch 5/50\n",
      "5655/5655 [==============================] - 43s - loss: 1.7006 - acc: 0.3478    \n",
      "Epoch 6/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.6106 - acc: 0.3837    \n",
      "Epoch 7/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.5163 - acc: 0.4232    \n",
      "Epoch 8/50\n",
      "5655/5655 [==============================] - 42s - loss: 1.4337 - acc: 0.4718    \n",
      "Epoch 9/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.3354 - acc: 0.5049    \n",
      "Epoch 10/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.2477 - acc: 0.5376    \n",
      "Epoch 11/50\n",
      "5655/5655 [==============================] - 42s - loss: 1.1625 - acc: 0.5671    \n",
      "Epoch 12/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.0651 - acc: 0.6080    \n",
      "Epoch 13/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.0106 - acc: 0.6389    \n",
      "Epoch 14/50\n",
      "5655/5655 [==============================] - 41s - loss: 0.9318 - acc: 0.6677    \n",
      "Epoch 15/50\n",
      "5655/5655 [==============================] - 42s - loss: 0.8471 - acc: 0.6985    \n",
      "Epoch 16/50\n",
      "5655/5655 [==============================] - 41s - loss: 0.7962 - acc: 0.7238    \n",
      "Epoch 17/50\n",
      "5655/5655 [==============================] - 42s - loss: 0.7261 - acc: 0.7454    \n",
      "Epoch 18/50\n",
      "5655/5655 [==============================] - 41s - loss: 0.6607 - acc: 0.7747    \n",
      "Epoch 19/50\n",
      "5655/5655 [==============================] - 44s - loss: 0.6275 - acc: 0.7862    \n",
      "Epoch 20/50\n",
      "5655/5655 [==============================] - 42s - loss: 0.5610 - acc: 0.8156    \n",
      "Epoch 21/50\n",
      "5655/5655 [==============================] - 42s - loss: 0.5341 - acc: 0.8202    \n",
      "Epoch 22/50\n",
      "5655/5655 [==============================] - 42s - loss: 0.5034 - acc: 0.8354    \n",
      "Epoch 23/50\n",
      "5655/5655 [==============================] - 41s - loss: 0.4557 - acc: 0.8511    \n",
      "Epoch 24/50\n",
      "5655/5655 [==============================] - 45s - loss: 0.4244 - acc: 0.8592    \n",
      "Epoch 25/50\n",
      "5655/5655 [==============================] - 41s - loss: 0.4067 - acc: 0.8644    \n",
      "Epoch 26/50\n",
      "5655/5655 [==============================] - 42s - loss: 0.3711 - acc: 0.8746    \n",
      "Epoch 27/50\n",
      "5655/5655 [==============================] - 43s - loss: 0.3474 - acc: 0.8838    \n",
      "Epoch 28/50\n",
      "5655/5655 [==============================] - 41s - loss: 0.3363 - acc: 0.8921    \n",
      "Epoch 29/50\n",
      "5655/5655 [==============================] - 43s - loss: 0.3257 - acc: 0.8953    \n",
      "Epoch 30/50\n",
      "5655/5655 [==============================] - 41s - loss: 0.2995 - acc: 0.8969    \n",
      "Epoch 31/50\n",
      "5655/5655 [==============================] - 41s - loss: 0.2910 - acc: 0.9068    \n",
      "Epoch 32/50\n",
      "5655/5655 [==============================] - 42s - loss: 0.2635 - acc: 0.9144    \n",
      "Epoch 33/50\n",
      "5655/5655 [==============================] - 42s - loss: 0.2878 - acc: 0.9073    \n",
      "Epoch 34/50\n",
      "5655/5655 [==============================] - 41s - loss: 0.2567 - acc: 0.9158    \n",
      "Epoch 35/50\n",
      "5655/5655 [==============================] - 42s - loss: 0.2523 - acc: 0.9231    \n",
      "Epoch 36/50\n",
      "5655/5655 [==============================] - 44s - loss: 0.2267 - acc: 0.9261    \n",
      "Epoch 37/50\n",
      "5655/5655 [==============================] - 41s - loss: 0.2156 - acc: 0.9293    \n",
      "Epoch 38/50\n",
      "5655/5655 [==============================] - 41s - loss: 0.2330 - acc: 0.9238    \n",
      "Epoch 39/50\n",
      "5655/5655 [==============================] - 41s - loss: 0.2060 - acc: 0.9383    \n",
      "Epoch 40/50\n",
      "5655/5655 [==============================] - 41s - loss: 0.2036 - acc: 0.9340    \n",
      "Epoch 41/50\n",
      "5655/5655 [==============================] - 43s - loss: 0.2071 - acc: 0.9319    \n",
      "Epoch 42/50\n",
      "5655/5655 [==============================] - 42s - loss: 0.2003 - acc: 0.9367    \n",
      "Epoch 43/50\n",
      "5655/5655 [==============================] - 46s - loss: 0.1939 - acc: 0.9420    \n",
      "Epoch 44/50\n",
      "5655/5655 [==============================] - 43s - loss: 0.1744 - acc: 0.9447    \n",
      "Epoch 45/50\n",
      "5655/5655 [==============================] - 41s - loss: 0.1732 - acc: 0.9454    \n",
      "Epoch 46/50\n",
      "5655/5655 [==============================] - 41s - loss: 0.1647 - acc: 0.9455    \n",
      "Epoch 47/50\n",
      "5655/5655 [==============================] - 41s - loss: 0.1692 - acc: 0.9455    \n",
      "Epoch 48/50\n",
      "5655/5655 [==============================] - 42s - loss: 0.1607 - acc: 0.9500    \n",
      "Epoch 49/50\n",
      "5655/5655 [==============================] - 42s - loss: 0.1691 - acc: 0.9496    \n",
      "Epoch 50/50\n",
      "5655/5655 [==============================] - 42s - loss: 0.1565 - acc: 0.9526    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         2\n",
      "          1       0.00      0.00      0.00         7\n",
      "          2       0.00      0.00      0.00        33\n",
      "          3       0.00      0.00      0.00       101\n",
      "          4       0.18      0.05      0.08       166\n",
      "          5       0.19      0.15      0.17       237\n",
      "          6       0.16      0.05      0.08       326\n",
      "          7       0.12      0.10      0.11       372\n",
      "          8       0.12      0.06      0.08       459\n",
      "          9       0.11      0.08      0.09       455\n",
      "         10       0.06      0.04      0.05       446\n",
      "         11       0.09      0.07      0.08       454\n",
      "         12       0.10      0.16      0.13       429\n",
      "         13       0.08      0.07      0.07       390\n",
      "         14       0.02      0.01      0.01       362\n",
      "         15       0.06      0.10      0.08       283\n",
      "         16       0.06      0.03      0.04       290\n",
      "         17       0.07      0.23      0.11       228\n",
      "         18       0.02      0.02      0.02       184\n",
      "         19       0.05      0.00      0.00       618\n",
      "         20       0.00      0.00      0.00         0\n",
      "         21       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.09      0.07      0.07      5842\n",
      "\n",
      "Precision:\t0.087\n",
      "Recall:  \t0.068\n",
      "F1 Score:\t0.069\n",
      "Accuracy:\t0.068\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         1\n",
      "          1       0.00      0.00      0.00         2\n",
      "          2       0.00      0.00      0.00         6\n",
      "          3       0.00      0.00      0.00         5\n",
      "          4       0.27      0.19      0.22        16\n",
      "          5       0.15      0.11      0.13        18\n",
      "          6       0.33      0.09      0.14        34\n",
      "          7       0.10      0.06      0.07        52\n",
      "          8       0.09      0.03      0.05        65\n",
      "          9       0.08      0.05      0.06        87\n",
      "         10       0.03      0.01      0.01       105\n",
      "         11       0.12      0.05      0.07       115\n",
      "         12       0.08      0.06      0.07       140\n",
      "         13       0.12      0.07      0.09       135\n",
      "         14       0.00      0.00      0.00       116\n",
      "         15       0.04      0.05      0.05        97\n",
      "         16       0.03      0.01      0.02        95\n",
      "         17       0.05      0.19      0.08        74\n",
      "         18       0.05      0.06      0.05        65\n",
      "         19       0.13      0.01      0.02       182\n",
      "         20       0.00      0.00      0.00         0\n",
      "         21       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.08      0.05      0.05      1410\n",
      "\n",
      "Precision:\t0.084\n",
      "Recall:  \t0.048\n",
      "F1 Score:\t0.052\n",
      "Accuracy:\t0.048\n"
     ]
    }
   ],
   "source": [
    "#def dnn (feats,labels):\n",
    "#estimate glass-box word count (make sure to add one to your estimation)\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_dim=feat_len))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(20, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_feats,train_wc, epochs=_EPOCHS,batch_size=32)\n",
    "model.save('./my_model.h5', overwrite=True)\n",
    "\n",
    "report (test1_feats,test1_wc,'test1.black','wc')\n",
    "report (test2_feats,test2_wc,'test2.black','wc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5655/5655 [==============================] - 57s - loss: 2.5287 - acc: 0.1469    \n",
      "Epoch 2/50\n",
      "5655/5655 [==============================] - 42s - loss: 2.2637 - acc: 0.1760    \n",
      "Epoch 3/50\n",
      "5655/5655 [==============================] - 42s - loss: 2.1490 - acc: 0.2085    \n",
      "Epoch 4/50\n",
      "5655/5655 [==============================] - 42s - loss: 2.0574 - acc: 0.2416    \n",
      "Epoch 5/50\n",
      "5655/5655 [==============================] - 44s - loss: 1.9841 - acc: 0.2631    \n",
      "Epoch 6/50\n",
      "5655/5655 [==============================] - 44s - loss: 1.8774 - acc: 0.3160    \n",
      "Epoch 7/50\n",
      "5655/5655 [==============================] - 42s - loss: 1.7873 - acc: 0.3569    \n",
      "Epoch 8/50\n",
      "5655/5655 [==============================] - 42s - loss: 1.6933 - acc: 0.4019    \n",
      "Epoch 9/50\n",
      "5655/5655 [==============================] - 40s - loss: 1.5830 - acc: 0.4458    \n",
      "Epoch 10/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.4701 - acc: 0.4859    \n",
      "Epoch 11/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.3709 - acc: 0.5218    \n",
      "Epoch 12/50\n",
      "5655/5655 [==============================] - 42s - loss: 1.2757 - acc: 0.5576    \n",
      "Epoch 13/50\n",
      "5655/5655 [==============================] - 42s - loss: 1.1983 - acc: 0.5996    \n",
      "Epoch 14/50\n",
      "5655/5655 [==============================] - 41s - loss: 1.1053 - acc: 0.6313    \n",
      "Epoch 15/50\n",
      "5655/5655 [==============================] - 44s - loss: 1.0061 - acc: 0.6561    \n",
      "Epoch 16/50\n",
      "5655/5655 [==============================] - 41s - loss: 0.9310 - acc: 0.6826    \n",
      "Epoch 17/50\n",
      "5655/5655 [==============================] - 41s - loss: 0.8788 - acc: 0.7017    \n",
      "Epoch 18/50\n",
      "5655/5655 [==============================] - 41s - loss: 0.8002 - acc: 0.7355    \n",
      "Epoch 19/50\n",
      "5655/5655 [==============================] - 42s - loss: 0.7592 - acc: 0.7468    \n",
      "Epoch 20/50\n",
      "5655/5655 [==============================] - 42s - loss: 0.6863 - acc: 0.7724    \n",
      "Epoch 21/50\n",
      "5655/5655 [==============================] - 42s - loss: 0.6572 - acc: 0.7859    \n",
      "Epoch 22/50\n",
      "5655/5655 [==============================] - 41s - loss: 0.5946 - acc: 0.8069    \n",
      "Epoch 23/50\n",
      "5655/5655 [==============================] - 42s - loss: 0.5728 - acc: 0.8080    \n",
      "Epoch 24/50\n",
      "5655/5655 [==============================] - 42s - loss: 0.5243 - acc: 0.8304    \n",
      "Epoch 25/50\n",
      "5655/5655 [==============================] - 41s - loss: 0.5263 - acc: 0.8276    \n",
      "Epoch 26/50\n",
      "5655/5655 [==============================] - 43s - loss: 0.4770 - acc: 0.8417    \n",
      "Epoch 27/50\n",
      "5655/5655 [==============================] - 41s - loss: 0.4589 - acc: 0.8508    \n",
      "Epoch 28/50\n",
      "5655/5655 [==============================] - 43s - loss: 0.4287 - acc: 0.8523    \n",
      "Epoch 29/50\n",
      "5655/5655 [==============================] - 42s - loss: 0.4149 - acc: 0.8660    \n",
      "Epoch 30/50\n",
      "5655/5655 [==============================] - 41s - loss: 0.3836 - acc: 0.8744    \n",
      "Epoch 31/50\n",
      "5655/5655 [==============================] - 44s - loss: 0.3917 - acc: 0.8721    \n",
      "Epoch 32/50\n",
      "5655/5655 [==============================] - 42s - loss: 0.3797 - acc: 0.8780    \n",
      "Epoch 33/50\n",
      "5655/5655 [==============================] - 42s - loss: 0.3475 - acc: 0.8847    \n",
      "Epoch 34/50\n",
      "5655/5655 [==============================] - 41s - loss: 0.3281 - acc: 0.8928    \n",
      "Epoch 35/50\n",
      "5655/5655 [==============================] - 47s - loss: 0.3307 - acc: 0.8974    \n",
      "Epoch 36/50\n",
      "5655/5655 [==============================] - 95s - loss: 0.3268 - acc: 0.8953    \n",
      "Epoch 37/50\n",
      "5655/5655 [==============================] - 104s - loss: 0.2978 - acc: 0.9073   \n",
      "Epoch 38/50\n",
      "5655/5655 [==============================] - 115s - loss: 0.2923 - acc: 0.9086   \n",
      "Epoch 39/50\n",
      "5655/5655 [==============================] - 65s - loss: 0.2847 - acc: 0.9070    \n",
      "Epoch 40/50\n",
      "5655/5655 [==============================] - 49s - loss: 0.2805 - acc: 0.9121    \n",
      "Epoch 41/50\n",
      "5655/5655 [==============================] - 50s - loss: 0.2592 - acc: 0.9178    \n",
      "Epoch 42/50\n",
      "5655/5655 [==============================] - 46s - loss: 0.2551 - acc: 0.9194    \n",
      "Epoch 43/50\n",
      "5655/5655 [==============================] - 43s - loss: 0.2582 - acc: 0.9116    \n",
      "Epoch 44/50\n",
      "5655/5655 [==============================] - 46s - loss: 0.2401 - acc: 0.9233    \n",
      "Epoch 45/50\n",
      "5655/5655 [==============================] - 44s - loss: 0.2443 - acc: 0.9217    \n",
      "Epoch 46/50\n",
      "5655/5655 [==============================] - 43s - loss: 0.2325 - acc: 0.9245    \n",
      "Epoch 47/50\n",
      "5655/5655 [==============================] - 45s - loss: 0.2297 - acc: 0.9261    \n",
      "Epoch 48/50\n",
      "5655/5655 [==============================] - 46s - loss: 0.2219 - acc: 0.9286    \n",
      "Epoch 49/50\n",
      "5655/5655 [==============================] - 47s - loss: 0.2276 - acc: 0.9259    \n",
      "Epoch 50/50\n",
      "5655/5655 [==============================] - 43s - loss: 0.2321 - acc: 0.9294    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.32      0.26      0.29       661\n",
      "          1       0.23      0.36      0.28       776\n",
      "          2       0.18      0.29      0.22       740\n",
      "          3       0.19      0.06      0.09       612\n",
      "          4       0.15      0.13      0.14       565\n",
      "          5       0.15      0.09      0.11       438\n",
      "          6       0.11      0.04      0.05       333\n",
      "          7       0.10      0.10      0.10       265\n",
      "          8       0.13      0.19      0.16       228\n",
      "          9       0.12      0.18      0.14       193\n",
      "         10       0.12      0.15      0.13       127\n",
      "         11       0.12      0.17      0.15       138\n",
      "         12       0.09      0.06      0.07       123\n",
      "         13       0.12      0.20      0.15        90\n",
      "         14       0.10      0.09      0.09        77\n",
      "         15       0.18      0.10      0.13        70\n",
      "         16       0.00      0.00      0.00        73\n",
      "         17       0.00      0.00      0.00        50\n",
      "         18       0.00      0.00      0.00        43\n",
      "         19       0.00      0.00      0.00        34\n",
      "         20       0.63      0.93      0.75       206\n",
      "\n",
      "avg / total       0.19      0.21      0.19      5842\n",
      "\n",
      "Precision:\t0.191\n",
      "Recall:  \t0.206\n",
      "F1 Score:\t0.187\n",
      "Accuracy:\t0.206\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.30      0.20      0.24       200\n",
      "          1       0.32      0.32      0.32       256\n",
      "          2       0.17      0.28      0.21       228\n",
      "          3       0.07      0.01      0.02       197\n",
      "          4       0.14      0.12      0.13       136\n",
      "          5       0.09      0.08      0.09        88\n",
      "          6       0.00      0.00      0.00        51\n",
      "          7       0.07      0.10      0.08        41\n",
      "          8       0.09      0.23      0.13        35\n",
      "          9       0.07      0.17      0.10        23\n",
      "         10       0.03      0.04      0.04        24\n",
      "         11       0.16      0.33      0.22        18\n",
      "         12       0.09      0.07      0.08        14\n",
      "         13       0.12      0.71      0.21         7\n",
      "         14       0.12      0.06      0.08        16\n",
      "         15       0.06      0.10      0.07        10\n",
      "         16       0.00      0.00      0.00        13\n",
      "         17       0.00      0.00      0.00         9\n",
      "         18       0.00      0.00      0.00         8\n",
      "         19       0.00      0.00      0.00         7\n",
      "         20       0.61      0.86      0.71        29\n",
      "\n",
      "avg / total       0.18      0.19      0.18      1410\n",
      "\n",
      "Precision:\t0.181\n",
      "Recall:  \t0.191\n",
      "F1 Score:\t0.176\n",
      "Accuracy:\t0.191\n"
     ]
    }
   ],
   "source": [
    "#def dnn (feats,labels):\n",
    "#estimate black-box error count\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_dim=feat_len))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(21, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_feats,train_err, epochs=_EPOCHS,batch_size=32)\n",
    "model.save('./my_model.h5', overwrite=True)\n",
    "\n",
    "report (test1_feats,test1_err,'test1.black','err')\n",
    "report (test2_feats,test2_err,'test2.black','err')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis for:  1\n",
      "MAE: glass/black: WC : 1.92 2.98\n",
      "RMSE: glass/black: WC : 2.53 3.65 \n",
      "\n",
      "Person Correlation: glass/black: WC : 0.92 0.86\n",
      "MAE: glass/black: ERR : 1.87 2.27\n",
      "RMSE: glass/black: ERR : 2.67 3.15 \n",
      "\n",
      "Person Correlation: glass/black: ERR : 0.89 0.84\n",
      "MAE: glass/black: WER : 14.80 34.05\n",
      "RMSE: glass/black: WER : 20.96 42.86 \n",
      "\n",
      "Person Correlation: glass/black: WER : 0.76 0.64\n",
      "Overall WER: glass/black: 42.57 34.93 33.19\n",
      "###########\n",
      "\n",
      "\n",
      "Analysis for:  2\n",
      "MAE: glass/black: WC : 1.64 3.25\n",
      "RMSE: glass/black: WC : 2.09 3.86 \n",
      "\n",
      "Person Correlation: glass/black: WC : 0.92 0.83\n",
      "MAE: glass/black: ERR : 1.79 2.16\n",
      "RMSE: glass/black: ERR : 2.46 3.00 \n",
      "\n",
      "Person Correlation: glass/black: ERR : 0.86 0.80\n",
      "MAE: glass/black: WER : 13.13 24.31\n",
      "RMSE: glass/black: WER : 18.15 34.56 \n",
      "\n",
      "Person Correlation: glass/black: WER : 0.78 0.67\n",
      "Overall WER: glass/black: 28.51 24.25 26.37\n",
      "###########\n"
     ]
    }
   ],
   "source": [
    "#summary\n",
    "parse_results (1)\n",
    "print ('\\n')\n",
    "parse_results (2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
