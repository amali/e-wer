{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#load lib\n",
    "import numpy as np\n",
    "import re, sys, glob\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from keras.preprocessing import text\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk import ngrams\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.models import load_model\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load data\n",
    "\n",
    "'''\n",
    "Features order in the data look like this \n",
    "print STDOUT \"S:\".$uttranceInfo{\"id\"}.\"\\t\".$wordcount.\" \".$graphemecount.\" \".$uttranceInfo{\"total_frames\"}.\n",
    "      \" \".$uttranceInfo{\"avg_loglike\"}.\" \".$uttranceInfo{\"total_AMloglike\"}.\" \".\n",
    "\t  $uttranceInfo{\"total_LMloglike\"}.\" \".$uttranceInfo{\"duration\"}.\" \".\n",
    "\t  $uttranceInfo{\"GER\"}.\"\\t\".$uttranceInfo{\"sentence\"}.\"\\t\".$uttranceInfo{\"grapheme\"}.\n",
    "\t  \"\\t\".$uttranceInfo{\"WER\"}.\"\\n\";\n",
    "'''\n",
    "\n",
    "train=\"data/dev.mgb2/wer.feats\"\n",
    "test1=\"data/eval.mgb2/wer.feats\"\n",
    "test2=\"data/summa_test20170317/wer.feats\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_file (file,type='glass'):\n",
    "    f=open(file,\"r\")\n",
    "    lines=f.readlines()\n",
    "    _id=[]\n",
    "    _text=[]\n",
    "    _numerical=[]\n",
    "    _char=[]\n",
    "    _ref=[]\n",
    "    for x in lines:\n",
    "        _id.append(x.split('\\t')[0])\n",
    "        _text.append(x.split('\\t')[2])\n",
    "        _char.append(x.split('\\t')[3])\n",
    "        _ref.append(x.split('\\t')[4])\n",
    "        if type == 'glass': \n",
    "            _numerical.append(x.split('\\t')[1])\n",
    "        else:\n",
    "            blac_box_numerical=x.split('\\t')[1].split(' ')\n",
    "            numerical2=' '.join(blac_box_numerical[0:2]+blac_box_numerical[6:])\n",
    "            _numerical.append(numerical2)\n",
    "        \n",
    "    f.close()\n",
    "    return _id, _numerical, _text, _char, _ref\n",
    "\n",
    "def word_grams(words, min=1, max=4):\n",
    "    s = []\n",
    "    for n in range(min, max):\n",
    "        for ngram in ngrams(words, n):\n",
    "            s.append(' '.join(str(i) for i in ngram))\n",
    "    return s\n",
    "\n",
    "def return_word_char_list (_text,_char):\n",
    "    _unigram_word_list = [] \n",
    "    _trigram_char_list = []\n",
    "    for i,j in enumerate(_char):\n",
    "        \n",
    "        _char_3gram = word_grams (_char[i].split(),1,3)\n",
    "        for tri in _char_3gram: \n",
    "             if tri not in _trigram_char_list: _trigram_char_list.append(tri)\n",
    "    \n",
    "        _words_1gram = word_grams (_text[i].split(),1,2)\n",
    "        for uni in _words_1gram: \n",
    "             if uni not in _unigram_word_list: _unigram_word_list.append(uni)\n",
    "    return _unigram_word_list, _trigram_char_list \n",
    "                    \n",
    "def vectorize (words,chars,word_list,char_list):\n",
    "    feature_vector = []\n",
    "    index=0\n",
    "    \n",
    "    temp_words = [0] * len(word_list)\n",
    "    for word in word_grams (words.split(),1,2): \n",
    "        for index, word2 in enumerate(word_list): \n",
    "            if word == word2:\n",
    "                #print (index, word2)\n",
    "                temp_words[index]+=1\n",
    "                break\n",
    "    \n",
    "    temp_chars = [0] * len(char_list)\n",
    "    for _char in word_grams (chars.split(),1,3): \n",
    "        for index, _char2 in enumerate(char_list): \n",
    "            if _char == _char2:\n",
    "                #print (index, _char2)\n",
    "                temp_chars[index]+=1\n",
    "                break            \n",
    "    return temp_words+temp_chars\n",
    "\n",
    "def make_features (numerical, text, char, word_list, char_list ):\n",
    "    allfeats= []\n",
    "    for i, _id in enumerate (text):\n",
    "        feat = vectorize (text[i],char[i],word_list,char_list)\n",
    "        allfeats.append (numerical[i].split()+feat)\n",
    "        if i % 1000 == 0: print (\"Processing: \", i)\n",
    "    nn=np.array(allfeats)\n",
    "    #nn_minmax = preprocessing.scale(nn)\n",
    "       \n",
    "    print (nn.shape)\n",
    "    return (nn)\n",
    "    \n",
    "def get_wc_err (file,dump):\n",
    "    f=open(file,\"r\")\n",
    "    lines=f.readlines()\n",
    "    _wc=[]\n",
    "    _err=[]\n",
    "    _real_wc =[]\n",
    "    _real_err =[]\n",
    "    for x in lines:\n",
    "        err = int(x.split('\\t')[4].split(' ')[1])\n",
    "        wc  = int(x.split('\\t')[4].split(' ')[2])\n",
    "        _real_wc.append (wc)    \n",
    "        _real_err.append (err)\n",
    "        \n",
    "        wc = wc - 2\n",
    "        if wc < 0: wc =0\n",
    "        if wc > 20: wc =20\n",
    "        \n",
    "        if err > 20: err =20\n",
    "         \n",
    "        _wc.append (wc)    \n",
    "        _err.append (err)\n",
    "        one_hot_labels_wc = to_categorical(np.array(_wc), num_classes=21)\n",
    "        one_hot_labels_err = to_categorical(np.array(_err), num_classes=21)\n",
    "        \n",
    "    np.savetxt(dump+'.err', np.array(_real_err), fmt='%d')\n",
    "    np.savetxt(dump+'.wc', np.array(_real_wc), fmt='%d')\n",
    "        \n",
    "    return one_hot_labels_wc, one_hot_labels_err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "    \n",
    "\n",
    "def report (test_vec,test_labels,test,ext):\n",
    "    \n",
    "    prob_out='prob.out.'+test+'.'+ext\n",
    "    pred_out='pred.out.'+test+'.'+ext\n",
    "    class_out='class.out.'+test+'.'+ext\n",
    "    \n",
    "    _shift=0\n",
    "    if ext == \"wc\" : _shift=2\n",
    "    #load models\n",
    "    model = load_model('./my_model.h5')\n",
    "    \n",
    "    #save predictions\n",
    "    pred = model.predict(test_vec)\n",
    "    np.savetxt(pred_out, pred, delimiter=' ')    \n",
    "    \n",
    "    prob = np.copy(pred)\n",
    "    i=0\n",
    "    for row in prob: \n",
    "      raw = [sigmoid(i) for i in row]\n",
    "      norm = [float(i)/sum(raw) for i in raw]\n",
    "      prob[int(i)]=norm\n",
    "      i=i+1\n",
    "    \n",
    "    #save prob\n",
    "    np.savetxt(prob_out, prob, delimiter=' ',fmt='%f') \n",
    "    \n",
    "    \n",
    "    test_classes = np.argmax(prob, axis=1)+_shift\n",
    "    #save classes\n",
    "    np.savetxt(class_out, test_classes, delimiter=' ',fmt='%d')\n",
    "    \n",
    "\n",
    "    test_labels = np.argmax(test_labels, axis=1) # to remove the Keras to_categorical\n",
    "    \n",
    "    \n",
    "\n",
    "    #print confusion matrix \n",
    "    confusion_matrix(test_labels, test_classes)\n",
    "\n",
    "    #print classification report\n",
    "    print(classification_report(test_labels, test_classes))\n",
    "\n",
    "\n",
    "    #print prec, recall and f1\n",
    "    print (\"Precision:\\t{:0.3f}\".format(precision_score(test_labels, test_classes,average='weighted')))\n",
    "    print (\"Recall:  \\t{:0.3f}\".format(recall_score(test_labels, test_classes,average='weighted')))\n",
    "    print (\"F1 Score:\\t{:0.3f}\".format(f1_score(test_labels, test_classes,average='weighted')))\n",
    "    print (\"Accuracy:\\t{:0.3f}\".format(accuracy_score(test_labels, test_classes)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature dimension:  14964\n",
      "Processing:  0\n",
      "Processing:  1000\n",
      "Processing:  2000\n",
      "Processing:  3000\n",
      "Processing:  4000\n",
      "Processing:  5000\n",
      "(5842, 14964)\n",
      "Processing:  0\n",
      "Processing:  1000\n",
      "Processing:  2000\n",
      "Processing:  3000\n",
      "Processing:  4000\n",
      "Processing:  5000\n",
      "(5655, 14964)\n",
      "Processing:  0\n",
      "Processing:  1000\n",
      "(1410, 14964)\n"
     ]
    }
   ],
   "source": [
    "id, numerical, text, char, ref =load_file (train,'glass')\n",
    "\n",
    "word_list, char_list = return_word_char_list (text, char)\n",
    "numerical_len=len(numerical[0].split())\n",
    "\n",
    "feat_len=(len(word_list+char_list)+numerical_len)\n",
    "print (\"Feature dimension: \", feat_len)\n",
    "\n",
    "\n",
    "\n",
    "train_feats = make_features (numerical, text, char, word_list, char_list )\n",
    "train_wc, train_err = get_wc_err (train,'train')\n",
    "\n",
    "\n",
    "\n",
    "id, numerical, text, char, ref =load_file (test1,'glass')\n",
    "test1_feats = make_features (numerical, text, char, word_list, char_list )\n",
    "test1_wc, test1_err = get_wc_err (test1,'test1')\n",
    "\n",
    "\n",
    "id, numerical, text, char, ref =load_file (test2,'glass')\n",
    "test2_feats = make_features (numerical, text, char, word_list, char_list )\n",
    "test2_wc, test2_err = get_wc_err (test2,'test2')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def dnn (feats,labels):\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_dim=feat_len))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(21, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#model.fit(feats, labels, epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "5842/5842 [==============================] - 38s - loss: 3.0791 - acc: 0.1089    \n",
      "Epoch 2/30\n",
      "5842/5842 [==============================] - 38s - loss: 2.5748 - acc: 0.1611    \n",
      "Epoch 3/30\n",
      "5842/5842 [==============================] - 38s - loss: 2.4023 - acc: 0.1792    \n",
      "Epoch 4/30\n",
      "5842/5842 [==============================] - 38s - loss: 2.2862 - acc: 0.1905    \n",
      "Epoch 5/30\n",
      "5842/5842 [==============================] - 38s - loss: 2.1882 - acc: 0.2128    \n",
      "Epoch 6/30\n",
      "5842/5842 [==============================] - 38s - loss: 2.1338 - acc: 0.2345    \n",
      "Epoch 7/30\n",
      "5842/5842 [==============================] - 37s - loss: 2.0688 - acc: 0.2432    \n",
      "Epoch 8/30\n",
      "5842/5842 [==============================] - 38s - loss: 2.0487 - acc: 0.2391    \n",
      "Epoch 9/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.9937 - acc: 0.2554    \n",
      "Epoch 10/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.9739 - acc: 0.2564    \n",
      "Epoch 11/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.9294 - acc: 0.2684    \n",
      "Epoch 12/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.9043 - acc: 0.2790    \n",
      "Epoch 13/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.8803 - acc: 0.2766    \n",
      "Epoch 14/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.8532 - acc: 0.2845    \n",
      "Epoch 15/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.8299 - acc: 0.3014    \n",
      "Epoch 16/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.8226 - acc: 0.2888    \n",
      "Epoch 17/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.8139 - acc: 0.3054    \n",
      "Epoch 18/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.7801 - acc: 0.3189    \n",
      "Epoch 19/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.7581 - acc: 0.3326    \n",
      "Epoch 20/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.7515 - acc: 0.3230    \n",
      "Epoch 21/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.7309 - acc: 0.3362    \n",
      "Epoch 22/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.7158 - acc: 0.3548    \n",
      "Epoch 23/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.7058 - acc: 0.3504    \n",
      "Epoch 24/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.6788 - acc: 0.3665    \n",
      "Epoch 25/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.6746 - acc: 0.3569    \n",
      "Epoch 26/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.6674 - acc: 0.3571    \n",
      "Epoch 27/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.6300 - acc: 0.3754    \n",
      "Epoch 28/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.6310 - acc: 0.3723    \n",
      "Epoch 29/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.6343 - acc: 0.3829    \n",
      "Epoch 30/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.6111 - acc: 0.3792    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\AMALI\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\Users\\AMALI\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "D:\\Users\\AMALI\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\Users\\AMALI\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "D:\\Users\\AMALI\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\Users\\AMALI\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.00      0.00      0.00        21\n",
      "          2       0.00      0.00      0.00        76\n",
      "          3       0.00      0.00      0.00       128\n",
      "          4       0.00      0.00      0.00       219\n",
      "          5       0.01      0.00      0.01       305\n",
      "          6       0.02      0.00      0.01       413\n",
      "          7       0.09      0.15      0.11       462\n",
      "          8       0.07      0.00      0.00       509\n",
      "          9       0.11      0.19      0.14       519\n",
      "         10       0.10      0.06      0.07       509\n",
      "         11       0.16      0.30      0.20       481\n",
      "         12       0.23      0.41      0.30       435\n",
      "         13       0.25      0.25      0.25       363\n",
      "         14       0.26      0.33      0.29       328\n",
      "         15       0.22      0.39      0.28       235\n",
      "         16       0.08      0.01      0.01       185\n",
      "         17       0.15      0.18      0.16       125\n",
      "         18       0.20      0.22      0.21        95\n",
      "         19       0.14      0.18      0.16        72\n",
      "         20       0.00      0.00      0.00       165\n",
      "         21       0.00      0.00      0.00         0\n",
      "         22       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.12      0.15      0.12      5655\n",
      "\n",
      "Precision:\t0.117\n",
      "Recall:  \t0.155\n",
      "F1 Score:\t0.124\n",
      "Accuracy:\t0.155\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         3\n",
      "          1       0.00      0.00      0.00         6\n",
      "          2       0.00      0.00      0.00         5\n",
      "          3       0.00      0.00      0.00        16\n",
      "          4       0.00      0.00      0.00        18\n",
      "          5       0.08      0.03      0.04        34\n",
      "          6       0.00      0.00      0.00        52\n",
      "          7       0.08      0.09      0.08        65\n",
      "          8       0.00      0.00      0.00        87\n",
      "          9       0.13      0.17      0.15       105\n",
      "         10       0.12      0.04      0.06       115\n",
      "         11       0.20      0.35      0.26       140\n",
      "         12       0.28      0.47      0.35       135\n",
      "         13       0.21      0.22      0.21       116\n",
      "         14       0.22      0.38      0.28        97\n",
      "         15       0.20      0.36      0.26        95\n",
      "         16       0.17      0.01      0.03        74\n",
      "         17       0.16      0.12      0.14        65\n",
      "         18       0.19      0.19      0.19        52\n",
      "         19       0.04      0.03      0.03        39\n",
      "         20       0.00      0.00      0.00        91\n",
      "         21       0.00      0.00      0.00         0\n",
      "         22       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.14      0.18      0.15      1410\n",
      "\n",
      "Precision:\t0.142\n",
      "Recall:  \t0.184\n",
      "F1 Score:\t0.150\n",
      "Accuracy:\t0.184\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_feats,train_wc, epochs=30,batch_size=32)\n",
    "model.save('./my_model.h5', overwrite=True)\n",
    "\n",
    "report (test1_feats,test1_wc,'test1.glass','wc')\n",
    "report (test2_feats,test2_wc,'test2.glass','wc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "5842/5842 [==============================] - 37s - loss: 3.2201 - acc: 0.1443    \n",
      "Epoch 2/30\n",
      "5842/5842 [==============================] - 38s - loss: 2.4695 - acc: 0.1838    \n",
      "Epoch 3/30\n",
      "5842/5842 [==============================] - 37s - loss: 2.2456 - acc: 0.1931    \n",
      "Epoch 4/30\n",
      "5842/5842 [==============================] - 37s - loss: 2.1754 - acc: 0.2023    \n",
      "Epoch 5/30\n",
      "5842/5842 [==============================] - 37s - loss: 2.1591 - acc: 0.2058    \n",
      "Epoch 6/30\n",
      "5842/5842 [==============================] - 37s - loss: 2.1333 - acc: 0.2191    \n",
      "Epoch 7/30\n",
      "5842/5842 [==============================] - 37s - loss: 2.1111 - acc: 0.2246    \n",
      "Epoch 8/30\n",
      "5842/5842 [==============================] - 37s - loss: 2.0762 - acc: 0.2241    \n",
      "Epoch 9/30\n",
      "5842/5842 [==============================] - 37s - loss: 2.0664 - acc: 0.2217    \n",
      "Epoch 10/30\n",
      "5842/5842 [==============================] - 37s - loss: 2.0468 - acc: 0.2292    \n",
      "Epoch 11/30\n",
      "5842/5842 [==============================] - 38s - loss: 2.0368 - acc: 0.2371    \n",
      "Epoch 12/30\n",
      "5842/5842 [==============================] - 37s - loss: 2.0242 - acc: 0.2403    \n",
      "Epoch 13/30\n",
      "5842/5842 [==============================] - 37s - loss: 2.0109 - acc: 0.2403    \n",
      "Epoch 14/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.9879 - acc: 0.2499    \n",
      "Epoch 15/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.9867 - acc: 0.2489    \n",
      "Epoch 16/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.9804 - acc: 0.2544    \n",
      "Epoch 17/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.9608 - acc: 0.2516    \n",
      "Epoch 18/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.9460 - acc: 0.2576    \n",
      "Epoch 19/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.9394 - acc: 0.2633    \n",
      "Epoch 20/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.9382 - acc: 0.2629    \n",
      "Epoch 21/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.9147 - acc: 0.2629    \n",
      "Epoch 22/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.9194 - acc: 0.2682    \n",
      "Epoch 23/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.9115 - acc: 0.2746    \n",
      "Epoch 24/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.9013 - acc: 0.2752    \n",
      "Epoch 25/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.8971 - acc: 0.2782    \n",
      "Epoch 26/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.8815 - acc: 0.2809    \n",
      "Epoch 27/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.9087 - acc: 0.2718    \n",
      "Epoch 28/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.8662 - acc: 0.2879    \n",
      "Epoch 29/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.8814 - acc: 0.2754    \n",
      "Epoch 30/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.8642 - acc: 0.2855    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\AMALI\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\Users\\AMALI\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\Users\\AMALI\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.43      0.06      0.10       619\n",
      "          1       0.34      0.23      0.27       886\n",
      "          2       0.23      0.57      0.33       868\n",
      "          3       0.26      0.02      0.04       800\n",
      "          4       0.16      0.33      0.22       588\n",
      "          5       0.16      0.18      0.17       498\n",
      "          6       0.14      0.19      0.16       358\n",
      "          7       0.12      0.01      0.02       217\n",
      "          8       0.08      0.01      0.02       208\n",
      "          9       0.12      0.13      0.13       160\n",
      "         10       0.00      0.00      0.00       106\n",
      "         11       0.09      0.02      0.04        89\n",
      "         12       0.13      0.22      0.17        60\n",
      "         13       0.00      0.00      0.00        39\n",
      "         14       0.25      0.10      0.14        31\n",
      "         15       0.00      0.00      0.00        29\n",
      "         16       0.06      0.17      0.09        18\n",
      "         17       0.00      0.00      0.00        17\n",
      "         18       0.00      0.00      0.00        14\n",
      "         19       0.00      0.00      0.00         7\n",
      "         20       0.86      0.86      0.86        43\n",
      "\n",
      "avg / total       0.23      0.21      0.17      5655\n",
      "\n",
      "Precision:\t0.233\n",
      "Recall:  \t0.211\n",
      "F1 Score:\t0.173\n",
      "Accuracy:\t0.211\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.47      0.11      0.18       200\n",
      "          1       0.33      0.28      0.30       256\n",
      "          2       0.21      0.52      0.30       228\n",
      "          3       0.29      0.02      0.04       197\n",
      "          4       0.19      0.33      0.24       136\n",
      "          5       0.14      0.12      0.13        88\n",
      "          6       0.10      0.24      0.14        51\n",
      "          7       0.12      0.02      0.04        41\n",
      "          8       0.33      0.06      0.10        35\n",
      "          9       0.07      0.17      0.10        23\n",
      "         10       0.00      0.00      0.00        24\n",
      "         11       0.00      0.00      0.00        18\n",
      "         12       0.00      0.00      0.00        14\n",
      "         13       0.00      0.00      0.00         7\n",
      "         14       0.00      0.00      0.00        16\n",
      "         15       0.00      0.00      0.00        10\n",
      "         16       0.06      0.08      0.06        13\n",
      "         17       0.00      0.00      0.00         9\n",
      "         18       0.00      0.00      0.00         8\n",
      "         19       0.00      0.00      0.00         7\n",
      "         20       0.94      0.55      0.70        29\n",
      "\n",
      "avg / total       0.26      0.22      0.19      1410\n",
      "\n",
      "Precision:\t0.264\n",
      "Recall:  \t0.218\n",
      "F1 Score:\t0.191\n",
      "Accuracy:\t0.218\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_feats,train_err, epochs=30,batch_size=32)\n",
    "model.save('./my_model.h5', overwrite=True)\n",
    "\n",
    "report (test1_feats,test1_err,'test1.glass','err')\n",
    "report (test2_feats,test2_err,'test2.glass','err')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "#rms = sqrt(mean_squared_error(y_actual, y_predicted))\n",
    "\n",
    "def MAE (txt,glass,black,ref): \n",
    "    MAE_glass=mean_absolute_error(glass, ref)\n",
    "    MAE_black=mean_absolute_error(black, ref)\n",
    "\n",
    "    RMS_glass = sqrt(mean_squared_error(ref, glass))\n",
    "    RMS_black = sqrt(mean_squared_error(ref, black))\n",
    "    \n",
    "    print  ('MAE:', txt,  \"%.2f\" % MAE_glass,  \"%.2f\" % MAE_black)\n",
    "    print  ('RMSE:', txt,  \"%.2f\" % RMS_glass,  \"%.2f\" % RMS_black, '\\n')\n",
    "    \n",
    "\n",
    "def parse_results(onetwo):\n",
    "    one_two = str (onetwo)\n",
    "    print (\"Analysis for: \", one_two)\n",
    "    #wc per sentence\n",
    "    glass_file_wc = 'class.out.test'+one_two+'.glass.wc'\n",
    "    black_file_wc = 'class.out.test'+one_two+'.black.wc'\n",
    "    ref_file_wc   =  'test'+one_two+'.wc'\n",
    "\n",
    "    glass_np_wc = np.loadtxt(glass_file_wc,usecols=range(0,1),dtype='float32')+2\n",
    "    black_np_wc = np.loadtxt(black_file_wc,usecols=range(0,1),dtype='float32')+2\n",
    "    ref_np_wc   = np.loadtxt(ref_file_wc,usecols=range(0,1),dtype='float32')\n",
    "\n",
    "    MAE ('glass/black: WC :',glass_np_wc,black_np_wc,ref_np_wc)\n",
    "    \n",
    "    #err per sentence\n",
    "    \n",
    "\n",
    "    \n",
    "    MAE ('glass/black: ERR :',glass_np_err,black_np_err,ref_np_err)\n",
    "    \n",
    "\n",
    "    #wer per sentence\n",
    "    glass_np_wer=np.divide(glass_np_err,glass_np_wc)*100\n",
    "    black_np_wer=np.divide(black_np_err,black_np_wc)*100\n",
    "    ref_np_wer=np.divide(ref_np_err,ref_np_wc)*100\n",
    "\n",
    "    MAE ('glass/black: WER :',glass_np_wer,black_np_err,ref_np_wer)\n",
    "    \n",
    "    \n",
    "    #Overall WER\n",
    "    wer_ref   = np.sum(ref_np_err)/np.sum(ref_np_wc)*100\n",
    "    wer_glass = np.sum(glass_np_err)/np.sum(glass_np_wc)*100\n",
    "    wer_black = np.sum(black_np_err)/np.sum(black_np_wc)*100\n",
    "    print ('Overall WER: glass/black:', \"%.2f\" % wer_ref, \"%.2f\" % wer_glass, \"%.2f\" % wer_black)\n",
    "    print ('###########')\n",
    "\n",
    "    #dump WER for more analysis\n",
    "    np.savetxt('wer_ref.'+one_two, ref_np_wer,fmt='%.2f') \n",
    "    np.savetxt('wer_black.'+one_two, black_np_wer,fmt='%.2f') \n",
    "    np.savetxt('wer_glass.'+one_two, glass_np_wer,fmt='%.2f') \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature dimension:  14960\n",
      "Processing:  0\n",
      "Processing:  1000\n",
      "Processing:  2000\n",
      "Processing:  3000\n",
      "Processing:  4000\n",
      "Processing:  5000\n",
      "(5842, 14960)\n",
      "Processing:  0\n",
      "Processing:  1000\n",
      "Processing:  2000\n",
      "Processing:  3000\n",
      "Processing:  4000\n",
      "Processing:  5000\n",
      "(5655, 14960)\n",
      "Processing:  0\n",
      "Processing:  1000\n",
      "(1410, 14960)\n"
     ]
    }
   ],
   "source": [
    "##Process the black-box features:\n",
    "id, numerical, text, char, ref =load_file (train,'black')\n",
    "\n",
    "word_list, char_list = return_word_char_list (text, char)\n",
    "numerical_len=len(numerical[0].split())\n",
    "\n",
    "feat_len=(len(word_list+char_list)+numerical_len)\n",
    "print (\"Feature dimension: \", feat_len)\n",
    "\n",
    "\n",
    "\n",
    "train_feats = make_features (numerical, text, char, word_list, char_list )\n",
    "train_wc, train_err = get_wc_err (train,'train')\n",
    "\n",
    "\n",
    "\n",
    "id, numerical, text, char, ref =load_file (test1,'black')\n",
    "test1_feats = make_features (numerical, text, char, word_list, char_list )\n",
    "test1_wc, test1_err = get_wc_err (test1,'test1')\n",
    "\n",
    "\n",
    "id, numerical, text, char, ref =load_file (test2,'black')\n",
    "test2_feats = make_features (numerical, text, char, word_list, char_list )\n",
    "test2_wc, test2_err = get_wc_err (test2,'test2')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def dnn (feats,labels):\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_dim=feat_len))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(21, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#model.fit(feats, labels, epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "5842/5842 [==============================] - 38s - loss: 2.6431 - acc: 0.1511    \n",
      "Epoch 2/30\n",
      "5842/5842 [==============================] - 38s - loss: 2.2223 - acc: 0.2126    \n",
      "Epoch 3/30\n",
      "5842/5842 [==============================] - 37s - loss: 2.0167 - acc: 0.2629    \n",
      "Epoch 4/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.8991 - acc: 0.2996    \n",
      "Epoch 5/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.8048 - acc: 0.3242    \n",
      "Epoch 6/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.7305 - acc: 0.3521    \n",
      "Epoch 7/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.6347 - acc: 0.3925    \n",
      "Epoch 8/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.5627 - acc: 0.4249    \n",
      "Epoch 9/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.4861 - acc: 0.4575    \n",
      "Epoch 10/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.4062 - acc: 0.4964    \n",
      "Epoch 11/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.3353 - acc: 0.5216    \n",
      "Epoch 12/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.2545 - acc: 0.5555    \n",
      "Epoch 13/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.1870 - acc: 0.5753    \n",
      "Epoch 14/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.1106 - acc: 0.6116    \n",
      "Epoch 15/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.0413 - acc: 0.6327    \n",
      "Epoch 16/30\n",
      "5842/5842 [==============================] - 38s - loss: 0.9965 - acc: 0.6580    \n",
      "Epoch 17/30\n",
      "5842/5842 [==============================] - 38s - loss: 0.9119 - acc: 0.6845    \n",
      "Epoch 18/30\n",
      "5842/5842 [==============================] - 38s - loss: 0.8738 - acc: 0.7044    \n",
      "Epoch 19/30\n",
      "5842/5842 [==============================] - 38s - loss: 0.8208 - acc: 0.7229    \n",
      "Epoch 20/30\n",
      "5842/5842 [==============================] - 38s - loss: 0.7877 - acc: 0.7443    \n",
      "Epoch 21/30\n",
      "5842/5842 [==============================] - 38s - loss: 0.7280 - acc: 0.7628    \n",
      "Epoch 22/30\n",
      "5842/5842 [==============================] - 38s - loss: 0.6751 - acc: 0.7809    \n",
      "Epoch 23/30\n",
      "5842/5842 [==============================] - 38s - loss: 0.6544 - acc: 0.7843    \n",
      "Epoch 24/30\n",
      "5842/5842 [==============================] - 38s - loss: 0.6283 - acc: 0.7934    \n",
      "Epoch 25/30\n",
      "5842/5842 [==============================] - 38s - loss: 0.6011 - acc: 0.8050    \n",
      "Epoch 26/30\n",
      "5842/5842 [==============================] - 38s - loss: 0.5511 - acc: 0.8182    \n",
      "Epoch 27/30\n",
      "5842/5842 [==============================] - 38s - loss: 0.5451 - acc: 0.8242    \n",
      "Epoch 28/30\n",
      "5842/5842 [==============================] - 38s - loss: 0.5199 - acc: 0.8346    \n",
      "Epoch 29/30\n",
      "5842/5842 [==============================] - 38s - loss: 0.4920 - acc: 0.8435    \n",
      "Epoch 30/30\n",
      "5842/5842 [==============================] - 38s - loss: 0.4836 - acc: 0.8422    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\AMALI\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\Users\\AMALI\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "D:\\Users\\AMALI\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\Users\\AMALI\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "D:\\Users\\AMALI\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\Users\\AMALI\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.00      0.00      0.00        21\n",
      "          2       0.00      0.00      0.00        76\n",
      "          3       0.00      0.00      0.00       128\n",
      "          4       0.09      0.04      0.05       219\n",
      "          5       0.11      0.07      0.08       305\n",
      "          6       0.14      0.09      0.11       413\n",
      "          7       0.13      0.06      0.08       462\n",
      "          8       0.11      0.10      0.11       509\n",
      "          9       0.17      0.06      0.08       519\n",
      "         10       0.15      0.31      0.20       509\n",
      "         11       0.12      0.07      0.09       481\n",
      "         12       0.12      0.15      0.13       435\n",
      "         13       0.12      0.13      0.12       363\n",
      "         14       0.09      0.14      0.11       328\n",
      "         15       0.10      0.09      0.09       235\n",
      "         16       0.09      0.11      0.10       185\n",
      "         17       0.09      0.22      0.13       125\n",
      "         18       0.08      0.26      0.13        95\n",
      "         19       0.09      0.26      0.13        72\n",
      "         20       0.33      0.13      0.19       165\n",
      "         21       0.00      0.00      0.00         0\n",
      "         22       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.12      0.12      0.11      5655\n",
      "\n",
      "Precision:\t0.122\n",
      "Recall:  \t0.116\n",
      "F1 Score:\t0.107\n",
      "Accuracy:\t0.116\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         3\n",
      "          1       0.00      0.00      0.00         6\n",
      "          2       0.00      0.00      0.00         5\n",
      "          3       0.00      0.00      0.00        16\n",
      "          4       0.00      0.00      0.00        18\n",
      "          5       0.20      0.15      0.17        34\n",
      "          6       0.14      0.06      0.08        52\n",
      "          7       0.17      0.06      0.09        65\n",
      "          8       0.12      0.09      0.10        87\n",
      "          9       0.20      0.07      0.10       105\n",
      "         10       0.15      0.23      0.19       115\n",
      "         11       0.19      0.11      0.14       140\n",
      "         12       0.13      0.09      0.11       135\n",
      "         13       0.14      0.16      0.15       116\n",
      "         14       0.10      0.15      0.12        97\n",
      "         15       0.13      0.13      0.13        95\n",
      "         16       0.13      0.15      0.14        74\n",
      "         17       0.10      0.17      0.12        65\n",
      "         18       0.10      0.27      0.15        52\n",
      "         19       0.13      0.28      0.18        39\n",
      "         20       0.56      0.15      0.24        91\n",
      "         21       0.00      0.00      0.00         0\n",
      "         22       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.17      0.13      0.13      1410\n",
      "\n",
      "Precision:\t0.166\n",
      "Recall:  \t0.133\n",
      "F1 Score:\t0.132\n",
      "Accuracy:\t0.133\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_feats,train_wc, epochs=30,batch_size=32)\n",
    "model.save('./my_model.h5', overwrite=True)\n",
    "\n",
    "report (test1_feats,test1_wc,'test1.black','wc')\n",
    "report (test2_feats,test2_wc,'test2.black','wc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "5842/5842 [==============================] - 38s - loss: 3.1903 - acc: 0.1559    \n",
      "Epoch 2/30\n",
      "5842/5842 [==============================] - 38s - loss: 2.4076 - acc: 0.1801    \n",
      "Epoch 3/30\n",
      "5842/5842 [==============================] - 41s - loss: 2.2463 - acc: 0.1960    \n",
      "Epoch 4/30\n",
      "5842/5842 [==============================] - 39s - loss: 2.1657 - acc: 0.2010    \n",
      "Epoch 5/30\n",
      "5842/5842 [==============================] - 38s - loss: 2.1208 - acc: 0.2203    \n",
      "Epoch 6/30\n",
      "5842/5842 [==============================] - 38s - loss: 2.0983 - acc: 0.2095    \n",
      "Epoch 7/30\n",
      "5842/5842 [==============================] - 38s - loss: 2.0677 - acc: 0.2200    \n",
      "Epoch 8/30\n",
      "5842/5842 [==============================] - 38s - loss: 2.0460 - acc: 0.2402    \n",
      "Epoch 9/30\n",
      "5842/5842 [==============================] - 38s - loss: 2.0118 - acc: 0.2446    \n",
      "Epoch 10/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.9944 - acc: 0.2506    \n",
      "Epoch 11/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.9620 - acc: 0.2568    \n",
      "Epoch 12/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.9458 - acc: 0.2636    \n",
      "Epoch 13/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.9287 - acc: 0.2766    \n",
      "Epoch 14/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.8996 - acc: 0.2848    \n",
      "Epoch 15/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.8690 - acc: 0.2958    \n",
      "Epoch 16/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.8352 - acc: 0.2970    \n",
      "Epoch 17/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.8234 - acc: 0.3083    \n",
      "Epoch 18/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.8059 - acc: 0.3093    \n",
      "Epoch 19/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.7974 - acc: 0.3136    \n",
      "Epoch 20/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.7576 - acc: 0.3364    \n",
      "Epoch 21/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.7522 - acc: 0.3422    \n",
      "Epoch 22/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.7400 - acc: 0.3346    \n",
      "Epoch 23/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.7105 - acc: 0.3571    \n",
      "Epoch 24/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.7008 - acc: 0.3605    \n",
      "Epoch 25/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.6842 - acc: 0.3661    \n",
      "Epoch 26/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.6597 - acc: 0.3754    \n",
      "Epoch 27/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.6346 - acc: 0.3756    \n",
      "Epoch 28/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.6240 - acc: 0.3875    \n",
      "Epoch 29/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.5894 - acc: 0.3966    \n",
      "Epoch 30/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.5847 - acc: 0.3922    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\AMALI\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\Users\\AMALI\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\Users\\AMALI\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.33      0.10      0.16       619\n",
      "          1       0.27      0.14      0.18       886\n",
      "          2       0.21      0.26      0.24       868\n",
      "          3       0.20      0.23      0.21       800\n",
      "          4       0.15      0.32      0.20       588\n",
      "          5       0.13      0.04      0.07       498\n",
      "          6       0.11      0.22      0.15       358\n",
      "          7       0.09      0.05      0.06       217\n",
      "          8       0.14      0.06      0.09       208\n",
      "          9       0.12      0.16      0.14       160\n",
      "         10       0.00      0.00      0.00       106\n",
      "         11       0.14      0.26      0.18        89\n",
      "         12       0.17      0.03      0.06        60\n",
      "         13       0.02      0.03      0.02        39\n",
      "         14       0.07      0.10      0.08        31\n",
      "         15       0.00      0.00      0.00        29\n",
      "         16       0.08      0.44      0.13        18\n",
      "         17       0.18      0.18      0.18        17\n",
      "         18       0.17      0.14      0.15        14\n",
      "         19       0.00      0.00      0.00         7\n",
      "         20       0.93      0.58      0.71        43\n",
      "\n",
      "avg / total       0.20      0.18      0.17      5655\n",
      "\n",
      "Precision:\t0.198\n",
      "Recall:  \t0.178\n",
      "F1 Score:\t0.169\n",
      "Accuracy:\t0.178\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.21      0.10      0.14       200\n",
      "          1       0.28      0.20      0.23       256\n",
      "          2       0.17      0.19      0.18       228\n",
      "          3       0.17      0.16      0.16       197\n",
      "          4       0.15      0.30      0.20       136\n",
      "          5       0.10      0.03      0.05        88\n",
      "          6       0.06      0.18      0.09        51\n",
      "          7       0.05      0.02      0.03        41\n",
      "          8       0.18      0.09      0.12        35\n",
      "          9       0.06      0.13      0.08        23\n",
      "         10       0.00      0.00      0.00        24\n",
      "         11       0.12      0.33      0.17        18\n",
      "         12       0.25      0.07      0.11        14\n",
      "         13       0.07      0.14      0.10         7\n",
      "         14       0.12      0.12      0.12        16\n",
      "         15       0.00      0.00      0.00        10\n",
      "         16       0.17      0.54      0.26        13\n",
      "         17       0.20      0.22      0.21         9\n",
      "         18       0.00      0.00      0.00         8\n",
      "         19       0.12      0.14      0.13         7\n",
      "         20       1.00      0.55      0.71        29\n",
      "\n",
      "avg / total       0.19      0.17      0.17      1410\n",
      "\n",
      "Precision:\t0.192\n",
      "Recall:  \t0.171\n",
      "F1 Score:\t0.169\n",
      "Accuracy:\t0.171\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_feats,train_err, epochs=30,batch_size=32)\n",
    "model.save('./my_model.h5', overwrite=True)\n",
    "\n",
    "report (test1_feats,test1_err,'test1.black','err')\n",
    "report (test2_feats,test2_err,'test2.black','err')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis for:  1\n",
      "MAE: glass/black: WC : 1.69 2.21\n",
      "RMSE: glass/black: WC : 2.12 2.69 \n",
      "\n",
      "MAE: glass/black: ERR : 1.61 1.87\n",
      "RMSE: glass/black: ERR : 2.21 2.49 \n",
      "\n",
      "MAE: glass/black: WER : 13.85 28.08\n",
      "RMSE: glass/black: WER : 18.27 35.76 \n",
      "\n",
      "Overall WER: glass/black: 33.03 27.84 31.63\n",
      "###########\n",
      "\n",
      "\n",
      "Analysis for:  2\n",
      "MAE: glass/black: WC : 1.65 2.18\n",
      "RMSE: glass/black: WC : 2.09 2.70 \n",
      "\n",
      "MAE: glass/black: ERR : 1.73 2.05\n",
      "RMSE: glass/black: ERR : 2.42 2.78 \n",
      "\n",
      "MAE: glass/black: WER : 12.72 24.32\n",
      "RMSE: glass/black: WER : 17.04 34.56 \n",
      "\n",
      "Overall WER: glass/black: 28.51 24.80 29.32\n",
      "###########\n"
     ]
    }
   ],
   "source": [
    "#summary\n",
    "parse_results (1)\n",
    "print ('\\n')\n",
    "parse_results (2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
