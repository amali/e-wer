{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#load lib\n",
    "import numpy as np\n",
    "import re, sys, glob\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from keras.preprocessing import text\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk import ngrams\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.models import load_model\n",
    "import math\n",
    "import scipy\n",
    "_EPOCHS=50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "\n",
    "'''\n",
    "Features order in the data look like this \n",
    "print STDOUT \"S:\".$uttranceInfo{\"id\"}.\"\\t\".$wordcount.\" \".$graphemecount.\" \".$uttranceInfo{\"total_frames\"}.\n",
    "      \" \".$uttranceInfo{\"avg_loglike\"}.\" \".$uttranceInfo{\"total_AMloglike\"}.\" \".\n",
    "\t  $uttranceInfo{\"total_LMloglike\"}.\" \".$uttranceInfo{\"duration\"}.\" \".\n",
    "\t  $uttranceInfo{\"GER\"}.\"\\t\".$uttranceInfo{\"sentence\"}.\"\\t\".$uttranceInfo{\"grapheme\"}.\n",
    "\t  \"\\t\".$uttranceInfo{\"WER\"}.\"\\n\";\n",
    "'''\n",
    "\n",
    "train=\"data/dev.mgb2/wer.feats\"\n",
    "test1=\"data/eval.mgb2/wer.feats\"\n",
    "test2=\"data/summa_test20170317/wer.feats\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file (file,type='glass'):\n",
    "    f=open(file,\"r\")\n",
    "    lines=f.readlines()\n",
    "    _id=[]\n",
    "    _text=[]\n",
    "    _numerical=[]\n",
    "    _char=[]\n",
    "    _ref=[]\n",
    "    for x in lines:\n",
    "        _id.append(x.split('\\t')[0])\n",
    "        _text.append(x.split('\\t')[2])\n",
    "        _char.append(x.split('\\t')[3])\n",
    "        _ref.append(x.split('\\t')[4])\n",
    "        if type == 'glass': \n",
    "            _numerical.append(x.split('\\t')[1])\n",
    "        else:\n",
    "            blac_box_numerical=x.split('\\t')[1].split(' ')\n",
    "            numerical2=' '.join(blac_box_numerical[0:2]+blac_box_numerical[6:])\n",
    "            _numerical.append(numerical2)\n",
    "        \n",
    "    f.close()\n",
    "    return _id, _numerical, _text, _char, _ref\n",
    "\n",
    "def word_grams(words, min=1, max=4):\n",
    "    s = []\n",
    "    for n in range(min, max):\n",
    "        for ngram in ngrams(words, n):\n",
    "            s.append(' '.join(str(i) for i in ngram))\n",
    "    return s\n",
    "\n",
    "def return_word_char_list (_text,_char):\n",
    "    _unigram_word_list = [] \n",
    "    _trigram_char_list = []\n",
    "    for i,j in enumerate(_char):\n",
    "        \n",
    "        _char_3gram = word_grams (_char[i].split(),1,3)\n",
    "        for tri in _char_3gram: \n",
    "             if tri not in _trigram_char_list: _trigram_char_list.append(tri)\n",
    "    \n",
    "        _words_1gram = word_grams (_text[i].split(),1,2)\n",
    "        for uni in _words_1gram: \n",
    "             if uni not in _unigram_word_list: _unigram_word_list.append(uni)\n",
    "    return _unigram_word_list, _trigram_char_list \n",
    "                    \n",
    "def vectorize (words,chars,word_list,char_list):\n",
    "    feature_vector = []\n",
    "    index=0\n",
    "    \n",
    "    temp_words = [0] * len(word_list)\n",
    "    for word in word_grams (words.split(),1,2): \n",
    "        for index, word2 in enumerate(word_list): \n",
    "            if word == word2:\n",
    "                #print (index, word2)\n",
    "                temp_words[index]+=1\n",
    "                break\n",
    "    \n",
    "    temp_chars = [0] * len(char_list)\n",
    "    for _char in word_grams (chars.split(),1,3): \n",
    "        for index, _char2 in enumerate(char_list): \n",
    "            if _char == _char2:\n",
    "                #print (index, _char2)\n",
    "                temp_chars[index]+=1\n",
    "                break            \n",
    "    return temp_words+temp_chars\n",
    "\n",
    "def make_features (numerical, text, char, word_list, char_list ):\n",
    "    allfeats= []\n",
    "    for i, _id in enumerate (text):\n",
    "        feat = vectorize (text[i],char[i],word_list,char_list)\n",
    "        allfeats.append (numerical[i].split()+feat)\n",
    "        if i % 1000 == 0: print (\"Processing: \", i)\n",
    "    nn=np.array(allfeats)\n",
    "    #nn_minmax = preprocessing.scale(nn)\n",
    "       \n",
    "    print (nn.shape)\n",
    "    return (nn)\n",
    "    \n",
    "def get_wc_err (file,dump):\n",
    "    print (\"Processing: \", file)\n",
    "    f=open(file,\"r\")\n",
    "    lines=f.readlines()\n",
    "    _wc=[]\n",
    "    _err=[]\n",
    "    _real_wc =[]\n",
    "    _real_err =[]\n",
    "    for x in lines:\n",
    "        err = int(x.split('\\t')[4].split(' ')[1])\n",
    "        wc  = int(x.split('\\t')[4].split(' ')[2])\n",
    "        _real_wc.append (wc)    \n",
    "        _real_err.append (err)\n",
    "        \n",
    "        if wc > 20: wc =20\n",
    "        if err > 20: err =20\n",
    "        wc = wc - 1 # for whatever reason keras like to start counting from zer\n",
    "        \n",
    "        _wc.append (wc)    \n",
    "        _err.append (err)\n",
    "    \n",
    "    unique, counts = np.unique(_wc, return_counts=True)\n",
    "    print (\"wc:unique: \",unique)\n",
    "    print (\"wc:counts: \",counts)\n",
    "    \n",
    "    unique, counts = np.unique(_err, return_counts=True)\n",
    "    print (\"err:unique: \",unique)\n",
    "    print (\"err:counts: \",counts)\n",
    "    \n",
    "    one_hot_labels_wc = to_categorical(np.array(_wc), num_classes=20)\n",
    "    one_hot_labels_err = to_categorical(np.array(_err), num_classes=21)\n",
    "        \n",
    "    np.savetxt(dump+'.err', np.array(_real_err), fmt='%d')\n",
    "    np.savetxt(dump+'.wc', np.array(_real_wc), fmt='%d')\n",
    "    \n",
    "    print (one_hot_labels_wc.shape,one_hot_labels_err.shape)\n",
    "    return one_hot_labels_wc, one_hot_labels_err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "    \n",
    "\n",
    "def report (test_vec,test_labels,test,ext):\n",
    "    \n",
    "    prob_out='prob.out.'+test+'.'+ext\n",
    "    pred_out='pred.out.'+test+'.'+ext\n",
    "    class_out='class.out.'+test+'.'+ext\n",
    "    \n",
    "    _shift=0\n",
    "    if ext == \"wc\" : _shift=2\n",
    "    #load models\n",
    "    model = load_model('./my_model.h5')\n",
    "    \n",
    "    #save predictions\n",
    "    pred = model.predict(test_vec)\n",
    "    np.savetxt(pred_out, pred, delimiter=' ')    \n",
    "    \n",
    "    prob = np.copy(pred)\n",
    "    i=0\n",
    "    for row in prob: \n",
    "      raw = [sigmoid(i) for i in row]\n",
    "      norm = [float(i)/sum(raw) for i in raw]\n",
    "      prob[int(i)]=norm\n",
    "      i=i+1\n",
    "    \n",
    "    #save prob\n",
    "    np.savetxt(prob_out, prob, delimiter=' ',fmt='%f') \n",
    "    \n",
    "    \n",
    "    test_classes = np.argmax(prob, axis=1)+_shift\n",
    "    #save classes\n",
    "    np.savetxt(class_out, test_classes, delimiter=' ',fmt='%d')\n",
    "    \n",
    "\n",
    "    test_labels = np.argmax(test_labels, axis=1) # to remove the Keras to_categorical\n",
    "    \n",
    "    \n",
    "\n",
    "    #print confusion matrix \n",
    "    confusion_matrix(test_labels, test_classes)\n",
    "\n",
    "    #print classification report\n",
    "    print(classification_report(test_labels, test_classes))\n",
    "\n",
    "\n",
    "    #print prec, recall and f1\n",
    "    print (\"Precision:\\t{:0.3f}\".format(precision_score(test_labels, test_classes,average='weighted')))\n",
    "    print (\"Recall:  \\t{:0.3f}\".format(recall_score(test_labels, test_classes,average='weighted')))\n",
    "    print (\"F1 Score:\\t{:0.3f}\".format(f1_score(test_labels, test_classes,average='weighted')))\n",
    "    print (\"Accuracy:\\t{:0.3f}\".format(accuracy_score(test_labels, test_classes)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature dimension:  14964\n",
      "Processing:  0\n",
      "Processing:  1000\n",
      "Processing:  2000\n",
      "Processing:  3000\n",
      "Processing:  4000\n",
      "Processing:  5000\n",
      "(5842, 14964)\n",
      "Processing:  data/dev.mgb2/wer.feats\n",
      "wc:unique:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "wc:counts:  [  2   7  33 101 166 237 326 372 459 455 446 454 429 390 362 283 290 228\n",
      " 184 618]\n",
      "err:unique:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "err:counts:  [661 776 740 612 565 438 333 265 228 193 127 138 123  90  77  70  73  50\n",
      "  43  34 206]\n",
      "(5842, 20) (5842, 21)\n",
      "Processing:  0\n",
      "Processing:  1000\n",
      "Processing:  2000\n",
      "Processing:  3000\n",
      "Processing:  4000\n",
      "Processing:  5000\n",
      "(5655, 14964)\n",
      "Processing:  data/eval.mgb2/wer.feats\n",
      "wc:unique:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "wc:counts:  [  1   9  21  76 128 219 305 413 462 509 519 509 481 435 363 328 235 185\n",
      " 125 332]\n",
      "err:unique:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "err:counts:  [619 886 868 800 588 498 358 217 208 160 106  89  60  39  31  29  18  17\n",
      "  14   7  43]\n",
      "(5655, 20) (5655, 21)\n",
      "Processing:  0\n",
      "Processing:  1000\n",
      "(1410, 14964)\n",
      "Processing:  data/summa_test20170317/wer.feats\n",
      "wc:unique:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "wc:counts:  [  1   2   6   5  16  18  34  52  65  87 105 115 140 135 116  97  95  74\n",
      "  65 182]\n",
      "err:unique:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "err:counts:  [200 256 228 197 136  88  51  41  35  23  24  18  14   7  16  10  13   9\n",
      "   8   7  29]\n",
      "(1410, 20) (1410, 21)\n"
     ]
    }
   ],
   "source": [
    "id, numerical, text, char, ref =load_file (train,'glass')\n",
    "\n",
    "word_list, char_list = return_word_char_list (text, char)\n",
    "numerical_len=len(numerical[0].split())\n",
    "\n",
    "feat_len=(len(word_list+char_list)+numerical_len)\n",
    "print (\"Feature dimension: \", feat_len)\n",
    "\n",
    "\n",
    "\n",
    "train_feats = make_features (numerical, text, char, word_list, char_list )\n",
    "train_wc, train_err = get_wc_err (train,'train')\n",
    "\n",
    "\n",
    "\n",
    "id, numerical, text, char, ref =load_file (test1,'glass')\n",
    "test1_feats = make_features (numerical, text, char, word_list, char_list )\n",
    "test1_wc, test1_err = get_wc_err (test1,'test1')\n",
    "\n",
    "\n",
    "id, numerical, text, char, ref =load_file (test2,'glass')\n",
    "test2_feats = make_features (numerical, text, char, word_list, char_list )\n",
    "test2_wc, test2_err = get_wc_err (test2,'test2')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5842/5842 [==============================] - 77s - loss: 2.9640 - acc: 0.1275    \n",
      "Epoch 2/50\n",
      "5842/5842 [==============================] - 57s - loss: 2.5190 - acc: 0.1618    \n",
      "Epoch 3/50\n",
      "5842/5842 [==============================] - 62s - loss: 2.3495 - acc: 0.1953    \n",
      "Epoch 4/50\n",
      "5842/5842 [==============================] - 56s - loss: 2.2295 - acc: 0.2129    \n",
      "Epoch 5/50\n",
      "5842/5842 [==============================] - 49s - loss: 2.1296 - acc: 0.2289    \n",
      "Epoch 6/50\n",
      "5842/5842 [==============================] - 49s - loss: 2.0563 - acc: 0.2393    \n",
      "Epoch 7/50\n",
      "5842/5842 [==============================] - 43s - loss: 1.9967 - acc: 0.2641    \n",
      "Epoch 8/50\n",
      "5842/5842 [==============================] - 42s - loss: 1.9570 - acc: 0.2645    \n",
      "Epoch 9/50\n",
      "5842/5842 [==============================] - 52s - loss: 1.8958 - acc: 0.2814    \n",
      "Epoch 10/50\n",
      "5842/5842 [==============================] - 47s - loss: 1.8929 - acc: 0.2843    \n",
      "Epoch 11/50\n",
      "5842/5842 [==============================] - 45s - loss: 1.8535 - acc: 0.2850    \n",
      "Epoch 12/50\n",
      "5842/5842 [==============================] - 41s - loss: 1.8431 - acc: 0.3028    \n",
      "Epoch 13/50\n",
      "5842/5842 [==============================] - 42s - loss: 1.8034 - acc: 0.3059    \n",
      "Epoch 14/50\n",
      "5842/5842 [==============================] - 43s - loss: 1.7749 - acc: 0.3126    \n",
      "Epoch 15/50\n",
      "5842/5842 [==============================] - 44s - loss: 1.7648 - acc: 0.3196    \n",
      "Epoch 16/50\n",
      "5842/5842 [==============================] - 43s - loss: 1.7422 - acc: 0.3249    \n",
      "Epoch 17/50\n",
      "5842/5842 [==============================] - 42s - loss: 1.7177 - acc: 0.3216    \n",
      "Epoch 18/50\n",
      "5842/5842 [==============================] - 42s - loss: 1.7107 - acc: 0.3398    \n",
      "Epoch 19/50\n",
      "5842/5842 [==============================] - 43s - loss: 1.6856 - acc: 0.3357    \n",
      "Epoch 20/50\n",
      "5842/5842 [==============================] - 46s - loss: 1.6741 - acc: 0.3441    \n",
      "Epoch 21/50\n",
      "5842/5842 [==============================] - 52s - loss: 1.6621 - acc: 0.3480    \n",
      "Epoch 22/50\n",
      "5842/5842 [==============================] - 52s - loss: 1.6497 - acc: 0.3622    \n",
      "Epoch 23/50\n",
      "5842/5842 [==============================] - 56s - loss: 1.6206 - acc: 0.3613    \n",
      "Epoch 24/50\n",
      "5842/5842 [==============================] - 49s - loss: 1.6371 - acc: 0.3696    \n",
      "Epoch 25/50\n",
      "5842/5842 [==============================] - 45s - loss: 1.6115 - acc: 0.3754    \n",
      "Epoch 26/50\n",
      "5842/5842 [==============================] - 48s - loss: 1.5976 - acc: 0.3805    \n",
      "Epoch 27/50\n",
      "5842/5842 [==============================] - 49s - loss: 1.5757 - acc: 0.3966    \n",
      "Epoch 28/50\n",
      "5842/5842 [==============================] - 50s - loss: 1.5641 - acc: 0.3956    \n",
      "Epoch 29/50\n",
      "5842/5842 [==============================] - 41s - loss: 1.5638 - acc: 0.3928    \n",
      "Epoch 30/50\n",
      "5842/5842 [==============================] - 41s - loss: 1.5427 - acc: 0.4004    \n",
      "Epoch 31/50\n",
      "5842/5842 [==============================] - 49s - loss: 1.5323 - acc: 0.4096    \n",
      "Epoch 32/50\n",
      "5842/5842 [==============================] - 56s - loss: 1.5189 - acc: 0.4178    \n",
      "Epoch 33/50\n",
      "5842/5842 [==============================] - 56s - loss: 1.5189 - acc: 0.4151    \n",
      "Epoch 34/50\n",
      "5842/5842 [==============================] - 63s - loss: 1.5027 - acc: 0.4149    \n",
      "Epoch 35/50\n",
      "5842/5842 [==============================] - 46s - loss: 1.4919 - acc: 0.4122    \n",
      "Epoch 36/50\n",
      "5842/5842 [==============================] - 43s - loss: 1.4959 - acc: 0.4207    \n",
      "Epoch 37/50\n",
      "5842/5842 [==============================] - 45s - loss: 1.4732 - acc: 0.4399    \n",
      "Epoch 38/50\n",
      "5842/5842 [==============================] - 42s - loss: 1.4651 - acc: 0.4492    \n",
      "Epoch 39/50\n",
      "5842/5842 [==============================] - 42s - loss: 1.4420 - acc: 0.4478    \n",
      "Epoch 40/50\n",
      "5842/5842 [==============================] - 45s - loss: 1.4541 - acc: 0.4368    \n",
      "Epoch 41/50\n",
      "5842/5842 [==============================] - 49s - loss: 1.4375 - acc: 0.4521    \n",
      "Epoch 42/50\n",
      "5842/5842 [==============================] - 47s - loss: 1.4158 - acc: 0.4647    \n",
      "Epoch 43/50\n",
      "5842/5842 [==============================] - 53s - loss: 1.4285 - acc: 0.4564    \n",
      "Epoch 44/50\n",
      "5842/5842 [==============================] - 71s - loss: 1.4088 - acc: 0.4647    \n",
      "Epoch 45/50\n",
      "5842/5842 [==============================] - 59s - loss: 1.3978 - acc: 0.4728    \n",
      "Epoch 46/50\n",
      "5842/5842 [==============================] - 61s - loss: 1.3863 - acc: 0.4745    \n",
      "Epoch 47/50\n",
      "5842/5842 [==============================] - 57s - loss: 1.3586 - acc: 0.4872    \n",
      "Epoch 48/50\n",
      "5842/5842 [==============================] - 50s - loss: 1.3583 - acc: 0.4882    \n",
      "Epoch 49/50\n",
      "5842/5842 [==============================] - 46s - loss: 1.3691 - acc: 0.4892    \n",
      "Epoch 50/50\n",
      "5842/5842 [==============================] - 45s - loss: 1.3460 - acc: 0.4981    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         1\n",
      "          1       0.00      0.00      0.00         9\n",
      "          2       0.00      0.00      0.00        21\n",
      "          3       0.00      0.00      0.00        76\n",
      "          4       0.06      0.01      0.01       128\n",
      "          5       0.02      0.00      0.01       219\n",
      "          6       0.01      0.00      0.01       305\n",
      "          7       0.05      0.02      0.03       413\n",
      "          8       0.03      0.02      0.02       462\n",
      "          9       0.06      0.02      0.03       509\n",
      "         10       0.05      0.09      0.07       519\n",
      "         11       0.08      0.09      0.09       509\n",
      "         12       0.06      0.03      0.04       481\n",
      "         13       0.06      0.09      0.07       435\n",
      "         14       0.06      0.02      0.03       363\n",
      "         15       0.04      0.09      0.06       328\n",
      "         16       0.03      0.03      0.03       235\n",
      "         17       0.05      0.10      0.07       185\n",
      "         18       0.02      0.01      0.01       125\n",
      "         19       0.04      0.02      0.02       332\n",
      "         20       0.00      0.00      0.00         0\n",
      "         21       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.05      0.04      0.04      5655\n",
      "\n",
      "Precision:\t0.048\n",
      "Recall:  \t0.043\n",
      "F1 Score:\t0.041\n",
      "Accuracy:\t0.043\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         1\n",
      "          1       0.00      0.00      0.00         2\n",
      "          2       0.00      0.00      0.00         6\n",
      "          3       0.00      0.00      0.00         5\n",
      "          4       0.17      0.06      0.09        16\n",
      "          5       0.00      0.00      0.00        18\n",
      "          6       0.22      0.06      0.09        34\n",
      "          7       0.00      0.00      0.00        52\n",
      "          8       0.10      0.03      0.05        65\n",
      "          9       0.04      0.01      0.02        87\n",
      "         10       0.06      0.06      0.06       105\n",
      "         11       0.06      0.04      0.05       115\n",
      "         12       0.05      0.02      0.03       140\n",
      "         13       0.09      0.10      0.10       135\n",
      "         14       0.07      0.03      0.04       116\n",
      "         15       0.04      0.08      0.06        97\n",
      "         16       0.06      0.06      0.06        95\n",
      "         17       0.10      0.16      0.12        74\n",
      "         18       0.08      0.02      0.03        65\n",
      "         19       0.10      0.05      0.07       182\n",
      "         20       0.00      0.00      0.00         0\n",
      "         21       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.07      0.05      0.05      1410\n",
      "\n",
      "Precision:\t0.070\n",
      "Recall:  \t0.052\n",
      "F1 Score:\t0.054\n",
      "Accuracy:\t0.052\n"
     ]
    }
   ],
   "source": [
    "#def dnn (feats,labels):\n",
    "#estimate glass-box word count (make sure to add one to your estimation)\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_dim=feat_len))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(20, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_feats,train_wc, epochs=_EPOCHS,batch_size=32)\n",
    "model.save('./my_model.h5', overwrite=True)\n",
    "\n",
    "report (test1_feats,test1_wc,'test1.glass','wc')\n",
    "report (test2_feats,test2_wc,'test2.glass','wc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5842/5842 [==============================] - 58s - loss: 2.7997 - acc: 0.1498    \n",
      "Epoch 2/50\n",
      "5842/5842 [==============================] - 48s - loss: 2.3674 - acc: 0.1879    \n",
      "Epoch 3/50\n",
      "5842/5842 [==============================] - 41s - loss: 2.2580 - acc: 0.1926    \n",
      "Epoch 4/50\n",
      "5842/5842 [==============================] - 42s - loss: 2.1873 - acc: 0.2138    \n",
      "Epoch 5/50\n",
      "5842/5842 [==============================] - 42s - loss: 2.1386 - acc: 0.2224    \n",
      "Epoch 6/50\n",
      "5842/5842 [==============================] - 42s - loss: 2.1115 - acc: 0.2379    \n",
      "Epoch 7/50\n",
      "5842/5842 [==============================] - 43s - loss: 2.0702 - acc: 0.2424    \n",
      "Epoch 8/50\n",
      "5842/5842 [==============================] - 41s - loss: 2.0474 - acc: 0.2424    \n",
      "Epoch 9/50\n",
      "5842/5842 [==============================] - 41s - loss: 2.0216 - acc: 0.2523    \n",
      "Epoch 10/50\n",
      "5842/5842 [==============================] - 41s - loss: 2.0031 - acc: 0.2552    \n",
      "Epoch 11/50\n",
      "5842/5842 [==============================] - 41s - loss: 1.9818 - acc: 0.2545    \n",
      "Epoch 12/50\n",
      "5842/5842 [==============================] - 42s - loss: 1.9586 - acc: 0.2675    \n",
      "Epoch 13/50\n",
      "5842/5842 [==============================] - 41s - loss: 1.9399 - acc: 0.2674    \n",
      "Epoch 14/50\n",
      "5842/5842 [==============================] - 42s - loss: 1.9366 - acc: 0.2722    \n",
      "Epoch 15/50\n",
      "5842/5842 [==============================] - 42s - loss: 1.9253 - acc: 0.2869    \n",
      "Epoch 16/50\n",
      "5842/5842 [==============================] - 41s - loss: 1.8900 - acc: 0.2903    \n",
      "Epoch 17/50\n",
      "5842/5842 [==============================] - 41s - loss: 1.8886 - acc: 0.2848    \n",
      "Epoch 18/50\n",
      "5842/5842 [==============================] - 42s - loss: 1.8683 - acc: 0.2990    \n",
      "Epoch 19/50\n",
      "5842/5842 [==============================] - 42s - loss: 1.8497 - acc: 0.3037    \n",
      "Epoch 20/50\n",
      "5842/5842 [==============================] - 42s - loss: 1.8455 - acc: 0.3067    \n",
      "Epoch 21/50\n",
      "5842/5842 [==============================] - 42s - loss: 1.8426 - acc: 0.3079    \n",
      "Epoch 22/50\n",
      "5842/5842 [==============================] - 43s - loss: 1.8130 - acc: 0.3196    \n",
      "Epoch 23/50\n",
      "5842/5842 [==============================] - 42s - loss: 1.8089 - acc: 0.3139    \n",
      "Epoch 24/50\n",
      "5842/5842 [==============================] - 41s - loss: 1.7888 - acc: 0.3247    \n",
      "Epoch 25/50\n",
      "5842/5842 [==============================] - 42s - loss: 1.7637 - acc: 0.3367    \n",
      "Epoch 26/50\n",
      "5842/5842 [==============================] - 41s - loss: 1.7706 - acc: 0.3297    \n",
      "Epoch 27/50\n",
      "5842/5842 [==============================] - 42s - loss: 1.7680 - acc: 0.3463    \n",
      "Epoch 28/50\n",
      "5842/5842 [==============================] - 43s - loss: 1.7201 - acc: 0.3516    \n",
      "Epoch 29/50\n",
      "5842/5842 [==============================] - 44s - loss: 1.7214 - acc: 0.3509    \n",
      "Epoch 30/50\n",
      "5842/5842 [==============================] - 42s - loss: 1.7057 - acc: 0.3576    \n",
      "Epoch 31/50\n",
      "5842/5842 [==============================] - 42s - loss: 1.6899 - acc: 0.3726    \n",
      "Epoch 32/50\n",
      "5842/5842 [==============================] - 43s - loss: 1.6779 - acc: 0.3732    \n",
      "Epoch 33/50\n",
      "5842/5842 [==============================] - 42s - loss: 1.6774 - acc: 0.3701    \n",
      "Epoch 34/50\n",
      "5842/5842 [==============================] - 42s - loss: 1.6550 - acc: 0.3903    \n",
      "Epoch 35/50\n",
      "5842/5842 [==============================] - 43s - loss: 1.6618 - acc: 0.3881    \n",
      "Epoch 36/50\n",
      "5842/5842 [==============================] - 42s - loss: 1.6320 - acc: 0.3959    \n",
      "Epoch 37/50\n",
      "5842/5842 [==============================] - 42s - loss: 1.6133 - acc: 0.4071    \n",
      "Epoch 38/50\n",
      "5842/5842 [==============================] - 42s - loss: 1.5915 - acc: 0.4059    \n",
      "Epoch 39/50\n",
      "5842/5842 [==============================] - 42s - loss: 1.5983 - acc: 0.4165    \n",
      "Epoch 40/50\n",
      "5842/5842 [==============================] - 42s - loss: 1.5751 - acc: 0.4156    \n",
      "Epoch 41/50\n",
      "5842/5842 [==============================] - 44s - loss: 1.5612 - acc: 0.4242    \n",
      "Epoch 42/50\n",
      "5842/5842 [==============================] - 42s - loss: 1.5492 - acc: 0.4278    \n",
      "Epoch 43/50\n",
      "5842/5842 [==============================] - 41s - loss: 1.5326 - acc: 0.4425    \n",
      "Epoch 44/50\n",
      "5842/5842 [==============================] - 43s - loss: 1.5295 - acc: 0.4421    \n",
      "Epoch 45/50\n",
      "5842/5842 [==============================] - 42s - loss: 1.5006 - acc: 0.4519    \n",
      "Epoch 46/50\n",
      "5842/5842 [==============================] - 43s - loss: 1.5062 - acc: 0.4533    \n",
      "Epoch 47/50\n",
      "5842/5842 [==============================] - 42s - loss: 1.4945 - acc: 0.4481    \n",
      "Epoch 48/50\n",
      "5842/5842 [==============================] - 44s - loss: 1.5003 - acc: 0.4533    \n",
      "Epoch 49/50\n",
      "5842/5842 [==============================] - 42s - loss: 1.4652 - acc: 0.4718    \n",
      "Epoch 50/50\n",
      "5842/5842 [==============================] - 43s - loss: 1.4590 - acc: 0.4620    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.52      0.09      0.15       619\n",
      "          1       0.34      0.14      0.20       886\n",
      "          2       0.21      0.30      0.25       868\n",
      "          3       0.21      0.05      0.08       800\n",
      "          4       0.15      0.59      0.24       588\n",
      "          5       0.18      0.07      0.10       498\n",
      "          6       0.17      0.16      0.17       358\n",
      "          7       0.13      0.23      0.16       217\n",
      "          8       0.17      0.04      0.07       208\n",
      "          9       0.14      0.13      0.13       160\n",
      "         10       0.18      0.03      0.05       106\n",
      "         11       0.16      0.15      0.15        89\n",
      "         12       0.10      0.25      0.15        60\n",
      "         13       0.38      0.08      0.13        39\n",
      "         14       0.00      0.00      0.00        31\n",
      "         15       0.00      0.00      0.00        29\n",
      "         16       0.10      0.28      0.15        18\n",
      "         17       0.09      0.06      0.07        17\n",
      "         18       0.00      0.00      0.00        14\n",
      "         19       0.00      0.00      0.00         7\n",
      "         20       0.63      0.86      0.73        43\n",
      "\n",
      "avg / total       0.24      0.19      0.17      5655\n",
      "\n",
      "Precision:\t0.244\n",
      "Recall:  \t0.189\n",
      "F1 Score:\t0.165\n",
      "Accuracy:\t0.189\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.44      0.10      0.16       200\n",
      "          1       0.30      0.14      0.19       256\n",
      "          2       0.22      0.40      0.29       228\n",
      "          3       0.17      0.04      0.07       197\n",
      "          4       0.15      0.46      0.22       136\n",
      "          5       0.06      0.02      0.03        88\n",
      "          6       0.06      0.12      0.08        51\n",
      "          7       0.11      0.20      0.14        41\n",
      "          8       0.00      0.00      0.00        35\n",
      "          9       0.09      0.13      0.10        23\n",
      "         10       0.00      0.00      0.00        24\n",
      "         11       0.11      0.06      0.07        18\n",
      "         12       0.13      0.43      0.20        14\n",
      "         13       0.14      0.14      0.14         7\n",
      "         14       0.00      0.00      0.00        16\n",
      "         15       0.00      0.00      0.00        10\n",
      "         16       0.28      0.38      0.32        13\n",
      "         17       0.00      0.00      0.00         9\n",
      "         18       0.00      0.00      0.00         8\n",
      "         19       0.00      0.00      0.00         7\n",
      "         20       0.79      0.76      0.77        29\n",
      "\n",
      "avg / total       0.22      0.19      0.17      1410\n",
      "\n",
      "Precision:\t0.224\n",
      "Recall:  \t0.192\n",
      "F1 Score:\t0.167\n",
      "Accuracy:\t0.192\n"
     ]
    }
   ],
   "source": [
    "#def dnn (feats,labels):\n",
    "#estimate glass-box error count\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_dim=feat_len))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(21, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_feats,train_err, epochs=_EPOCHS,batch_size=32)\n",
    "model.save('./my_model.h5', overwrite=True)\n",
    "\n",
    "report (test1_feats,test1_err,'test1.glass','err')\n",
    "report (test2_feats,test2_err,'test2.glass','err')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "def MAE (txt,glass,black,ref): \n",
    "    MAE_glass=mean_absolute_error(glass, ref)\n",
    "    MAE_black=mean_absolute_error(black, ref)\n",
    "\n",
    "    RMS_glass = sqrt(mean_squared_error(ref, glass))\n",
    "    RMS_black = sqrt(mean_squared_error(ref, black))\n",
    "    \n",
    "    personWER_glass = scipy.stats.pearsonr(glass, ref)\n",
    "    personWER_black = scipy.stats.pearsonr(black, ref)\n",
    "    \n",
    "    print  ('MAE:', txt,  \"%.2f\" % MAE_glass,  \"%.2f\" % MAE_black)\n",
    "    print  ('RMSE:', txt,  \"%.2f\" % RMS_glass,  \"%.2f\" % RMS_black, '\\n')\n",
    "    print ('Person Correlation:', txt, \"%.2f\" % personWER_glass[0], \"%.2f\" % personWER_black[0])\n",
    "    \n",
    "\n",
    "def parse_results(onetwo):\n",
    "    one_two = str (onetwo)\n",
    "    print (\"Analysis for: \", one_two)\n",
    "    #wc per sentence\n",
    "    glass_file_wc = 'class.out.test'+one_two+'.glass.wc'\n",
    "    black_file_wc = 'class.out.test'+one_two+'.black.wc'\n",
    "    ref_file_wc   =  'test'+one_two+'.wc'\n",
    "\n",
    "    glass_np_wc = np.loadtxt(glass_file_wc,usecols=range(0,1),dtype='float32')+1\n",
    "    black_np_wc = np.loadtxt(black_file_wc,usecols=range(0,1),dtype='float32')+1\n",
    "    ref_np_wc   = np.loadtxt(ref_file_wc,usecols=range(0,1),dtype='float32')\n",
    "\n",
    "    MAE ('glass/black: WC :',glass_np_wc,black_np_wc,ref_np_wc)\n",
    "    \n",
    "\n",
    "    #err per sentence\n",
    "    glass_file_err = 'class.out.test'+one_two+'.glass.err'\n",
    "    black_file_err = 'class.out.test'+one_two+'.black.err'\n",
    "    ref_file_err   = 'test'+one_two+'.err'\n",
    "\n",
    "    glass_np_err = np.loadtxt(glass_file_err,usecols=range(0,1),dtype='float32')\n",
    "    black_np_err = np.loadtxt(black_file_err,usecols=range(0,1),dtype='float32')\n",
    "    ref_np_err   = np.loadtxt(ref_file_err,usecols=range(0,1),dtype='float32')\n",
    "\n",
    "\n",
    "    \n",
    "    MAE ('glass/black: ERR :',glass_np_err,black_np_err,ref_np_err)\n",
    "    \n",
    "\n",
    "    #wer per sentence\n",
    "    glass_np_wer=np.divide(glass_np_err,glass_np_wc)*100\n",
    "    black_np_wer=np.divide(black_np_err,black_np_wc)*100\n",
    "    ref_np_wer=np.divide(ref_np_err,ref_np_wc)*100\n",
    "\n",
    "    MAE ('glass/black: WER :',glass_np_wer,black_np_err,ref_np_wer)\n",
    "    \n",
    "    \n",
    "    #Overall WER\n",
    "    wer_ref   = np.sum(ref_np_err)/np.sum(ref_np_wc)*100\n",
    "    wer_glass = np.sum(glass_np_err)/np.sum(glass_np_wc)*100\n",
    "    wer_black = np.sum(black_np_err)/np.sum(black_np_wc)*100\n",
    "    print ('Overall WER: glass/black:', \"%.2f\" % wer_ref, \"%.2f\" % wer_glass, \"%.2f\" % wer_black)\n",
    "    print ('###########')\n",
    "\n",
    "    #dump WER for more analysis\n",
    "    np.savetxt('wer_ref.'+one_two, ref_np_wer,fmt='%.2f') \n",
    "    np.savetxt('wer_black.'+one_two, black_np_wer,fmt='%.2f') \n",
    "    np.savetxt('wer_glass.'+one_two, glass_np_wer,fmt='%.2f') \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature dimension:  14960\n",
      "Processing:  0\n",
      "Processing:  1000\n",
      "Processing:  2000\n",
      "Processing:  3000\n",
      "Processing:  4000\n",
      "Processing:  5000\n",
      "(5842, 14960)\n",
      "Processing:  data/dev.mgb2/wer.feats\n",
      "wc:unique:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "wc:counts:  [  2   7  33 101 166 237 326 372 459 455 446 454 429 390 362 283 290 228\n",
      " 184 618]\n",
      "err:unique:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "err:counts:  [661 776 740 612 565 438 333 265 228 193 127 138 123  90  77  70  73  50\n",
      "  43  34 206]\n",
      "(5842, 20) (5842, 21)\n",
      "Processing:  0\n",
      "Processing:  1000\n",
      "Processing:  2000\n",
      "Processing:  3000\n",
      "Processing:  4000\n",
      "Processing:  5000\n",
      "(5655, 14960)\n",
      "Processing:  data/eval.mgb2/wer.feats\n",
      "wc:unique:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "wc:counts:  [  1   9  21  76 128 219 305 413 462 509 519 509 481 435 363 328 235 185\n",
      " 125 332]\n",
      "err:unique:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "err:counts:  [619 886 868 800 588 498 358 217 208 160 106  89  60  39  31  29  18  17\n",
      "  14   7  43]\n",
      "(5655, 20) (5655, 21)\n",
      "Processing:  0\n",
      "Processing:  1000\n",
      "(1410, 14960)\n",
      "Processing:  data/summa_test20170317/wer.feats\n",
      "wc:unique:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "wc:counts:  [  1   2   6   5  16  18  34  52  65  87 105 115 140 135 116  97  95  74\n",
      "  65 182]\n",
      "err:unique:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "err:counts:  [200 256 228 197 136  88  51  41  35  23  24  18  14   7  16  10  13   9\n",
      "   8   7  29]\n",
      "(1410, 20) (1410, 21)\n"
     ]
    }
   ],
   "source": [
    "##Process the black-box features:\n",
    "id, numerical, text, char, ref =load_file (train,'black')\n",
    "\n",
    "word_list, char_list = return_word_char_list (text, char)\n",
    "numerical_len=len(numerical[0].split())\n",
    "\n",
    "feat_len=(len(word_list+char_list)+numerical_len)\n",
    "print (\"Feature dimension: \", feat_len)\n",
    "\n",
    "\n",
    "\n",
    "train_feats = make_features (numerical, text, char, word_list, char_list )\n",
    "train_wc, train_err = get_wc_err (train,'train')\n",
    "\n",
    "\n",
    "\n",
    "id, numerical, text, char, ref =load_file (test1,'black')\n",
    "test1_feats = make_features (numerical, text, char, word_list, char_list )\n",
    "test1_wc, test1_err = get_wc_err (test1,'test1')\n",
    "\n",
    "\n",
    "id, numerical, text, char, ref =load_file (test2,'black')\n",
    "test2_feats = make_features (numerical, text, char, word_list, char_list )\n",
    "test2_wc, test2_err = get_wc_err (test2,'test2')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5842/5842 [==============================] - 58s - loss: 2.5935 - acc: 0.1679    \n",
      "Epoch 2/50\n",
      "5842/5842 [==============================] - 42s - loss: 2.1472 - acc: 0.2412    \n",
      "Epoch 3/50\n",
      "5842/5842 [==============================] - 40s - loss: 1.9480 - acc: 0.2845    \n",
      "Epoch 4/50\n",
      "5842/5842 [==============================] - 40s - loss: 1.8373 - acc: 0.3073    \n",
      "Epoch 5/50\n",
      "5842/5842 [==============================] - 41s - loss: 1.7319 - acc: 0.3468    \n",
      "Epoch 6/50\n",
      "5842/5842 [==============================] - 41s - loss: 1.6501 - acc: 0.3733    \n",
      "Epoch 7/50\n",
      "5842/5842 [==============================] - 41s - loss: 1.5681 - acc: 0.3990    \n",
      "Epoch 8/50\n",
      "5842/5842 [==============================] - 41s - loss: 1.4958 - acc: 0.4399    \n",
      "Epoch 9/50\n",
      "5842/5842 [==============================] - 41s - loss: 1.4224 - acc: 0.4743    \n",
      "Epoch 10/50\n",
      "5842/5842 [==============================] - 42s - loss: 1.3517 - acc: 0.5118    \n",
      "Epoch 11/50\n",
      "5842/5842 [==============================] - 41s - loss: 1.2734 - acc: 0.5382    \n",
      "Epoch 12/50\n",
      "5842/5842 [==============================] - 40s - loss: 1.2033 - acc: 0.5704    \n",
      "Epoch 13/50\n",
      "5842/5842 [==============================] - 41s - loss: 1.1378 - acc: 0.5924    \n",
      "Epoch 14/50\n",
      "5842/5842 [==============================] - 42s - loss: 1.0616 - acc: 0.6309    \n",
      "Epoch 15/50\n",
      "5842/5842 [==============================] - 41s - loss: 1.0068 - acc: 0.6481    \n",
      "Epoch 16/50\n",
      "5842/5842 [==============================] - 41s - loss: 0.9284 - acc: 0.6767    \n",
      "Epoch 17/50\n",
      "5842/5842 [==============================] - 41s - loss: 0.8585 - acc: 0.7145    \n",
      "Epoch 18/50\n",
      "5842/5842 [==============================] - 41s - loss: 0.8202 - acc: 0.7194    \n",
      "Epoch 19/50\n",
      "5842/5842 [==============================] - 41s - loss: 0.7574 - acc: 0.7460    \n",
      "Epoch 20/50\n",
      "5842/5842 [==============================] - 42s - loss: 0.7245 - acc: 0.7552    \n",
      "Epoch 21/50\n",
      "5842/5842 [==============================] - 42s - loss: 0.6773 - acc: 0.7824    \n",
      "Epoch 22/50\n",
      "5842/5842 [==============================] - 42s - loss: 0.6309 - acc: 0.7970    \n",
      "Epoch 23/50\n",
      "5842/5842 [==============================] - 43s - loss: 0.6146 - acc: 0.7972    \n",
      "Epoch 24/50\n",
      "5842/5842 [==============================] - 41s - loss: 0.5586 - acc: 0.8201    \n",
      "Epoch 25/50\n",
      "5842/5842 [==============================] - 42s - loss: 0.5269 - acc: 0.8312    \n",
      "Epoch 26/50\n",
      "5842/5842 [==============================] - 42s - loss: 0.5136 - acc: 0.8331    \n",
      "Epoch 27/50\n",
      "5842/5842 [==============================] - 51s - loss: 0.4851 - acc: 0.8449    \n",
      "Epoch 28/50\n",
      "5842/5842 [==============================] - 47s - loss: 0.4536 - acc: 0.8530    \n",
      "Epoch 29/50\n",
      "5842/5842 [==============================] - 47s - loss: 0.4343 - acc: 0.8613    \n",
      "Epoch 30/50\n",
      "5842/5842 [==============================] - 44s - loss: 0.4347 - acc: 0.8610    \n",
      "Epoch 31/50\n",
      "5842/5842 [==============================] - 45s - loss: 0.4028 - acc: 0.8713    \n",
      "Epoch 32/50\n",
      "5842/5842 [==============================] - 43s - loss: 0.4086 - acc: 0.8704    \n",
      "Epoch 33/50\n",
      "5842/5842 [==============================] - 43s - loss: 0.3742 - acc: 0.8827    \n",
      "Epoch 34/50\n",
      "5842/5842 [==============================] - 43s - loss: 0.3836 - acc: 0.8810    \n",
      "Epoch 35/50\n",
      "5842/5842 [==============================] - 42s - loss: 0.3584 - acc: 0.8886    \n",
      "Epoch 36/50\n",
      "5842/5842 [==============================] - 42s - loss: 0.3460 - acc: 0.8889    \n",
      "Epoch 37/50\n",
      "5842/5842 [==============================] - 43s - loss: 0.3417 - acc: 0.8983    \n",
      "Epoch 38/50\n",
      "5842/5842 [==============================] - 42s - loss: 0.3240 - acc: 0.9048    \n",
      "Epoch 39/50\n",
      "5842/5842 [==============================] - 42s - loss: 0.3328 - acc: 0.9004    \n",
      "Epoch 40/50\n",
      "5842/5842 [==============================] - 42s - loss: 0.3116 - acc: 0.9048    \n",
      "Epoch 41/50\n",
      "5842/5842 [==============================] - 43s - loss: 0.2924 - acc: 0.9103    \n",
      "Epoch 42/50\n",
      "5842/5842 [==============================] - 42s - loss: 0.2944 - acc: 0.9067    \n",
      "Epoch 43/50\n",
      "5842/5842 [==============================] - 42s - loss: 0.2929 - acc: 0.9146    \n",
      "Epoch 44/50\n",
      "5842/5842 [==============================] - 42s - loss: 0.2873 - acc: 0.9139    \n",
      "Epoch 45/50\n",
      "5842/5842 [==============================] - 43s - loss: 0.2903 - acc: 0.9156    \n",
      "Epoch 46/50\n",
      "5842/5842 [==============================] - 42s - loss: 0.2766 - acc: 0.9161    \n",
      "Epoch 47/50\n",
      "5842/5842 [==============================] - 42s - loss: 0.2702 - acc: 0.9170    \n",
      "Epoch 48/50\n",
      "5842/5842 [==============================] - 43s - loss: 0.2640 - acc: 0.9185    \n",
      "Epoch 49/50\n",
      "5842/5842 [==============================] - 42s - loss: 0.2510 - acc: 0.9237    \n",
      "Epoch 50/50\n",
      "5842/5842 [==============================] - 44s - loss: 0.2488 - acc: 0.9276    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         1\n",
      "          1       0.00      0.00      0.00         9\n",
      "          2       0.00      0.00      0.00        21\n",
      "          3       0.00      0.00      0.00        76\n",
      "          4       0.04      0.01      0.01       128\n",
      "          5       0.16      0.03      0.05       219\n",
      "          6       0.15      0.12      0.14       305\n",
      "          7       0.14      0.03      0.04       413\n",
      "          8       0.16      0.15      0.15       462\n",
      "          9       0.14      0.12      0.13       509\n",
      "         10       0.13      0.10      0.11       519\n",
      "         11       0.16      0.13      0.14       509\n",
      "         12       0.09      0.07      0.08       481\n",
      "         13       0.10      0.15      0.12       435\n",
      "         14       0.11      0.09      0.10       363\n",
      "         15       0.07      0.12      0.09       328\n",
      "         16       0.06      0.04      0.05       235\n",
      "         17       0.04      0.08      0.05       185\n",
      "         18       0.06      0.24      0.10       125\n",
      "         19       0.10      0.06      0.08       332\n",
      "         20       0.00      0.00      0.00         0\n",
      "         21       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.12      0.10      0.10      5655\n",
      "\n",
      "Precision:\t0.116\n",
      "Recall:  \t0.097\n",
      "F1 Score:\t0.099\n",
      "Accuracy:\t0.097\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         1\n",
      "          1       0.00      0.00      0.00         2\n",
      "          2       0.00      0.00      0.00         6\n",
      "          3       0.00      0.00      0.00         5\n",
      "          4       0.22      0.12      0.16        16\n",
      "          5       0.00      0.00      0.00        18\n",
      "          6       0.26      0.29      0.27        34\n",
      "          7       0.17      0.02      0.03        52\n",
      "          8       0.12      0.08      0.10        65\n",
      "          9       0.10      0.06      0.07        87\n",
      "         10       0.13      0.07      0.09       105\n",
      "         11       0.12      0.07      0.09       115\n",
      "         12       0.07      0.04      0.05       140\n",
      "         13       0.11      0.10      0.11       135\n",
      "         14       0.04      0.03      0.03       116\n",
      "         15       0.08      0.10      0.09        97\n",
      "         16       0.07      0.04      0.05        95\n",
      "         17       0.07      0.11      0.08        74\n",
      "         18       0.10      0.37      0.16        65\n",
      "         19       0.25      0.10      0.14       182\n",
      "         20       0.00      0.00      0.00         0\n",
      "         21       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.12      0.09      0.09      1410\n",
      "\n",
      "Precision:\t0.119\n",
      "Recall:  \t0.089\n",
      "F1 Score:\t0.090\n",
      "Accuracy:\t0.089\n"
     ]
    }
   ],
   "source": [
    "#def dnn (feats,labels):\n",
    "#estimate glass-box word count (make sure to add one to your estimation)\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_dim=feat_len))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(20, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_feats,train_wc, epochs=_EPOCHS,batch_size=32)\n",
    "model.save('./my_model.h5', overwrite=True)\n",
    "\n",
    "report (test1_feats,test1_wc,'test1.black','wc')\n",
    "report (test2_feats,test2_wc,'test2.black','wc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5842/5842 [==============================] - 55s - loss: 2.5923 - acc: 0.1556    \n",
      "Epoch 2/50\n",
      "5842/5842 [==============================] - 41s - loss: 2.2768 - acc: 0.1982    \n",
      "Epoch 3/50\n",
      "5842/5842 [==============================] - 41s - loss: 2.1464 - acc: 0.2333    \n",
      "Epoch 4/50\n",
      "5842/5842 [==============================] - 41s - loss: 2.0539 - acc: 0.2573    \n",
      "Epoch 5/50\n",
      "5842/5842 [==============================] - 43s - loss: 1.9636 - acc: 0.2963    \n",
      "Epoch 6/50\n",
      "5842/5842 [==============================] - 42s - loss: 1.8794 - acc: 0.3247    \n",
      "Epoch 7/50\n",
      "5842/5842 [==============================] - 42s - loss: 1.7854 - acc: 0.3596    \n",
      "Epoch 8/50\n",
      "5842/5842 [==============================] - 41s - loss: 1.6903 - acc: 0.4000    \n",
      "Epoch 9/50\n",
      "5842/5842 [==============================] - 42s - loss: 1.6092 - acc: 0.4305    \n",
      "Epoch 10/50\n",
      "5842/5842 [==============================] - 42s - loss: 1.5192 - acc: 0.4658    \n",
      "Epoch 11/50\n",
      "5842/5842 [==============================] - 42s - loss: 1.4172 - acc: 0.5089    \n",
      "Epoch 12/50\n",
      "5842/5842 [==============================] - 42s - loss: 1.3435 - acc: 0.5322    \n",
      "Epoch 13/50\n",
      "5842/5842 [==============================] - 43s - loss: 1.2553 - acc: 0.5779    \n",
      "Epoch 14/50\n",
      "5842/5842 [==============================] - 42s - loss: 1.1768 - acc: 0.5914    \n",
      "Epoch 15/50\n",
      "5842/5842 [==============================] - 42s - loss: 1.0991 - acc: 0.6202    \n",
      "Epoch 16/50\n",
      "5842/5842 [==============================] - 42s - loss: 1.0276 - acc: 0.6465    \n",
      "Epoch 17/50\n",
      "5842/5842 [==============================] - 42s - loss: 0.9648 - acc: 0.6741    \n",
      "Epoch 18/50\n",
      "5842/5842 [==============================] - 42s - loss: 0.9052 - acc: 0.6919    \n",
      "Epoch 19/50\n",
      "5842/5842 [==============================] - 42s - loss: 0.8472 - acc: 0.7124    \n",
      "Epoch 20/50\n",
      "5842/5842 [==============================] - 43s - loss: 0.8080 - acc: 0.7326    \n",
      "Epoch 21/50\n",
      "5842/5842 [==============================] - 43s - loss: 0.7577 - acc: 0.7480    \n",
      "Epoch 22/50\n",
      "5842/5842 [==============================] - 42s - loss: 0.7109 - acc: 0.7640    \n",
      "Epoch 23/50\n",
      "5842/5842 [==============================] - 42s - loss: 0.6658 - acc: 0.7737    \n",
      "Epoch 24/50\n",
      "5842/5842 [==============================] - 42s - loss: 0.6524 - acc: 0.7824    \n",
      "Epoch 25/50\n",
      "5842/5842 [==============================] - 42s - loss: 0.6204 - acc: 0.7958    \n",
      "Epoch 26/50\n",
      "5842/5842 [==============================] - 43s - loss: 0.5762 - acc: 0.8109    \n",
      "Epoch 27/50\n",
      "5842/5842 [==============================] - 42s - loss: 0.5594 - acc: 0.8194    \n",
      "Epoch 28/50\n",
      "5842/5842 [==============================] - 42s - loss: 0.5348 - acc: 0.8252    \n",
      "Epoch 29/50\n",
      "5842/5842 [==============================] - 42s - loss: 0.5117 - acc: 0.8357    \n",
      "Epoch 30/50\n",
      "5842/5842 [==============================] - 42s - loss: 0.4976 - acc: 0.8357    \n",
      "Epoch 31/50\n",
      "5842/5842 [==============================] - 42s - loss: 0.4702 - acc: 0.8485    \n",
      "Epoch 32/50\n",
      "5842/5842 [==============================] - 42s - loss: 0.4533 - acc: 0.8514    \n",
      "Epoch 33/50\n",
      "5842/5842 [==============================] - 42s - loss: 0.4390 - acc: 0.8536    \n",
      "Epoch 34/50\n",
      "5842/5842 [==============================] - 43s - loss: 0.4163 - acc: 0.8646    \n",
      "Epoch 35/50\n",
      "5842/5842 [==============================] - 42s - loss: 0.4051 - acc: 0.8653    \n",
      "Epoch 36/50\n",
      "5842/5842 [==============================] - 42s - loss: 0.4005 - acc: 0.8744    \n",
      "Epoch 37/50\n",
      "5842/5842 [==============================] - 42s - loss: 0.3874 - acc: 0.8761    \n",
      "Epoch 38/50\n",
      "5842/5842 [==============================] - 43s - loss: 0.3795 - acc: 0.8809    \n",
      "Epoch 39/50\n",
      "5842/5842 [==============================] - 42s - loss: 0.3621 - acc: 0.8798    \n",
      "Epoch 40/50\n",
      "5842/5842 [==============================] - 43s - loss: 0.3666 - acc: 0.8863    \n",
      "Epoch 41/50\n",
      "5842/5842 [==============================] - 43s - loss: 0.3711 - acc: 0.8822    \n",
      "Epoch 42/50\n",
      "5842/5842 [==============================] - 43s - loss: 0.3301 - acc: 0.8930    \n",
      "Epoch 43/50\n",
      "5842/5842 [==============================] - 42s - loss: 0.3321 - acc: 0.8973    \n",
      "Epoch 44/50\n",
      "5842/5842 [==============================] - 42s - loss: 0.3340 - acc: 0.8928    \n",
      "Epoch 45/50\n",
      "5842/5842 [==============================] - 42s - loss: 0.3314 - acc: 0.8973    \n",
      "Epoch 46/50\n",
      "5842/5842 [==============================] - 42s - loss: 0.3133 - acc: 0.9004    \n",
      "Epoch 47/50\n",
      "5842/5842 [==============================] - 42s - loss: 0.3073 - acc: 0.9036    \n",
      "Epoch 48/50\n",
      "5842/5842 [==============================] - 42s - loss: 0.2994 - acc: 0.9053    \n",
      "Epoch 49/50\n",
      "5842/5842 [==============================] - 43s - loss: 0.3007 - acc: 0.9004    \n",
      "Epoch 50/50\n",
      "5842/5842 [==============================] - 42s - loss: 0.2854 - acc: 0.9094    \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.29      0.19      0.23       619\n",
      "          1       0.25      0.22      0.24       886\n",
      "          2       0.19      0.12      0.15       868\n",
      "          3       0.17      0.24      0.20       800\n",
      "          4       0.13      0.20      0.16       588\n",
      "          5       0.14      0.13      0.14       498\n",
      "          6       0.10      0.08      0.09       358\n",
      "          7       0.07      0.07      0.07       217\n",
      "          8       0.08      0.11      0.09       208\n",
      "          9       0.12      0.11      0.12       160\n",
      "         10       0.07      0.07      0.07       106\n",
      "         11       0.11      0.11      0.11        89\n",
      "         12       0.11      0.10      0.10        60\n",
      "         13       0.00      0.00      0.00        39\n",
      "         14       0.12      0.03      0.05        31\n",
      "         15       0.05      0.07      0.06        29\n",
      "         16       0.05      0.22      0.09        18\n",
      "         17       0.22      0.12      0.15        17\n",
      "         18       0.00      0.00      0.00        14\n",
      "         19       0.00      0.00      0.00         7\n",
      "         20       0.74      0.81      0.78        43\n",
      "\n",
      "avg / total       0.18      0.17      0.17      5655\n",
      "\n",
      "Precision:\t0.176\n",
      "Recall:  \t0.168\n",
      "F1 Score:\t0.168\n",
      "Accuracy:\t0.168\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.19      0.14      0.16       200\n",
      "          1       0.25      0.22      0.24       256\n",
      "          2       0.16      0.12      0.14       228\n",
      "          3       0.18      0.20      0.19       197\n",
      "          4       0.15      0.17      0.16       136\n",
      "          5       0.09      0.10      0.10        88\n",
      "          6       0.06      0.06      0.06        51\n",
      "          7       0.04      0.05      0.05        41\n",
      "          8       0.09      0.23      0.13        35\n",
      "          9       0.04      0.09      0.06        23\n",
      "         10       0.27      0.38      0.32        24\n",
      "         11       0.00      0.00      0.00        18\n",
      "         12       0.10      0.14      0.12        14\n",
      "         13       0.17      0.14      0.15         7\n",
      "         14       0.00      0.00      0.00        16\n",
      "         15       0.07      0.20      0.11        10\n",
      "         16       0.16      0.23      0.19        13\n",
      "         17       0.14      0.11      0.12         9\n",
      "         18       0.00      0.00      0.00         8\n",
      "         19       0.08      0.14      0.11         7\n",
      "         20       0.74      0.69      0.71        29\n",
      "\n",
      "avg / total       0.18      0.17      0.17      1410\n",
      "\n",
      "Precision:\t0.176\n",
      "Recall:  \t0.167\n",
      "F1 Score:\t0.169\n",
      "Accuracy:\t0.167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#def dnn (feats,labels):\n",
    "#estimate black-box error count\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_dim=feat_len))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(21, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_feats,train_err, epochs=_EPOCHS,batch_size=32)\n",
    "model.save('./my_model.h5', overwrite=True)\n",
    "\n",
    "report (test1_feats,test1_err,'test1.black','err')\n",
    "report (test2_feats,test2_err,'test2.black','err')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis for:  1\n",
      "MAE: glass/black: WC : 2.67 2.51\n",
      "RMSE: glass/black: WC : 3.08 3.06 \n",
      "\n",
      "Person Correlation: glass/black: WC : 0.91 0.88\n",
      "MAE: glass/black: ERR : 1.71 2.12\n",
      "RMSE: glass/black: ERR : 2.27 2.82 \n",
      "\n",
      "Person Correlation: glass/black: ERR : 0.82 0.72\n",
      "MAE: glass/black: WER : 13.70 28.24\n",
      "RMSE: glass/black: WER : 17.76 35.94 \n",
      "\n",
      "Person Correlation: glass/black: WER : 0.70 0.55\n",
      "Overall WER: glass/black: 33.03 30.32 29.80\n",
      "###########\n",
      "\n",
      "\n",
      "Analysis for:  2\n",
      "MAE: glass/black: WC : 2.55 2.67\n",
      "RMSE: glass/black: WC : 3.00 3.25 \n",
      "\n",
      "Person Correlation: glass/black: WC : 0.89 0.84\n",
      "MAE: glass/black: ERR : 1.82 2.31\n",
      "RMSE: glass/black: ERR : 2.43 3.11 \n",
      "\n",
      "Person Correlation: glass/black: ERR : 0.86 0.78\n",
      "MAE: glass/black: WER : 12.73 24.31\n",
      "RMSE: glass/black: WER : 17.05 34.55 \n",
      "\n",
      "Person Correlation: glass/black: WER : 0.80 0.66\n",
      "Overall WER: glass/black: 28.51 26.45 28.65\n",
      "###########\n"
     ]
    }
   ],
   "source": [
    "#summary\n",
    "parse_results (1)\n",
    "print ('\\n')\n",
    "parse_results (2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
