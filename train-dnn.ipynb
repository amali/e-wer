{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#load lib\n",
    "import numpy as np\n",
    "import re, sys, glob\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from keras.preprocessing import text\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk import ngrams\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.models import load_model\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load data\n",
    "\n",
    "'''\n",
    "Features order in the data look like this \n",
    "print STDOUT \"S:\".$uttranceInfo{\"id\"}.\"\\t\".$wordcount.\" \".$graphemecount.\" \".$uttranceInfo{\"total_frames\"}.\n",
    "      \" \".$uttranceInfo{\"avg_loglike\"}.\" \".$uttranceInfo{\"total_AMloglike\"}.\" \".\n",
    "\t  $uttranceInfo{\"total_LMloglike\"}.\" \".$uttranceInfo{\"duration\"}.\" \".\n",
    "\t  $uttranceInfo{\"GER\"}.\"\\t\".$uttranceInfo{\"sentence\"}.\"\\t\".$uttranceInfo{\"grapheme\"}.\n",
    "\t  \"\\t\".$uttranceInfo{\"WER\"}.\"\\n\";\n",
    "'''\n",
    "\n",
    "train=\"data/dev.mgb2/wer.feats\"\n",
    "test1=\"data/eval.mgb2/wer.feats\"\n",
    "test2=\"data/summa_test20170317/wer.feats\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_file (file,type='glass'):\n",
    "    f=open(file,\"r\")\n",
    "    lines=f.readlines()\n",
    "    _id=[]\n",
    "    _text=[]\n",
    "    _numerical=[]\n",
    "    _char=[]\n",
    "    _ref=[]\n",
    "    for x in lines:\n",
    "        _id.append(x.split('\\t')[0])\n",
    "        _text.append(x.split('\\t')[2])\n",
    "        _char.append(x.split('\\t')[3])\n",
    "        _ref.append(x.split('\\t')[4])\n",
    "        if type == 'glass': \n",
    "            _numerical.append(x.split('\\t')[1])\n",
    "        else:\n",
    "            blac_box_numerical=x.split('\\t')[1].split(' ')\n",
    "            numerical2=' '.join(blac_box_numerical[0:2]+blac_box_numerical[6:])\n",
    "            _numerical.append(numerical2)\n",
    "        \n",
    "    f.close()\n",
    "    return _id, _numerical, _text, _char, _ref\n",
    "\n",
    "def word_grams(words, min=1, max=4):\n",
    "    s = []\n",
    "    for n in range(min, max):\n",
    "        for ngram in ngrams(words, n):\n",
    "            s.append(' '.join(str(i) for i in ngram))\n",
    "    return s\n",
    "\n",
    "def return_word_char_list (_text,_char):\n",
    "    _unigram_word_list = [] \n",
    "    _trigram_char_list = []\n",
    "    for i,j in enumerate(_char):\n",
    "        \n",
    "        _char_3gram = word_grams (_char[i].split(),1,3)\n",
    "        for tri in _char_3gram: \n",
    "             if tri not in _trigram_char_list: _trigram_char_list.append(tri)\n",
    "    \n",
    "        _words_1gram = word_grams (_text[i].split(),1,2)\n",
    "        for uni in _words_1gram: \n",
    "             if uni not in _unigram_word_list: _unigram_word_list.append(uni)\n",
    "    return _unigram_word_list, _trigram_char_list \n",
    "                    \n",
    "def vectorize (words,chars,word_list,char_list):\n",
    "    feature_vector = []\n",
    "    index=0\n",
    "    \n",
    "    temp_words = [0] * len(word_list)\n",
    "    for word in word_grams (words.split(),1,2): \n",
    "        for index, word2 in enumerate(word_list): \n",
    "            if word == word2:\n",
    "                #print (index, word2)\n",
    "                temp_words[index]+=1\n",
    "                break\n",
    "    \n",
    "    temp_chars = [0] * len(char_list)\n",
    "    for _char in word_grams (chars.split(),1,3): \n",
    "        for index, _char2 in enumerate(char_list): \n",
    "            if _char == _char2:\n",
    "                #print (index, _char2)\n",
    "                temp_chars[index]+=1\n",
    "                break            \n",
    "    return temp_words+temp_chars\n",
    "\n",
    "def make_features (numerical, text, char, word_list, char_list ):\n",
    "    allfeats= []\n",
    "    for i, _id in enumerate (text):\n",
    "        feat = vectorize (text[i],char[i],word_list,char_list)\n",
    "        allfeats.append (numerical[i].split()+feat)\n",
    "        if i % 1000 == 0: print (\"Processing: \", i)\n",
    "    nn=np.array(allfeats)\n",
    "    #nn_minmax = preprocessing.scale(nn)\n",
    "       \n",
    "    print (nn.shape)\n",
    "    return (nn)\n",
    "    \n",
    "def get_wc_err (file,dump):\n",
    "    print (\"Processing: \", file)\n",
    "    f=open(file,\"r\")\n",
    "    lines=f.readlines()\n",
    "    _wc=[]\n",
    "    _err=[]\n",
    "    _real_wc =[]\n",
    "    _real_err =[]\n",
    "    for x in lines:\n",
    "        err = int(x.split('\\t')[4].split(' ')[1])\n",
    "        wc  = int(x.split('\\t')[4].split(' ')[2])\n",
    "        _real_wc.append (wc)    \n",
    "        _real_err.append (err)\n",
    "        \n",
    "        if wc > 20: wc =20\n",
    "        if err > 20: err =20\n",
    "        wc = wc - 1 # for whatever reason keras like to start counting from zer\n",
    "        \n",
    "        _wc.append (wc)    \n",
    "        _err.append (err)\n",
    "    \n",
    "    unique, counts = np.unique(_wc, return_counts=True)\n",
    "    print (\"wc:unique: \",unique)\n",
    "    print (\"wc:counts: \",counts)\n",
    "    \n",
    "    unique, counts = np.unique(_err, return_counts=True)\n",
    "    print (\"err:unique: \",unique)\n",
    "    print (\"err:counts: \",counts)\n",
    "    \n",
    "    one_hot_labels_wc = to_categorical(np.array(_wc), num_classes=20)\n",
    "    one_hot_labels_err = to_categorical(np.array(_err), num_classes=21)\n",
    "        \n",
    "    np.savetxt(dump+'.err', np.array(_real_err), fmt='%d')\n",
    "    np.savetxt(dump+'.wc', np.array(_real_wc), fmt='%d')\n",
    "    \n",
    "    print (one_hot_labels_wc.shape,one_hot_labels_err.shape)\n",
    "    return one_hot_labels_wc, one_hot_labels_err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "    \n",
    "\n",
    "def report (test_vec,test_labels,test,ext):\n",
    "    \n",
    "    prob_out='prob.out.'+test+'.'+ext\n",
    "    pred_out='pred.out.'+test+'.'+ext\n",
    "    class_out='class.out.'+test+'.'+ext\n",
    "    \n",
    "    _shift=0\n",
    "    if ext == \"wc\" : _shift=2\n",
    "    #load models\n",
    "    model = load_model('./my_model.h5')\n",
    "    \n",
    "    #save predictions\n",
    "    pred = model.predict(test_vec)\n",
    "    np.savetxt(pred_out, pred, delimiter=' ')    \n",
    "    \n",
    "    prob = np.copy(pred)\n",
    "    i=0\n",
    "    for row in prob: \n",
    "      raw = [sigmoid(i) for i in row]\n",
    "      norm = [float(i)/sum(raw) for i in raw]\n",
    "      prob[int(i)]=norm\n",
    "      i=i+1\n",
    "    \n",
    "    #save prob\n",
    "    np.savetxt(prob_out, prob, delimiter=' ',fmt='%f') \n",
    "    \n",
    "    \n",
    "    test_classes = np.argmax(prob, axis=1)+_shift\n",
    "    #save classes\n",
    "    np.savetxt(class_out, test_classes, delimiter=' ',fmt='%d')\n",
    "    \n",
    "\n",
    "    test_labels = np.argmax(test_labels, axis=1) # to remove the Keras to_categorical\n",
    "    \n",
    "    \n",
    "\n",
    "    #print confusion matrix \n",
    "    confusion_matrix(test_labels, test_classes)\n",
    "\n",
    "    #print classification report\n",
    "    print(classification_report(test_labels, test_classes))\n",
    "\n",
    "\n",
    "    #print prec, recall and f1\n",
    "    print (\"Precision:\\t{:0.3f}\".format(precision_score(test_labels, test_classes,average='weighted')))\n",
    "    print (\"Recall:  \\t{:0.3f}\".format(recall_score(test_labels, test_classes,average='weighted')))\n",
    "    print (\"F1 Score:\\t{:0.3f}\".format(f1_score(test_labels, test_classes,average='weighted')))\n",
    "    print (\"Accuracy:\\t{:0.3f}\".format(accuracy_score(test_labels, test_classes)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature dimension:  14964\n",
      "Processing:  0\n",
      "Processing:  1000\n",
      "Processing:  2000\n",
      "Processing:  3000\n",
      "Processing:  4000\n",
      "Processing:  5000\n",
      "(5842, 14964)\n",
      "Processing:  data/dev.mgb2/wer.feats\n",
      "wc:unique:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "wc:counts:  [  2   7  33 101 166 237 326 372 459 455 446 454 429 390 362 283 290 228\n",
      " 184 618]\n",
      "err:unique:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "err:counts:  [661 776 740 612 565 438 333 265 228 193 127 138 123  90  77  70  73  50\n",
      "  43  34 206]\n",
      "(5842, 20) (5842, 21)\n",
      "Processing:  0\n",
      "Processing:  1000\n",
      "Processing:  2000\n",
      "Processing:  3000\n",
      "Processing:  4000\n",
      "Processing:  5000\n",
      "(5655, 14964)\n",
      "Processing:  data/eval.mgb2/wer.feats\n",
      "wc:unique:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "wc:counts:  [  1   9  21  76 128 219 305 413 462 509 519 509 481 435 363 328 235 185\n",
      " 125 332]\n",
      "err:unique:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "err:counts:  [619 886 868 800 588 498 358 217 208 160 106  89  60  39  31  29  18  17\n",
      "  14   7  43]\n",
      "(5655, 20) (5655, 21)\n",
      "Processing:  0\n",
      "Processing:  1000\n",
      "(1410, 14964)\n",
      "Processing:  data/summa_test20170317/wer.feats\n",
      "wc:unique:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "wc:counts:  [  1   2   6   5  16  18  34  52  65  87 105 115 140 135 116  97  95  74\n",
      "  65 182]\n",
      "err:unique:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "err:counts:  [200 256 228 197 136  88  51  41  35  23  24  18  14   7  16  10  13   9\n",
      "   8   7  29]\n",
      "(1410, 20) (1410, 21)\n"
     ]
    }
   ],
   "source": [
    "id, numerical, text, char, ref =load_file (train,'glass')\n",
    "\n",
    "word_list, char_list = return_word_char_list (text, char)\n",
    "numerical_len=len(numerical[0].split())\n",
    "\n",
    "feat_len=(len(word_list+char_list)+numerical_len)\n",
    "print (\"Feature dimension: \", feat_len)\n",
    "\n",
    "\n",
    "\n",
    "train_feats = make_features (numerical, text, char, word_list, char_list )\n",
    "train_wc, train_err = get_wc_err (train,'train')\n",
    "\n",
    "\n",
    "\n",
    "id, numerical, text, char, ref =load_file (test1,'glass')\n",
    "test1_feats = make_features (numerical, text, char, word_list, char_list )\n",
    "test1_wc, test1_err = get_wc_err (test1,'test1')\n",
    "\n",
    "\n",
    "id, numerical, text, char, ref =load_file (test2,'glass')\n",
    "test2_feats = make_features (numerical, text, char, word_list, char_list )\n",
    "test2_wc, test2_err = get_wc_err (test2,'test2')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "5842/5842 [==============================] - 39s - loss: 2.9767 - acc: 0.1159    \n",
      "Epoch 2/30\n",
      "5842/5842 [==============================] - 39s - loss: 2.5306 - acc: 0.1638    \n",
      "Epoch 3/30\n",
      "5842/5842 [==============================] - 38s - loss: 2.3230 - acc: 0.2008    \n",
      "Epoch 4/30\n",
      "5842/5842 [==============================] - 39s - loss: 2.1986 - acc: 0.2194    \n",
      "Epoch 5/30\n",
      "5842/5842 [==============================] - 38s - loss: 2.1210 - acc: 0.2395    \n",
      "Epoch 6/30\n",
      "5842/5842 [==============================] - 38s - loss: 2.0574 - acc: 0.2393    \n",
      "Epoch 7/30\n",
      "5842/5842 [==============================] - 38s - loss: 2.0079 - acc: 0.2585    \n",
      "Epoch 8/30\n",
      "5842/5842 [==============================] - 39s - loss: 1.9557 - acc: 0.2638    \n",
      "Epoch 9/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.9130 - acc: 0.2802    \n",
      "Epoch 10/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.8972 - acc: 0.2729    \n",
      "Epoch 11/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.8413 - acc: 0.2922    \n",
      "Epoch 12/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.8155 - acc: 0.3037    \n",
      "Epoch 13/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.8098 - acc: 0.3097    \n",
      "Epoch 14/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.7818 - acc: 0.3134    \n",
      "Epoch 15/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.7443 - acc: 0.3158    \n",
      "Epoch 16/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.7233 - acc: 0.3251    \n",
      "Epoch 17/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.7108 - acc: 0.3285    \n",
      "Epoch 18/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.6913 - acc: 0.3357    \n",
      "Epoch 19/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.6698 - acc: 0.3526    \n",
      "Epoch 20/30\n",
      "5842/5842 [==============================] - 39s - loss: 1.6568 - acc: 0.3531    \n",
      "Epoch 21/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.6472 - acc: 0.3586    \n",
      "Epoch 22/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.6175 - acc: 0.3740    \n",
      "Epoch 23/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.6210 - acc: 0.3740    \n",
      "Epoch 24/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.5883 - acc: 0.3756    \n",
      "Epoch 25/30\n",
      "5842/5842 [==============================] - 39s - loss: 1.5845 - acc: 0.3821    \n",
      "Epoch 26/30\n",
      "5842/5842 [==============================] - 39s - loss: 1.5647 - acc: 0.3951    \n",
      "Epoch 27/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.5554 - acc: 0.3954    \n",
      "Epoch 28/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.5383 - acc: 0.4009    \n",
      "Epoch 29/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.5096 - acc: 0.4160    \n",
      "Epoch 30/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.5187 - acc: 0.4110    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\AMALI\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\Users\\AMALI\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "D:\\Users\\AMALI\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\Users\\AMALI\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "D:\\Users\\AMALI\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\Users\\AMALI\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         1\n",
      "          1       0.00      0.00      0.00         9\n",
      "          2       0.00      0.00      0.00        21\n",
      "          3       0.00      0.00      0.00        76\n",
      "          4       0.00      0.00      0.00       128\n",
      "          5       0.01      0.00      0.01       219\n",
      "          6       0.03      0.01      0.02       305\n",
      "          7       0.04      0.01      0.02       413\n",
      "          8       0.03      0.02      0.03       462\n",
      "          9       0.01      0.00      0.00       509\n",
      "         10       0.02      0.02      0.02       519\n",
      "         11       0.04      0.05      0.05       509\n",
      "         12       0.06      0.08      0.07       481\n",
      "         13       0.06      0.03      0.04       435\n",
      "         14       0.07      0.14      0.09       363\n",
      "         15       0.10      0.04      0.06       328\n",
      "         16       0.05      0.09      0.06       235\n",
      "         17       0.04      0.04      0.04       185\n",
      "         18       0.03      0.06      0.04       125\n",
      "         19       0.08      0.10      0.09       332\n",
      "         20       0.00      0.00      0.00         0\n",
      "         21       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.04      0.04      0.04      5655\n",
      "\n",
      "Precision:\t0.042\n",
      "Recall:  \t0.044\n",
      "F1 Score:\t0.039\n",
      "Accuracy:\t0.044\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         1\n",
      "          1       0.00      0.00      0.00         2\n",
      "          2       0.00      0.00      0.00         6\n",
      "          3       0.00      0.00      0.00         5\n",
      "          4       0.00      0.00      0.00        16\n",
      "          5       0.00      0.00      0.00        18\n",
      "          6       0.24      0.12      0.16        34\n",
      "          7       0.00      0.00      0.00        52\n",
      "          8       0.11      0.05      0.07        65\n",
      "          9       0.00      0.00      0.00        87\n",
      "         10       0.05      0.04      0.04       105\n",
      "         11       0.05      0.04      0.05       115\n",
      "         12       0.12      0.12      0.12       140\n",
      "         13       0.05      0.01      0.02       135\n",
      "         14       0.10      0.22      0.14       116\n",
      "         15       0.11      0.03      0.05        97\n",
      "         16       0.10      0.18      0.12        95\n",
      "         17       0.08      0.04      0.05        74\n",
      "         18       0.12      0.22      0.15        65\n",
      "         19       0.25      0.24      0.25       182\n",
      "         20       0.00      0.00      0.00         0\n",
      "         21       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.10      0.10      0.09      1410\n",
      "\n",
      "Precision:\t0.100\n",
      "Recall:  \t0.100\n",
      "F1 Score:\t0.093\n",
      "Accuracy:\t0.100\n"
     ]
    }
   ],
   "source": [
    "#def dnn (feats,labels):\n",
    "#estimate glass-box word count (make sure to add one to your estimation)\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_dim=feat_len))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(20, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_feats,train_wc, epochs=30,batch_size=32)\n",
    "model.save('./my_model.h5', overwrite=True)\n",
    "\n",
    "report (test1_feats,test1_wc,'test1.glass','wc')\n",
    "report (test2_feats,test2_wc,'test2.glass','wc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "5842/5842 [==============================] - 39s - loss: 2.9636 - acc: 0.1388    \n",
      "Epoch 2/30\n",
      "5842/5842 [==============================] - 38s - loss: 2.3813 - acc: 0.1850    \n",
      "Epoch 3/30\n",
      "5842/5842 [==============================] - 38s - loss: 2.2518 - acc: 0.2052    \n",
      "Epoch 4/30\n",
      "5842/5842 [==============================] - 39s - loss: 2.1935 - acc: 0.1987    \n",
      "Epoch 5/30\n",
      "5842/5842 [==============================] - 39s - loss: 2.1299 - acc: 0.2237    \n",
      "Epoch 6/30\n",
      "5842/5842 [==============================] - 39s - loss: 2.0976 - acc: 0.2239    \n",
      "Epoch 7/30\n",
      "5842/5842 [==============================] - 39s - loss: 2.0717 - acc: 0.2331    \n",
      "Epoch 8/30\n",
      "5842/5842 [==============================] - 39s - loss: 2.0502 - acc: 0.2278    \n",
      "Epoch 9/30\n",
      "5842/5842 [==============================] - 39s - loss: 2.0297 - acc: 0.2419    \n",
      "Epoch 10/30\n",
      "5842/5842 [==============================] - 39s - loss: 2.0107 - acc: 0.2525    \n",
      "Epoch 11/30\n",
      "5842/5842 [==============================] - 39s - loss: 1.9902 - acc: 0.2542    \n",
      "Epoch 12/30\n",
      "5842/5842 [==============================] - 39s - loss: 1.9619 - acc: 0.2593    \n",
      "Epoch 13/30\n",
      "5842/5842 [==============================] - 39s - loss: 1.9587 - acc: 0.2580    \n",
      "Epoch 14/30\n",
      "5842/5842 [==============================] - 39s - loss: 1.9336 - acc: 0.2711    \n",
      "Epoch 15/30\n",
      "5842/5842 [==============================] - 39s - loss: 1.9188 - acc: 0.2811    \n",
      "Epoch 16/30\n",
      "5842/5842 [==============================] - 39s - loss: 1.9166 - acc: 0.2811    \n",
      "Epoch 17/30\n",
      "5842/5842 [==============================] - 40s - loss: 1.8960 - acc: 0.2840    \n",
      "Epoch 18/30\n",
      "5842/5842 [==============================] - 39s - loss: 1.8872 - acc: 0.2867    \n",
      "Epoch 19/30\n",
      "5842/5842 [==============================] - 39s - loss: 1.8837 - acc: 0.2905    \n",
      "Epoch 20/30\n",
      "5842/5842 [==============================] - 39s - loss: 1.8327 - acc: 0.2978    \n",
      "Epoch 21/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.8382 - acc: 0.3025    \n",
      "Epoch 22/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.8213 - acc: 0.3105    \n",
      "Epoch 23/30\n",
      "5842/5842 [==============================] - 39s - loss: 1.8251 - acc: 0.3146    \n",
      "Epoch 24/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.8001 - acc: 0.3124    \n",
      "Epoch 25/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.7988 - acc: 0.3239    \n",
      "Epoch 26/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.7782 - acc: 0.3281    \n",
      "Epoch 27/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.7757 - acc: 0.3309    \n",
      "Epoch 28/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.7561 - acc: 0.3449    \n",
      "Epoch 29/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.7419 - acc: 0.3432    \n",
      "Epoch 30/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.7446 - acc: 0.3439    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\AMALI\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\Users\\AMALI\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\Users\\AMALI\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.46      0.16      0.24       619\n",
      "          1       0.27      0.37      0.31       886\n",
      "          2       0.23      0.38      0.29       868\n",
      "          3       0.16      0.01      0.03       800\n",
      "          4       0.16      0.25      0.20       588\n",
      "          5       0.17      0.19      0.18       498\n",
      "          6       0.13      0.07      0.09       358\n",
      "          7       0.11      0.16      0.13       217\n",
      "          8       0.29      0.10      0.14       208\n",
      "          9       0.14      0.42      0.21       160\n",
      "         10       0.00      0.00      0.00       106\n",
      "         11       0.00      0.00      0.00        89\n",
      "         12       0.14      0.25      0.18        60\n",
      "         13       0.00      0.00      0.00        39\n",
      "         14       0.25      0.06      0.10        31\n",
      "         15       0.00      0.00      0.00        29\n",
      "         16       0.09      0.17      0.12        18\n",
      "         17       0.00      0.00      0.00        17\n",
      "         18       0.00      0.00      0.00        14\n",
      "         19       0.00      0.00      0.00         7\n",
      "         20       0.69      0.86      0.76        43\n",
      "\n",
      "avg / total       0.22      0.21      0.19      5655\n",
      "\n",
      "Precision:\t0.218\n",
      "Recall:  \t0.214\n",
      "F1 Score:\t0.190\n",
      "Accuracy:\t0.214\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.40      0.14      0.20       200\n",
      "          1       0.29      0.53      0.37       256\n",
      "          2       0.23      0.33      0.27       228\n",
      "          3       0.17      0.01      0.02       197\n",
      "          4       0.11      0.13      0.12       136\n",
      "          5       0.10      0.09      0.09        88\n",
      "          6       0.08      0.04      0.05        51\n",
      "          7       0.13      0.20      0.16        41\n",
      "          8       0.00      0.00      0.00        35\n",
      "          9       0.09      0.43      0.15        23\n",
      "         10       0.00      0.00      0.00        24\n",
      "         11       0.00      0.00      0.00        18\n",
      "         12       0.03      0.07      0.04        14\n",
      "         13       0.00      0.00      0.00         7\n",
      "         14       0.00      0.00      0.00        16\n",
      "         15       0.00      0.00      0.00        10\n",
      "         16       0.19      0.23      0.21        13\n",
      "         17       0.00      0.00      0.00         9\n",
      "         18       0.00      0.00      0.00         8\n",
      "         19       0.00      0.00      0.00         7\n",
      "         20       0.91      0.69      0.78        29\n",
      "\n",
      "avg / total       0.22      0.22      0.19      1410\n",
      "\n",
      "Precision:\t0.215\n",
      "Recall:  \t0.221\n",
      "F1 Score:\t0.188\n",
      "Accuracy:\t0.221\n"
     ]
    }
   ],
   "source": [
    "#def dnn (feats,labels):\n",
    "#estimate glass-box error count\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_dim=feat_len))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(21, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_feats,train_err, epochs=30,batch_size=32)\n",
    "model.save('./my_model.h5', overwrite=True)\n",
    "\n",
    "report (test1_feats,test1_err,'test1.glass','err')\n",
    "report (test2_feats,test2_err,'test2.glass','err')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "def MAE (txt,glass,black,ref): \n",
    "    MAE_glass=mean_absolute_error(glass, ref)\n",
    "    MAE_black=mean_absolute_error(black, ref)\n",
    "\n",
    "    RMS_glass = sqrt(mean_squared_error(ref, glass))\n",
    "    RMS_black = sqrt(mean_squared_error(ref, black))\n",
    "    \n",
    "    print  ('MAE:', txt,  \"%.2f\" % MAE_glass,  \"%.2f\" % MAE_black)\n",
    "    print  ('RMSE:', txt,  \"%.2f\" % RMS_glass,  \"%.2f\" % RMS_black, '\\n')\n",
    "    \n",
    "\n",
    "def parse_results(onetwo):\n",
    "    one_two = str (onetwo)\n",
    "    print (\"Analysis for: \", one_two)\n",
    "    #wc per sentence\n",
    "    glass_file_wc = 'class.out.test'+one_two+'.glass.wc'\n",
    "    black_file_wc = 'class.out.test'+one_two+'.black.wc'\n",
    "    ref_file_wc   =  'test'+one_two+'.wc'\n",
    "\n",
    "    glass_np_wc = np.loadtxt(glass_file_wc,usecols=range(0,1),dtype='float32')+1\n",
    "    black_np_wc = np.loadtxt(black_file_wc,usecols=range(0,1),dtype='float32')+1\n",
    "    ref_np_wc   = np.loadtxt(ref_file_wc,usecols=range(0,1),dtype='float32')\n",
    "\n",
    "    MAE ('glass/black: WC :',glass_np_wc,black_np_wc,ref_np_wc)\n",
    "    \n",
    "\n",
    "    #err per sentence\n",
    "    glass_file_err = 'class.out.test'+one_two+'.glass.err'\n",
    "    black_file_err = 'class.out.test'+one_two+'.black.err'\n",
    "    ref_file_err   = 'test'+one_two+'.err'\n",
    "\n",
    "    glass_np_err = np.loadtxt(glass_file_err,usecols=range(0,1),dtype='float32')\n",
    "    black_np_err = np.loadtxt(black_file_err,usecols=range(0,1),dtype='float32')\n",
    "    ref_np_err   = np.loadtxt(ref_file_err,usecols=range(0,1),dtype='float32')\n",
    "\n",
    "\n",
    "    \n",
    "    MAE ('glass/black: ERR :',glass_np_err,black_np_err,ref_np_err)\n",
    "    \n",
    "\n",
    "    #wer per sentence\n",
    "    glass_np_wer=np.divide(glass_np_err,glass_np_wc)*100\n",
    "    black_np_wer=np.divide(black_np_err,black_np_wc)*100\n",
    "    ref_np_wer=np.divide(ref_np_err,ref_np_wc)*100\n",
    "\n",
    "    MAE ('glass/black: WER :',glass_np_wer,black_np_err,ref_np_wer)\n",
    "    \n",
    "    \n",
    "    #Overall WER\n",
    "    wer_ref   = np.sum(ref_np_err)/np.sum(ref_np_wc)*100\n",
    "    wer_glass = np.sum(glass_np_err)/np.sum(glass_np_wc)*100\n",
    "    wer_black = np.sum(black_np_err)/np.sum(black_np_wc)*100\n",
    "    print ('Overall WER: glass/black:', \"%.2f\" % wer_ref, \"%.2f\" % wer_glass, \"%.2f\" % wer_black)\n",
    "    print ('###########')\n",
    "\n",
    "    #dump WER for more analysis\n",
    "    np.savetxt('wer_ref.'+one_two, ref_np_wer,fmt='%.2f') \n",
    "    np.savetxt('wer_black.'+one_two, black_np_wer,fmt='%.2f') \n",
    "    np.savetxt('wer_glass.'+one_two, glass_np_wer,fmt='%.2f') \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature dimension:  14960\n",
      "Processing:  0\n",
      "Processing:  1000\n",
      "Processing:  2000\n",
      "Processing:  3000\n",
      "Processing:  4000\n",
      "Processing:  5000\n",
      "(5842, 14960)\n",
      "Processing:  data/dev.mgb2/wer.feats\n",
      "wc:unique:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "wc:counts:  [  2   7  33 101 166 237 326 372 459 455 446 454 429 390 362 283 290 228\n",
      " 184 618]\n",
      "err:unique:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "err:counts:  [661 776 740 612 565 438 333 265 228 193 127 138 123  90  77  70  73  50\n",
      "  43  34 206]\n",
      "(5842, 20) (5842, 21)\n",
      "Processing:  0\n",
      "Processing:  1000\n",
      "Processing:  2000\n",
      "Processing:  3000\n",
      "Processing:  4000\n",
      "Processing:  5000\n",
      "(5655, 14960)\n",
      "Processing:  data/eval.mgb2/wer.feats\n",
      "wc:unique:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "wc:counts:  [  1   9  21  76 128 219 305 413 462 509 519 509 481 435 363 328 235 185\n",
      " 125 332]\n",
      "err:unique:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "err:counts:  [619 886 868 800 588 498 358 217 208 160 106  89  60  39  31  29  18  17\n",
      "  14   7  43]\n",
      "(5655, 20) (5655, 21)\n",
      "Processing:  0\n",
      "Processing:  1000\n",
      "(1410, 14960)\n",
      "Processing:  data/summa_test20170317/wer.feats\n",
      "wc:unique:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "wc:counts:  [  1   2   6   5  16  18  34  52  65  87 105 115 140 135 116  97  95  74\n",
      "  65 182]\n",
      "err:unique:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "err:counts:  [200 256 228 197 136  88  51  41  35  23  24  18  14   7  16  10  13   9\n",
      "   8   7  29]\n",
      "(1410, 20) (1410, 21)\n"
     ]
    }
   ],
   "source": [
    "##Process the black-box features:\n",
    "id, numerical, text, char, ref =load_file (train,'black')\n",
    "\n",
    "word_list, char_list = return_word_char_list (text, char)\n",
    "numerical_len=len(numerical[0].split())\n",
    "\n",
    "feat_len=(len(word_list+char_list)+numerical_len)\n",
    "print (\"Feature dimension: \", feat_len)\n",
    "\n",
    "\n",
    "\n",
    "train_feats = make_features (numerical, text, char, word_list, char_list )\n",
    "train_wc, train_err = get_wc_err (train,'train')\n",
    "\n",
    "\n",
    "\n",
    "id, numerical, text, char, ref =load_file (test1,'black')\n",
    "test1_feats = make_features (numerical, text, char, word_list, char_list )\n",
    "test1_wc, test1_err = get_wc_err (test1,'test1')\n",
    "\n",
    "\n",
    "id, numerical, text, char, ref =load_file (test2,'black')\n",
    "test2_feats = make_features (numerical, text, char, word_list, char_list )\n",
    "test2_wc, test2_err = get_wc_err (test2,'test2')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "5842/5842 [==============================] - 40s - loss: 2.5644 - acc: 0.1691    \n",
      "Epoch 2/30\n",
      "5842/5842 [==============================] - 38s - loss: 2.1310 - acc: 0.2419    \n",
      "Epoch 3/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.9412 - acc: 0.2937    \n",
      "Epoch 4/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.8126 - acc: 0.3182    \n",
      "Epoch 5/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.7160 - acc: 0.3524    \n",
      "Epoch 6/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.6272 - acc: 0.3863    \n",
      "Epoch 7/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.5319 - acc: 0.4243    \n",
      "Epoch 8/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.4463 - acc: 0.4596    \n",
      "Epoch 9/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.3459 - acc: 0.5108    \n",
      "Epoch 10/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.3053 - acc: 0.5214    \n",
      "Epoch 11/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.2025 - acc: 0.5721    \n",
      "Epoch 12/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.1324 - acc: 0.6024    \n",
      "Epoch 13/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.0492 - acc: 0.6339    \n",
      "Epoch 14/30\n",
      "5842/5842 [==============================] - 38s - loss: 0.9913 - acc: 0.6530    \n",
      "Epoch 15/30\n",
      "5842/5842 [==============================] - 38s - loss: 0.9153 - acc: 0.6796    \n",
      "Epoch 16/30\n",
      "5842/5842 [==============================] - 38s - loss: 0.8500 - acc: 0.7078    \n",
      "Epoch 17/30\n",
      "5842/5842 [==============================] - 38s - loss: 0.7981 - acc: 0.7299    \n",
      "Epoch 18/30\n",
      "5842/5842 [==============================] - 38s - loss: 0.7440 - acc: 0.7402    \n",
      "Epoch 19/30\n",
      "5842/5842 [==============================] - 38s - loss: 0.7011 - acc: 0.7634    \n",
      "Epoch 20/30\n",
      "5842/5842 [==============================] - 39s - loss: 0.6622 - acc: 0.7775    \n",
      "Epoch 21/30\n",
      "5842/5842 [==============================] - 38s - loss: 0.6189 - acc: 0.7932    \n",
      "Epoch 22/30\n",
      "5842/5842 [==============================] - 38s - loss: 0.5879 - acc: 0.8037    \n",
      "Epoch 23/30\n",
      "5842/5842 [==============================] - 38s - loss: 0.5551 - acc: 0.8117    \n",
      "Epoch 24/30\n",
      "5842/5842 [==============================] - 38s - loss: 0.5149 - acc: 0.8322    \n",
      "Epoch 25/30\n",
      "5842/5842 [==============================] - 38s - loss: 0.4776 - acc: 0.8454    \n",
      "Epoch 26/30\n",
      "5842/5842 [==============================] - 38s - loss: 0.4589 - acc: 0.8521    \n",
      "Epoch 27/30\n",
      "5842/5842 [==============================] - 38s - loss: 0.4469 - acc: 0.8566    \n",
      "Epoch 28/30\n",
      "5842/5842 [==============================] - 38s - loss: 0.4269 - acc: 0.8615    \n",
      "Epoch 29/30\n",
      "5842/5842 [==============================] - 38s - loss: 0.4098 - acc: 0.8704    \n",
      "Epoch 30/30\n",
      "5842/5842 [==============================] - 38s - loss: 0.3893 - acc: 0.8725    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\AMALI\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\Users\\AMALI\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "D:\\Users\\AMALI\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\Users\\AMALI\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "D:\\Users\\AMALI\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\Users\\AMALI\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         1\n",
      "          1       0.00      0.00      0.00         9\n",
      "          2       0.00      0.00      0.00        21\n",
      "          3       0.00      0.00      0.00        76\n",
      "          4       0.05      0.01      0.01       128\n",
      "          5       0.07      0.02      0.03       219\n",
      "          6       0.09      0.05      0.06       305\n",
      "          7       0.08      0.03      0.04       413\n",
      "          8       0.13      0.09      0.11       462\n",
      "          9       0.12      0.10      0.11       509\n",
      "         10       0.09      0.07      0.08       519\n",
      "         11       0.05      0.02      0.03       509\n",
      "         12       0.04      0.03      0.03       481\n",
      "         13       0.05      0.08      0.07       435\n",
      "         14       0.07      0.12      0.09       363\n",
      "         15       0.04      0.02      0.03       328\n",
      "         16       0.07      0.06      0.07       235\n",
      "         17       0.04      0.08      0.06       185\n",
      "         18       0.04      0.15      0.06       125\n",
      "         19       0.11      0.12      0.12       332\n",
      "         20       0.00      0.00      0.00         0\n",
      "         21       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.07      0.06      0.06      5655\n",
      "\n",
      "Precision:\t0.074\n",
      "Recall:  \t0.064\n",
      "F1 Score:\t0.064\n",
      "Accuracy:\t0.064\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         1\n",
      "          1       0.00      0.00      0.00         2\n",
      "          2       0.00      0.00      0.00         6\n",
      "          3       0.00      0.00      0.00         5\n",
      "          4       0.00      0.00      0.00        16\n",
      "          5       0.00      0.00      0.00        18\n",
      "          6       0.26      0.18      0.21        34\n",
      "          7       0.27      0.06      0.10        52\n",
      "          8       0.05      0.02      0.02        65\n",
      "          9       0.11      0.09      0.10        87\n",
      "         10       0.13      0.07      0.09       105\n",
      "         11       0.00      0.00      0.00       115\n",
      "         12       0.16      0.10      0.12       140\n",
      "         13       0.09      0.07      0.07       135\n",
      "         14       0.07      0.11      0.09       116\n",
      "         15       0.04      0.02      0.03        97\n",
      "         16       0.06      0.06      0.06        95\n",
      "         17       0.08      0.09      0.09        74\n",
      "         18       0.08      0.28      0.12        65\n",
      "         19       0.14      0.10      0.12       182\n",
      "         20       0.00      0.00      0.00         0\n",
      "         21       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.10      0.08      0.08      1410\n",
      "\n",
      "Precision:\t0.098\n",
      "Recall:  \t0.079\n",
      "F1 Score:\t0.081\n",
      "Accuracy:\t0.079\n"
     ]
    }
   ],
   "source": [
    "#def dnn (feats,labels):\n",
    "#estimate glass-box word count (make sure to add one to your estimation)\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_dim=feat_len))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(20, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_feats,train_wc, epochs=30,batch_size=32)\n",
    "model.save('./my_model.h5', overwrite=True)\n",
    "\n",
    "report (test1_feats,test1_wc,'test1.black','wc')\n",
    "report (test2_feats,test2_wc,'test2.black','wc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "5842/5842 [==============================] - 37s - loss: 2.5856 - acc: 0.1604    \n",
      "Epoch 2/30\n",
      "5842/5842 [==============================] - 37s - loss: 2.2714 - acc: 0.1941    \n",
      "Epoch 3/30\n",
      "5842/5842 [==============================] - 37s - loss: 2.1316 - acc: 0.2412    \n",
      "Epoch 4/30\n",
      "5842/5842 [==============================] - 38s - loss: 2.0479 - acc: 0.2588    \n",
      "Epoch 5/30\n",
      "5842/5842 [==============================] - 37s - loss: 1.9616 - acc: 0.2936    \n",
      "Epoch 6/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.8871 - acc: 0.3184    \n",
      "Epoch 7/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.8011 - acc: 0.3591    \n",
      "Epoch 8/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.7197 - acc: 0.3934    \n",
      "Epoch 9/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.6216 - acc: 0.4315    \n",
      "Epoch 10/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.5273 - acc: 0.4603    \n",
      "Epoch 11/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.4243 - acc: 0.5086    \n",
      "Epoch 12/30\n",
      "5842/5842 [==============================] - 39s - loss: 1.3473 - acc: 0.5320    \n",
      "Epoch 13/30\n",
      "5842/5842 [==============================] - 39s - loss: 1.2590 - acc: 0.5683    \n",
      "Epoch 14/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.1981 - acc: 0.5794    \n",
      "Epoch 15/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.1268 - acc: 0.6145    \n",
      "Epoch 16/30\n",
      "5842/5842 [==============================] - 38s - loss: 1.0494 - acc: 0.6426    \n",
      "Epoch 17/30\n",
      "5842/5842 [==============================] - 38s - loss: 0.9864 - acc: 0.6652    \n",
      "Epoch 18/30\n",
      "5842/5842 [==============================] - 39s - loss: 0.9246 - acc: 0.6852    \n",
      "Epoch 19/30\n",
      "5842/5842 [==============================] - 40s - loss: 0.8769 - acc: 0.7133    \n",
      "Epoch 20/30\n",
      "5842/5842 [==============================] - 40s - loss: 0.8099 - acc: 0.7278    \n",
      "Epoch 21/30\n",
      "5842/5842 [==============================] - 40s - loss: 0.7793 - acc: 0.7372    \n",
      "Epoch 22/30\n",
      "5842/5842 [==============================] - 38s - loss: 0.7333 - acc: 0.7521    \n",
      "Epoch 23/30\n",
      "5842/5842 [==============================] - 38s - loss: 0.6975 - acc: 0.7667    \n",
      "Epoch 24/30\n",
      "5842/5842 [==============================] - 38s - loss: 0.6764 - acc: 0.7701    \n",
      "Epoch 25/30\n",
      "5842/5842 [==============================] - 38s - loss: 0.6208 - acc: 0.7908    \n",
      "Epoch 26/30\n",
      "5842/5842 [==============================] - 38s - loss: 0.6152 - acc: 0.7917    \n",
      "Epoch 27/30\n",
      "5842/5842 [==============================] - 38s - loss: 0.5818 - acc: 0.8062    \n",
      "Epoch 28/30\n",
      "5842/5842 [==============================] - 37s - loss: 0.5529 - acc: 0.8189    \n",
      "Epoch 29/30\n",
      "5842/5842 [==============================] - 37s - loss: 0.5353 - acc: 0.8232    \n",
      "Epoch 30/30\n",
      "5842/5842 [==============================] - 38s - loss: 0.5158 - acc: 0.8317    \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.32      0.24      0.28       619\n",
      "          1       0.30      0.14      0.19       886\n",
      "          2       0.20      0.13      0.16       868\n",
      "          3       0.18      0.26      0.21       800\n",
      "          4       0.09      0.03      0.04       588\n",
      "          5       0.13      0.27      0.17       498\n",
      "          6       0.11      0.18      0.14       358\n",
      "          7       0.08      0.06      0.07       217\n",
      "          8       0.07      0.03      0.05       208\n",
      "          9       0.10      0.21      0.14       160\n",
      "         10       0.04      0.01      0.02       106\n",
      "         11       0.09      0.17      0.12        89\n",
      "         12       0.08      0.22      0.12        60\n",
      "         13       0.05      0.08      0.06        39\n",
      "         14       0.02      0.03      0.02        31\n",
      "         15       0.00      0.00      0.00        29\n",
      "         16       0.11      0.11      0.11        18\n",
      "         17       0.00      0.00      0.00        17\n",
      "         18       0.00      0.00      0.00        14\n",
      "         19       0.00      0.00      0.00         7\n",
      "         20       0.30      0.91      0.45        43\n",
      "\n",
      "avg / total       0.18      0.17      0.16      5655\n",
      "\n",
      "Precision:\t0.181\n",
      "Recall:  \t0.166\n",
      "F1 Score:\t0.159\n",
      "Accuracy:\t0.166\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.20      0.14      0.16       200\n",
      "          1       0.25      0.12      0.17       256\n",
      "          2       0.18      0.12      0.15       228\n",
      "          3       0.21      0.23      0.22       197\n",
      "          4       0.19      0.07      0.10       136\n",
      "          5       0.08      0.22      0.12        88\n",
      "          6       0.04      0.08      0.05        51\n",
      "          7       0.05      0.05      0.05        41\n",
      "          8       0.00      0.00      0.00        35\n",
      "          9       0.06      0.22      0.09        23\n",
      "         10       0.12      0.04      0.06        24\n",
      "         11       0.10      0.33      0.16        18\n",
      "         12       0.06      0.14      0.08        14\n",
      "         13       0.05      0.14      0.07         7\n",
      "         14       0.08      0.19      0.11        16\n",
      "         15       0.00      0.00      0.00        10\n",
      "         16       0.11      0.08      0.09        13\n",
      "         17       0.00      0.00      0.00         9\n",
      "         18       1.00      0.12      0.22         8\n",
      "         19       0.00      0.00      0.00         7\n",
      "         20       0.41      0.97      0.57        29\n",
      "\n",
      "avg / total       0.18      0.15      0.15      1410\n",
      "\n",
      "Precision:\t0.180\n",
      "Recall:  \t0.152\n",
      "F1 Score:\t0.148\n",
      "Accuracy:\t0.152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\AMALI\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\Users\\AMALI\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\Users\\AMALI\\Anaconda3\\envs\\ztdl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#def dnn (feats,labels):\n",
    "#estimate black-box error count\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_dim=feat_len))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(21, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_feats,train_err, epochs=30,batch_size=32)\n",
    "model.save('./my_model.h5', overwrite=True)\n",
    "\n",
    "report (test1_feats,test1_err,'test1.black','err')\n",
    "report (test2_feats,test2_err,'test2.black','err')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis for:  1\n",
      "MAE: glass/black: WC : 2.50 2.78\n",
      "RMSE: glass/black: WC : 2.88 3.28 \n",
      "\n",
      "MAE: glass/black: ERR : 1.64 2.28\n",
      "RMSE: glass/black: ERR : 2.24 3.05 \n",
      "\n",
      "MAE: glass/black: WER : 13.84 27.53\n",
      "RMSE: glass/black: WER : 18.37 35.24 \n",
      "\n",
      "Overall WER: glass/black: 33.03 26.89 34.10\n",
      "###########\n",
      "\n",
      "\n",
      "Analysis for:  2\n",
      "MAE: glass/black: WC : 2.27 2.72\n",
      "RMSE: glass/black: WC : 2.71 3.27 \n",
      "\n",
      "MAE: glass/black: ERR : 1.74 2.71\n",
      "RMSE: glass/black: ERR : 2.38 3.64 \n",
      "\n",
      "MAE: glass/black: WER : 12.95 23.59\n",
      "RMSE: glass/black: WER : 17.67 33.85 \n",
      "\n",
      "Overall WER: glass/black: 28.51 22.16 33.77\n",
      "###########\n"
     ]
    }
   ],
   "source": [
    "#summary\n",
    "parse_results (1)\n",
    "print ('\\n')\n",
    "parse_results (2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
