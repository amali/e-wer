{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#load lib\n",
    "import numpy as np\n",
    "import re, sys, glob\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from keras.preprocessing import text\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk import ngrams\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.models import load_model\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load data\n",
    "\n",
    "'''\n",
    "Features order in the data look like this \n",
    "print STDOUT \"S:\".$uttranceInfo{\"id\"}.\"\\t\".$wordcount.\" \".$graphemecount.\" \".$uttranceInfo{\"total_frames\"}.\n",
    "      \" \".$uttranceInfo{\"avg_loglike\"}.\" \".$uttranceInfo{\"total_AMloglike\"}.\" \".\n",
    "\t  $uttranceInfo{\"total_LMloglike\"}.\" \".$uttranceInfo{\"duration\"}.\" \".\n",
    "\t  $uttranceInfo{\"GER\"}.\"\\t\".$uttranceInfo{\"sentence\"}.\"\\t\".$uttranceInfo{\"grapheme\"}.\n",
    "\t  \"\\t\".$uttranceInfo{\"WER\"}.\"\\n\";\n",
    "'''\n",
    "\n",
    "train=\"data/dev.mgb2/wer.feats\"\n",
    "test1=\"data/eval.mgb2/wer.feats\"\n",
    "test2=\"data/summa_test20170317/wer.feats\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_file (file,type='glass'):\n",
    "    f=open(file,\"r\")\n",
    "    lines=f.readlines()\n",
    "    _id=[]\n",
    "    _text=[]\n",
    "    _numerical=[]\n",
    "    _char=[]\n",
    "    _ref=[]\n",
    "    for x in lines:\n",
    "        _id.append(x.split('\\t')[0])\n",
    "        _text.append(x.split('\\t')[2])\n",
    "        _char.append(x.split('\\t')[3])\n",
    "        _ref.append(x.split('\\t')[4])\n",
    "        if type == 'glass': \n",
    "            _numerical.append(x.split('\\t')[1])\n",
    "        else:\n",
    "            blac_box_numerical=x.split('\\t')[1].split(' ')\n",
    "            numerical2=' '.join(blac_box_numerical[0:2]+blac_box_numerical[6:])\n",
    "            _numerical.append(numerical2)\n",
    "        \n",
    "    f.close()\n",
    "    return _id, _numerical, _text, _char, _ref\n",
    "\n",
    "def word_grams(words, min=1, max=4):\n",
    "    s = []\n",
    "    for n in range(min, max):\n",
    "        for ngram in ngrams(words, n):\n",
    "            s.append(' '.join(str(i) for i in ngram))\n",
    "    return s\n",
    "\n",
    "def return_word_char_list (_text,_char):\n",
    "    _unigram_word_list = [] \n",
    "    _trigram_char_list = []\n",
    "    for i,j in enumerate(_char):\n",
    "        \n",
    "        _char_3gram = word_grams (_char[i].split(),1,3)\n",
    "        for tri in _char_3gram: \n",
    "             if tri not in _trigram_char_list: _trigram_char_list.append(tri)\n",
    "    \n",
    "        _words_1gram = word_grams (_text[i].split(),1,2)\n",
    "        for uni in _words_1gram: \n",
    "             if uni not in _unigram_word_list: _unigram_word_list.append(uni)\n",
    "    return _unigram_word_list, _trigram_char_list \n",
    "                    \n",
    "def vectorize (words,chars,word_list,char_list):\n",
    "    feature_vector = []\n",
    "    index=0\n",
    "    \n",
    "    temp_words = [0] * len(word_list)\n",
    "    for word in word_grams (words.split(),1,2): \n",
    "        for index, word2 in enumerate(word_list): \n",
    "            if word == word2:\n",
    "                #print (index, word2)\n",
    "                temp_words[index]+=1\n",
    "                break\n",
    "    \n",
    "    temp_chars = [0] * len(char_list)\n",
    "    for _char in word_grams (chars.split(),1,3): \n",
    "        for index, _char2 in enumerate(char_list): \n",
    "            if _char == _char2:\n",
    "                #print (index, _char2)\n",
    "                temp_chars[index]+=1\n",
    "                break            \n",
    "    return temp_words+temp_chars\n",
    "\n",
    "def make_features (numerical, text, char, word_list, char_list ):\n",
    "    allfeats= []\n",
    "    for i, _id in enumerate (text):\n",
    "        feat = vectorize (text[i],char[i],word_list,char_list)\n",
    "        allfeats.append (numerical[i].split()+feat)\n",
    "        if i % 1000 == 0: print (\"Processing: \", i)\n",
    "    nn=np.array(allfeats)\n",
    "    #nn_minmax = preprocessing.scale(nn)\n",
    "       \n",
    "    print (nn.shape)\n",
    "    return (nn)\n",
    "    \n",
    "def get_wc_err (file,dump):\n",
    "    print (\"Processing: \", file)\n",
    "    f=open(file,\"r\")\n",
    "    lines=f.readlines()\n",
    "    _wc=[]\n",
    "    _err=[]\n",
    "    _real_wc =[]\n",
    "    _real_err =[]\n",
    "    for x in lines:\n",
    "        err = int(x.split('\\t')[4].split(' ')[1])\n",
    "        wc  = int(x.split('\\t')[4].split(' ')[2])\n",
    "        _real_wc.append (wc)    \n",
    "        _real_err.append (err)\n",
    "        \n",
    "        if wc > 20: wc =20\n",
    "        if err > 20: err =20\n",
    "        wc = wc - 1 # for whatever reason keras like to start counting from zer\n",
    "        \n",
    "        _wc.append (wc)    \n",
    "        _err.append (err)\n",
    "    \n",
    "    unique, counts = np.unique(_wc, return_counts=True)\n",
    "    print (\"wc:unique: \",unique)\n",
    "    print (\"wc:counts: \",counts)\n",
    "    \n",
    "    unique, counts = np.unique(_err, return_counts=True)\n",
    "    print (\"err:unique: \",unique)\n",
    "    print (\"err:counts: \",counts)\n",
    "    \n",
    "    one_hot_labels_wc = to_categorical(np.array(_wc), num_classes=20)\n",
    "    one_hot_labels_err = to_categorical(np.array(_err), num_classes=21)\n",
    "        \n",
    "    np.savetxt(dump+'.err', np.array(_real_err), fmt='%d')\n",
    "    np.savetxt(dump+'.wc', np.array(_real_wc), fmt='%d')\n",
    "    \n",
    "    print (one_hot_labels_wc.shape,one_hot_labels_err.shape)\n",
    "    return one_hot_labels_wc, one_hot_labels_err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "    \n",
    "\n",
    "def report (test_vec,test_labels,test,ext):\n",
    "    \n",
    "    prob_out='prob.out.'+test+'.'+ext\n",
    "    pred_out='pred.out.'+test+'.'+ext\n",
    "    class_out='class.out.'+test+'.'+ext\n",
    "    \n",
    "    _shift=0\n",
    "    if ext == \"wc\" : _shift=2\n",
    "    #load models\n",
    "    model = load_model('./my_model.h5')\n",
    "    \n",
    "    #save predictions\n",
    "    pred = model.predict(test_vec)\n",
    "    np.savetxt(pred_out, pred, delimiter=' ')    \n",
    "    \n",
    "    prob = np.copy(pred)\n",
    "    i=0\n",
    "    for row in prob: \n",
    "      raw = [sigmoid(i) for i in row]\n",
    "      norm = [float(i)/sum(raw) for i in raw]\n",
    "      prob[int(i)]=norm\n",
    "      i=i+1\n",
    "    \n",
    "    #save prob\n",
    "    np.savetxt(prob_out, prob, delimiter=' ',fmt='%f') \n",
    "    \n",
    "    \n",
    "    test_classes = np.argmax(prob, axis=1)+_shift\n",
    "    #save classes\n",
    "    np.savetxt(class_out, test_classes, delimiter=' ',fmt='%d')\n",
    "    \n",
    "\n",
    "    test_labels = np.argmax(test_labels, axis=1) # to remove the Keras to_categorical\n",
    "    \n",
    "    \n",
    "\n",
    "    #print confusion matrix \n",
    "    confusion_matrix(test_labels, test_classes)\n",
    "\n",
    "    #print classification report\n",
    "    print(classification_report(test_labels, test_classes))\n",
    "\n",
    "\n",
    "    #print prec, recall and f1\n",
    "    print (\"Precision:\\t{:0.3f}\".format(precision_score(test_labels, test_classes,average='weighted')))\n",
    "    print (\"Recall:  \\t{:0.3f}\".format(recall_score(test_labels, test_classes,average='weighted')))\n",
    "    print (\"F1 Score:\\t{:0.3f}\".format(f1_score(test_labels, test_classes,average='weighted')))\n",
    "    print (\"Accuracy:\\t{:0.3f}\".format(accuracy_score(test_labels, test_classes)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature dimension:  14964\n",
      "Processing:  0\n",
      "Processing:  1000\n",
      "Processing:  2000\n",
      "Processing:  3000\n",
      "Processing:  4000\n",
      "Processing:  5000\n",
      "(5842, 14964)\n",
      "Processing:  data/dev.mgb2/wer.feats\n",
      "wc:unique:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "wc:counts:  [  2   7  33 101 166 237 326 372 459 455 446 454 429 390 362 283 290 228\n",
      " 184 618]\n",
      "err:unique:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "err:counts:  [661 776 740 612 565 438 333 265 228 193 127 138 123  90  77  70  73  50\n",
      "  43  34 206]\n",
      "(5842, 20) (5842, 21)\n",
      "Processing:  0\n",
      "Processing:  1000\n",
      "Processing:  2000\n",
      "Processing:  3000\n",
      "Processing:  4000\n",
      "Processing:  5000\n",
      "(5655, 14964)\n",
      "Processing:  data/eval.mgb2/wer.feats\n",
      "wc:unique:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "wc:counts:  [  1   9  21  76 128 219 305 413 462 509 519 509 481 435 363 328 235 185\n",
      " 125 332]\n",
      "err:unique:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "err:counts:  [619 886 868 800 588 498 358 217 208 160 106  89  60  39  31  29  18  17\n",
      "  14   7  43]\n",
      "(5655, 20) (5655, 21)\n",
      "Processing:  0\n",
      "Processing:  1000\n",
      "(1410, 14964)\n",
      "Processing:  data/summa_test20170317/wer.feats\n",
      "wc:unique:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "wc:counts:  [  1   2   6   5  16  18  34  52  65  87 105 115 140 135 116  97  95  74\n",
      "  65 182]\n",
      "err:unique:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "err:counts:  [200 256 228 197 136  88  51  41  35  23  24  18  14   7  16  10  13   9\n",
      "   8   7  29]\n",
      "(1410, 20) (1410, 21)\n"
     ]
    }
   ],
   "source": [
    "id, numerical, text, char, ref =load_file (train,'glass')\n",
    "\n",
    "word_list, char_list = return_word_char_list (text, char)\n",
    "numerical_len=len(numerical[0].split())\n",
    "\n",
    "feat_len=(len(word_list+char_list)+numerical_len)\n",
    "print (\"Feature dimension: \", feat_len)\n",
    "\n",
    "\n",
    "\n",
    "train_feats = make_features (numerical, text, char, word_list, char_list )\n",
    "train_wc, train_err = get_wc_err (train,'train')\n",
    "\n",
    "\n",
    "\n",
    "id, numerical, text, char, ref =load_file (test1,'glass')\n",
    "test1_feats = make_features (numerical, text, char, word_list, char_list )\n",
    "test1_wc, test1_err = get_wc_err (test1,'test1')\n",
    "\n",
    "\n",
    "id, numerical, text, char, ref =load_file (test2,'glass')\n",
    "test2_feats = make_features (numerical, text, char, word_list, char_list )\n",
    "test2_wc, test2_err = get_wc_err (test2,'test2')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5842/5842 [==============================] - 22s - loss: 2.9670 - acc: 0.1279    \n",
      "Epoch 2/50\n",
      "5842/5842 [==============================] - 18s - loss: 2.4631 - acc: 0.1825    \n",
      "Epoch 3/50\n",
      "5842/5842 [==============================] - 18s - loss: 2.2855 - acc: 0.2042    \n",
      "Epoch 4/50\n",
      "5842/5842 [==============================] - 18s - loss: 2.1830 - acc: 0.2271    \n",
      "Epoch 5/50\n",
      "5842/5842 [==============================] - 18s - loss: 2.0909 - acc: 0.2422    \n",
      "Epoch 6/50\n",
      "5842/5842 [==============================] - 17s - loss: 2.0409 - acc: 0.2473    \n",
      "Epoch 7/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.9880 - acc: 0.2614    \n",
      "Epoch 8/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.9404 - acc: 0.2645    \n",
      "Epoch 9/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.8955 - acc: 0.2821    - ETA: 8s - loss: 1.9092 - acc: 0. - ETA: 8s - loss: 1.9084 - ET\n",
      "Epoch 10/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.8723 - acc: 0.2800    \n",
      "Epoch 11/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.8456 - acc: 0.2984    \n",
      "Epoch 12/50\n",
      "5842/5842 [==============================] - 18s - loss: 1.8210 - acc: 0.3002    - ETA: 1s - loss: 1.8\n",
      "Epoch 13/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.7816 - acc: 0.3138    \n",
      "Epoch 14/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.7702 - acc: 0.3167    \n",
      "Epoch 15/50\n",
      "5842/5842 [==============================] - 18s - loss: 1.7434 - acc: 0.3172    \n",
      "Epoch 16/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.7291 - acc: 0.3393    \n",
      "Epoch 17/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.7216 - acc: 0.3257    \n",
      "Epoch 18/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.7170 - acc: 0.3305    \n",
      "Epoch 19/50\n",
      "5842/5842 [==============================] - 18s - loss: 1.6886 - acc: 0.3461    \n",
      "Epoch 20/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.6607 - acc: 0.3495    \n",
      "Epoch 21/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.6496 - acc: 0.3566    \n",
      "Epoch 22/50\n",
      "5842/5842 [==============================] - 16s - loss: 1.6377 - acc: 0.3602    \n",
      "Epoch 23/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.6330 - acc: 0.3607    \n",
      "Epoch 24/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.6188 - acc: 0.3738    \n",
      "Epoch 25/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.5878 - acc: 0.3869    \n",
      "Epoch 26/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.5949 - acc: 0.3822    \n",
      "Epoch 27/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.5841 - acc: 0.3797    \n",
      "Epoch 28/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.5823 - acc: 0.3901    \n",
      "Epoch 29/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.5591 - acc: 0.4024    \n",
      "Epoch 30/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.5592 - acc: 0.3925    \n",
      "Epoch 31/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.5361 - acc: 0.4110    \n",
      "Epoch 32/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.5263 - acc: 0.4071    \n",
      "Epoch 33/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.5184 - acc: 0.4130    \n",
      "Epoch 34/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.5201 - acc: 0.4189    \n",
      "Epoch 35/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.5084 - acc: 0.4245    \n",
      "Epoch 36/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.4846 - acc: 0.4303    \n",
      "Epoch 37/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.4732 - acc: 0.4516    \n",
      "Epoch 38/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.4679 - acc: 0.4451    \n",
      "Epoch 39/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.4538 - acc: 0.4572    \n",
      "Epoch 40/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.4574 - acc: 0.4529    \n",
      "Epoch 41/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.4453 - acc: 0.4471    \n",
      "Epoch 42/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.4471 - acc: 0.4587    \n",
      "Epoch 43/50\n",
      "5842/5842 [==============================] - 18s - loss: 1.4153 - acc: 0.4709    \n",
      "Epoch 44/50\n",
      "5842/5842 [==============================] - 18s - loss: 1.4108 - acc: 0.4664    \n",
      "Epoch 45/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.4013 - acc: 0.4733    \n",
      "Epoch 46/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.3907 - acc: 0.4793    \n",
      "Epoch 47/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.4063 - acc: 0.4807    \n",
      "Epoch 48/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.3840 - acc: 0.4866    \n",
      "Epoch 49/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.3591 - acc: 0.4978    \n",
      "Epoch 50/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.3565 - acc: 0.4998    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/sls/qcri/asr/amali/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/data/sls/qcri/asr/amali/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/data/sls/qcri/asr/amali/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/data/sls/qcri/asr/amali/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/data/sls/qcri/asr/amali/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/data/sls/qcri/asr/amali/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         1\n",
      "          1       0.00      0.00      0.00         9\n",
      "          2       0.00      0.00      0.00        21\n",
      "          3       0.00      0.00      0.00        76\n",
      "          4       0.00      0.00      0.00       128\n",
      "          5       0.03      0.00      0.01       219\n",
      "          6       0.03      0.01      0.02       305\n",
      "          7       0.04      0.02      0.03       413\n",
      "          8       0.07      0.04      0.05       462\n",
      "          9       0.06      0.03      0.04       509\n",
      "         10       0.10      0.19      0.13       519\n",
      "         11       0.09      0.02      0.03       509\n",
      "         12       0.10      0.20      0.13       481\n",
      "         13       0.14      0.12      0.13       435\n",
      "         14       0.12      0.17      0.14       363\n",
      "         15       0.21      0.55      0.30       328\n",
      "         16       0.26      0.04      0.07       235\n",
      "         17       0.21      0.32      0.25       185\n",
      "         18       0.13      0.02      0.03       125\n",
      "         19       0.35      0.33      0.34       332\n",
      "         20       0.00      0.00      0.00         0\n",
      "         21       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.11      0.13      0.11      5655\n",
      "\n",
      "Precision:\t0.113\n",
      "Recall:  \t0.129\n",
      "F1 Score:\t0.106\n",
      "Accuracy:\t0.129\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         1\n",
      "          1       0.00      0.00      0.00         2\n",
      "          2       0.00      0.00      0.00         6\n",
      "          3       0.00      0.00      0.00         5\n",
      "          4       0.00      0.00      0.00        16\n",
      "          5       0.00      0.00      0.00        18\n",
      "          6       0.25      0.12      0.16        34\n",
      "          7       0.00      0.00      0.00        52\n",
      "          8       0.14      0.06      0.09        65\n",
      "          9       0.11      0.05      0.07        87\n",
      "         10       0.08      0.10      0.09       105\n",
      "         11       0.05      0.01      0.01       115\n",
      "         12       0.15      0.25      0.19       140\n",
      "         13       0.30      0.19      0.24       135\n",
      "         14       0.18      0.32      0.23       116\n",
      "         15       0.19      0.57      0.28        97\n",
      "         16       0.33      0.04      0.07        95\n",
      "         17       0.21      0.27      0.24        74\n",
      "         18       0.00      0.00      0.00        65\n",
      "         19       0.54      0.41      0.47       182\n",
      "         20       0.00      0.00      0.00         0\n",
      "         21       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.20      0.20      0.18      1410\n",
      "\n",
      "Precision:\t0.204\n",
      "Recall:  \t0.196\n",
      "F1 Score:\t0.177\n",
      "Accuracy:\t0.196\n"
     ]
    }
   ],
   "source": [
    "#def dnn (feats,labels):\n",
    "#estimate glass-box word count (make sure to add one to your estimation)\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_dim=feat_len))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(20, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_feats,train_wc, epochs=50,batch_size=32)\n",
    "model.save('./my_model.h5', overwrite=True)\n",
    "\n",
    "report (test1_feats,test1_wc,'test1.glass','wc')\n",
    "report (test2_feats,test2_wc,'test2.glass','wc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5842/5842 [==============================] - 18s - loss: 2.8063 - acc: 0.1566    \n",
      "Epoch 2/50\n",
      "5842/5842 [==============================] - 17s - loss: 2.3701 - acc: 0.1739    - ETA: 2s\n",
      "Epoch 3/50\n",
      "5842/5842 [==============================] - 17s - loss: 2.2698 - acc: 0.1903    \n",
      "Epoch 4/50\n",
      "5842/5842 [==============================] - 17s - loss: 2.2094 - acc: 0.2020    \n",
      "Epoch 5/50\n",
      "5842/5842 [==============================] - 17s - loss: 2.1544 - acc: 0.2150    \n",
      "Epoch 6/50\n",
      "5842/5842 [==============================] - 17s - loss: 2.1106 - acc: 0.2258    \n",
      "Epoch 7/50\n",
      "5842/5842 [==============================] - 17s - loss: 2.0872 - acc: 0.2343    \n",
      "Epoch 8/50\n",
      "5842/5842 [==============================] - 17s - loss: 2.0606 - acc: 0.2407    \n",
      "Epoch 9/50\n",
      "5842/5842 [==============================] - 17s - loss: 2.0346 - acc: 0.2376    \n",
      "Epoch 10/50\n",
      "5842/5842 [==============================] - 17s - loss: 2.0226 - acc: 0.2494    \n",
      "Epoch 11/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.9913 - acc: 0.2456    \n",
      "Epoch 12/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.9678 - acc: 0.2624    \n",
      "Epoch 13/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.9687 - acc: 0.2614    \n",
      "Epoch 14/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.9522 - acc: 0.2739    \n",
      "Epoch 15/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.9262 - acc: 0.2653    \n",
      "Epoch 16/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.9061 - acc: 0.2850    \n",
      "Epoch 17/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.8941 - acc: 0.2794    \n",
      "Epoch 18/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.8718 - acc: 0.2900    \n",
      "Epoch 19/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.8729 - acc: 0.2961    \n",
      "Epoch 20/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.8812 - acc: 0.3047    \n",
      "Epoch 21/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.8401 - acc: 0.3035    \n",
      "Epoch 22/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.8279 - acc: 0.3177    \n",
      "Epoch 23/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.8152 - acc: 0.3141    \n",
      "Epoch 24/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.8010 - acc: 0.3259    \n",
      "Epoch 25/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.8045 - acc: 0.3175    \n",
      "Epoch 26/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.7853 - acc: 0.3393    \n",
      "Epoch 27/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.7834 - acc: 0.3288    \n",
      "Epoch 28/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.7709 - acc: 0.3287    \n",
      "Epoch 29/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.7551 - acc: 0.3393    \n",
      "Epoch 30/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.7360 - acc: 0.3403    \n",
      "Epoch 31/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.7297 - acc: 0.3566    \n",
      "Epoch 32/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.7217 - acc: 0.3489    \n",
      "Epoch 33/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.7053 - acc: 0.3649    \n",
      "Epoch 34/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.6912 - acc: 0.3655    \n",
      "Epoch 35/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.6903 - acc: 0.3704    \n",
      "Epoch 36/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.6662 - acc: 0.3793    \n",
      "Epoch 37/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.6708 - acc: 0.3725    \n",
      "Epoch 38/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.6520 - acc: 0.3810    \n",
      "Epoch 39/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.6514 - acc: 0.3932    \n",
      "Epoch 40/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.6488 - acc: 0.3904    \n",
      "Epoch 41/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.6153 - acc: 0.4053    \n",
      "Epoch 42/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.6061 - acc: 0.4026    \n",
      "Epoch 43/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.6238 - acc: 0.3990    \n",
      "Epoch 44/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.6074 - acc: 0.4122    \n",
      "Epoch 45/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.5897 - acc: 0.4172    \n",
      "Epoch 46/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.5875 - acc: 0.4240    \n",
      "Epoch 47/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.5744 - acc: 0.4209    \n",
      "Epoch 48/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.5549 - acc: 0.4231    \n",
      "Epoch 49/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.5697 - acc: 0.4238    \n",
      "Epoch 50/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.5787 - acc: 0.4283    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/sls/qcri/asr/amali/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/data/sls/qcri/asr/amali/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/data/sls/qcri/asr/amali/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.44      0.23      0.31       619\n",
      "          1       0.31      0.29      0.30       886\n",
      "          2       0.22      0.52      0.31       868\n",
      "          3       0.16      0.06      0.08       800\n",
      "          4       0.19      0.14      0.16       588\n",
      "          5       0.16      0.28      0.20       498\n",
      "          6       0.17      0.05      0.08       358\n",
      "          7       0.09      0.06      0.07       217\n",
      "          8       0.17      0.12      0.14       208\n",
      "          9       0.17      0.11      0.14       160\n",
      "         10       0.33      0.02      0.04       106\n",
      "         11       0.07      0.01      0.02        89\n",
      "         12       0.16      0.38      0.22        60\n",
      "         13       0.00      0.00      0.00        39\n",
      "         14       0.33      0.03      0.06        31\n",
      "         15       0.16      0.62      0.25        29\n",
      "         16       0.00      0.00      0.00        18\n",
      "         17       0.00      0.00      0.00        17\n",
      "         18       0.00      0.00      0.00        14\n",
      "         19       0.00      0.00      0.00         7\n",
      "         20       0.85      0.77      0.80        43\n",
      "\n",
      "avg / total       0.23      0.23      0.20      5655\n",
      "\n",
      "Precision:\t0.230\n",
      "Recall:  \t0.225\n",
      "F1 Score:\t0.202\n",
      "Accuracy:\t0.225\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.33      0.19      0.24       200\n",
      "          1       0.29      0.36      0.32       256\n",
      "          2       0.22      0.43      0.29       228\n",
      "          3       0.19      0.09      0.12       197\n",
      "          4       0.17      0.09      0.12       136\n",
      "          5       0.13      0.20      0.16        88\n",
      "          6       0.08      0.04      0.05        51\n",
      "          7       0.13      0.12      0.13        41\n",
      "          8       0.17      0.11      0.14        35\n",
      "          9       0.09      0.13      0.11        23\n",
      "         10       0.00      0.00      0.00        24\n",
      "         11       0.00      0.00      0.00        18\n",
      "         12       0.07      0.21      0.11        14\n",
      "         13       0.00      0.00      0.00         7\n",
      "         14       0.00      0.00      0.00        16\n",
      "         15       0.16      0.60      0.26        10\n",
      "         16       0.00      0.00      0.00        13\n",
      "         17       0.00      0.00      0.00         9\n",
      "         18       0.00      0.00      0.00         8\n",
      "         19       0.00      0.00      0.00         7\n",
      "         20       0.93      0.48      0.64        29\n",
      "\n",
      "avg / total       0.22      0.22      0.20      1410\n",
      "\n",
      "Precision:\t0.218\n",
      "Recall:  \t0.221\n",
      "F1 Score:\t0.203\n",
      "Accuracy:\t0.221\n"
     ]
    }
   ],
   "source": [
    "#def dnn (feats,labels):\n",
    "#estimate glass-box error count\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_dim=feat_len))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(21, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_feats,train_err, epochs=50,batch_size=32)\n",
    "model.save('./my_model.h5', overwrite=True)\n",
    "\n",
    "report (test1_feats,test1_err,'test1.glass','err')\n",
    "report (test2_feats,test2_err,'test2.glass','err')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "def MAE (txt,glass,black,ref): \n",
    "    MAE_glass=mean_absolute_error(glass, ref)\n",
    "    MAE_black=mean_absolute_error(black, ref)\n",
    "\n",
    "    RMS_glass = sqrt(mean_squared_error(ref, glass))\n",
    "    RMS_black = sqrt(mean_squared_error(ref, black))\n",
    "    \n",
    "    print  ('MAE:', txt,  \"%.2f\" % MAE_glass,  \"%.2f\" % MAE_black)\n",
    "    print  ('RMSE:', txt,  \"%.2f\" % RMS_glass,  \"%.2f\" % RMS_black, '\\n')\n",
    "    \n",
    "\n",
    "def parse_results(onetwo):\n",
    "    one_two = str (onetwo)\n",
    "    print (\"Analysis for: \", one_two)\n",
    "    #wc per sentence\n",
    "    glass_file_wc = 'class.out.test'+one_two+'.glass.wc'\n",
    "    black_file_wc = 'class.out.test'+one_two+'.black.wc'\n",
    "    ref_file_wc   =  'test'+one_two+'.wc'\n",
    "\n",
    "    glass_np_wc = np.loadtxt(glass_file_wc,usecols=range(0,1),dtype='float32')+1\n",
    "    black_np_wc = np.loadtxt(black_file_wc,usecols=range(0,1),dtype='float32')+1\n",
    "    ref_np_wc   = np.loadtxt(ref_file_wc,usecols=range(0,1),dtype='float32')\n",
    "\n",
    "    MAE ('glass/black: WC :',glass_np_wc,black_np_wc,ref_np_wc)\n",
    "    \n",
    "\n",
    "    #err per sentence\n",
    "    glass_file_err = 'class.out.test'+one_two+'.glass.err'\n",
    "    black_file_err = 'class.out.test'+one_two+'.black.err'\n",
    "    ref_file_err   = 'test'+one_two+'.err'\n",
    "\n",
    "    glass_np_err = np.loadtxt(glass_file_err,usecols=range(0,1),dtype='float32')\n",
    "    black_np_err = np.loadtxt(black_file_err,usecols=range(0,1),dtype='float32')\n",
    "    ref_np_err   = np.loadtxt(ref_file_err,usecols=range(0,1),dtype='float32')\n",
    "\n",
    "\n",
    "    \n",
    "    MAE ('glass/black: ERR :',glass_np_err,black_np_err,ref_np_err)\n",
    "    \n",
    "\n",
    "    #wer per sentence\n",
    "    glass_np_wer=np.divide(glass_np_err,glass_np_wc)*100\n",
    "    black_np_wer=np.divide(black_np_err,black_np_wc)*100\n",
    "    ref_np_wer=np.divide(ref_np_err,ref_np_wc)*100\n",
    "\n",
    "    MAE ('glass/black: WER :',glass_np_wer,black_np_err,ref_np_wer)\n",
    "    \n",
    "    \n",
    "    #Overall WER\n",
    "    wer_ref   = np.sum(ref_np_err)/np.sum(ref_np_wc)*100\n",
    "    wer_glass = np.sum(glass_np_err)/np.sum(glass_np_wc)*100\n",
    "    wer_black = np.sum(black_np_err)/np.sum(black_np_wc)*100\n",
    "    print ('Overall WER: glass/black:', \"%.2f\" % wer_ref, \"%.2f\" % wer_glass, \"%.2f\" % wer_black)\n",
    "    print ('###########')\n",
    "\n",
    "    #dump WER for more analysis\n",
    "    np.savetxt('wer_ref.'+one_two, ref_np_wer,fmt='%.2f') \n",
    "    np.savetxt('wer_black.'+one_two, black_np_wer,fmt='%.2f') \n",
    "    np.savetxt('wer_glass.'+one_two, glass_np_wer,fmt='%.2f') \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature dimension:  14960\n",
      "Processing:  0\n",
      "Processing:  1000\n",
      "Processing:  2000\n",
      "Processing:  3000\n",
      "Processing:  4000\n",
      "Processing:  5000\n",
      "(5842, 14960)\n",
      "Processing:  data/dev.mgb2/wer.feats\n",
      "wc:unique:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "wc:counts:  [  2   7  33 101 166 237 326 372 459 455 446 454 429 390 362 283 290 228\n",
      " 184 618]\n",
      "err:unique:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "err:counts:  [661 776 740 612 565 438 333 265 228 193 127 138 123  90  77  70  73  50\n",
      "  43  34 206]\n",
      "(5842, 20) (5842, 21)\n",
      "Processing:  0\n",
      "Processing:  1000\n",
      "Processing:  2000\n",
      "Processing:  3000\n",
      "Processing:  4000\n",
      "Processing:  5000\n",
      "(5655, 14960)\n",
      "Processing:  data/eval.mgb2/wer.feats\n",
      "wc:unique:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "wc:counts:  [  1   9  21  76 128 219 305 413 462 509 519 509 481 435 363 328 235 185\n",
      " 125 332]\n",
      "err:unique:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "err:counts:  [619 886 868 800 588 498 358 217 208 160 106  89  60  39  31  29  18  17\n",
      "  14   7  43]\n",
      "(5655, 20) (5655, 21)\n",
      "Processing:  0\n",
      "Processing:  1000\n",
      "(1410, 14960)\n",
      "Processing:  data/summa_test20170317/wer.feats\n",
      "wc:unique:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "wc:counts:  [  1   2   6   5  16  18  34  52  65  87 105 115 140 135 116  97  95  74\n",
      "  65 182]\n",
      "err:unique:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "err:counts:  [200 256 228 197 136  88  51  41  35  23  24  18  14   7  16  10  13   9\n",
      "   8   7  29]\n",
      "(1410, 20) (1410, 21)\n"
     ]
    }
   ],
   "source": [
    "##Process the black-box features:\n",
    "id, numerical, text, char, ref =load_file (train,'black')\n",
    "\n",
    "word_list, char_list = return_word_char_list (text, char)\n",
    "numerical_len=len(numerical[0].split())\n",
    "\n",
    "feat_len=(len(word_list+char_list)+numerical_len)\n",
    "print (\"Feature dimension: \", feat_len)\n",
    "\n",
    "\n",
    "\n",
    "train_feats = make_features (numerical, text, char, word_list, char_list )\n",
    "train_wc, train_err = get_wc_err (train,'train')\n",
    "\n",
    "\n",
    "\n",
    "id, numerical, text, char, ref =load_file (test1,'black')\n",
    "test1_feats = make_features (numerical, text, char, word_list, char_list )\n",
    "test1_wc, test1_err = get_wc_err (test1,'test1')\n",
    "\n",
    "\n",
    "id, numerical, text, char, ref =load_file (test2,'black')\n",
    "test2_feats = make_features (numerical, text, char, word_list, char_list )\n",
    "test2_wc, test2_err = get_wc_err (test2,'test2')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5842/5842 [==============================] - 19s - loss: 2.5270 - acc: 0.1809    \n",
      "Epoch 2/50\n",
      "5842/5842 [==============================] - 18s - loss: 2.1329 - acc: 0.2475    \n",
      "Epoch 3/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.9290 - acc: 0.2917    \n",
      "Epoch 4/50\n",
      "5842/5842 [==============================] - 16s - loss: 1.7993 - acc: 0.3245    \n",
      "Epoch 5/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.7103 - acc: 0.3490    \n",
      "Epoch 6/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.5894 - acc: 0.3935    \n",
      "Epoch 7/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.5261 - acc: 0.4302    \n",
      "Epoch 8/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.4490 - acc: 0.4697    \n",
      "Epoch 9/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.3724 - acc: 0.5045    \n",
      "Epoch 10/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.2675 - acc: 0.5383    \n",
      "Epoch 11/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.2174 - acc: 0.5592    \n",
      "Epoch 12/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.1279 - acc: 0.6012    \n",
      "Epoch 13/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.0423 - acc: 0.6342    \n",
      "Epoch 14/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.9621 - acc: 0.6664    \n",
      "Epoch 15/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.8937 - acc: 0.6931    \n",
      "Epoch 16/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.8476 - acc: 0.7135    \n",
      "Epoch 17/50\n",
      "5842/5842 [==============================] - 18s - loss: 0.7914 - acc: 0.7349    - ETA: 1s - loss: 0\n",
      "Epoch 18/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.7308 - acc: 0.7537    \n",
      "Epoch 19/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.6838 - acc: 0.7751    \n",
      "Epoch 20/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.6538 - acc: 0.7799    \n",
      "Epoch 21/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.6127 - acc: 0.7958    \n",
      "Epoch 22/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.5720 - acc: 0.8119    \n",
      "Epoch 23/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.5333 - acc: 0.8264    \n",
      "Epoch 24/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.5251 - acc: 0.8256    \n",
      "Epoch 25/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.4984 - acc: 0.8345    \n",
      "Epoch 26/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.4632 - acc: 0.8514    \n",
      "Epoch 27/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.4254 - acc: 0.8641    \n",
      "Epoch 28/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.4299 - acc: 0.8648    \n",
      "Epoch 29/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.3981 - acc: 0.8723    \n",
      "Epoch 30/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.4108 - acc: 0.8689    \n",
      "Epoch 31/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.3584 - acc: 0.8846    \n",
      "Epoch 32/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.3721 - acc: 0.8824    \n",
      "Epoch 33/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.3420 - acc: 0.8942    \n",
      "Epoch 34/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.3510 - acc: 0.8884    \n",
      "Epoch 35/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.3192 - acc: 0.9023    \n",
      "Epoch 36/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.3159 - acc: 0.9004    \n",
      "Epoch 37/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.3192 - acc: 0.9005    \n",
      "Epoch 38/50\n",
      "5842/5842 [==============================] - 16s - loss: 0.3113 - acc: 0.9014    \n",
      "Epoch 39/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.3101 - acc: 0.9067    \n",
      "Epoch 40/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.2949 - acc: 0.9059    \n",
      "Epoch 41/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.2951 - acc: 0.9113    \n",
      "Epoch 42/50\n",
      "5842/5842 [==============================] - 18s - loss: 0.2939 - acc: 0.9118    \n",
      "Epoch 43/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.2919 - acc: 0.9106    \n",
      "Epoch 44/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.2800 - acc: 0.9161    \n",
      "Epoch 45/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.2642 - acc: 0.9195    \n",
      "Epoch 46/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.2467 - acc: 0.9233    \n",
      "Epoch 47/50\n",
      "5842/5842 [==============================] - 18s - loss: 0.2480 - acc: 0.9267    \n",
      "Epoch 48/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.2559 - acc: 0.9242    \n",
      "Epoch 49/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.2533 - acc: 0.9221    \n",
      "Epoch 50/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.2411 - acc: 0.9314    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/sls/qcri/asr/amali/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/data/sls/qcri/asr/amali/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/data/sls/qcri/asr/amali/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/data/sls/qcri/asr/amali/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/data/sls/qcri/asr/amali/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/data/sls/qcri/asr/amali/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         1\n",
      "          1       0.00      0.00      0.00         9\n",
      "          2       0.00      0.00      0.00        21\n",
      "          3       0.00      0.00      0.00        76\n",
      "          4       0.07      0.01      0.01       128\n",
      "          5       0.12      0.05      0.07       219\n",
      "          6       0.13      0.06      0.08       305\n",
      "          7       0.19      0.10      0.13       413\n",
      "          8       0.15      0.14      0.15       462\n",
      "          9       0.14      0.05      0.07       509\n",
      "         10       0.09      0.08      0.09       519\n",
      "         11       0.10      0.07      0.08       509\n",
      "         12       0.06      0.05      0.05       481\n",
      "         13       0.09      0.09      0.09       435\n",
      "         14       0.11      0.10      0.10       363\n",
      "         15       0.07      0.21      0.11       328\n",
      "         16       0.08      0.14      0.10       235\n",
      "         17       0.07      0.04      0.05       185\n",
      "         18       0.08      0.27      0.12       125\n",
      "         19       0.14      0.07      0.10       332\n",
      "         20       0.00      0.00      0.00         0\n",
      "         21       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.11      0.09      0.09      5655\n",
      "\n",
      "Precision:\t0.109\n",
      "Recall:  \t0.090\n",
      "F1 Score:\t0.089\n",
      "Accuracy:\t0.090\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         1\n",
      "          1       0.00      0.00      0.00         2\n",
      "          2       0.00      0.00      0.00         6\n",
      "          3       0.00      0.00      0.00         5\n",
      "          4       0.00      0.00      0.00        16\n",
      "          5       0.08      0.06      0.06        18\n",
      "          6       0.31      0.15      0.20        34\n",
      "          7       0.11      0.04      0.06        52\n",
      "          8       0.11      0.08      0.09        65\n",
      "          9       0.05      0.01      0.02        87\n",
      "         10       0.08      0.06      0.07       105\n",
      "         11       0.04      0.02      0.02       115\n",
      "         12       0.18      0.09      0.12       140\n",
      "         13       0.12      0.09      0.10       135\n",
      "         14       0.12      0.09      0.10       116\n",
      "         15       0.07      0.22      0.11        97\n",
      "         16       0.13      0.19      0.15        95\n",
      "         17       0.04      0.01      0.02        74\n",
      "         18       0.10      0.22      0.13        65\n",
      "         19       0.20      0.09      0.13       182\n",
      "         20       0.00      0.00      0.00         0\n",
      "         21       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.12      0.09      0.09      1410\n",
      "\n",
      "Precision:\t0.116\n",
      "Recall:  \t0.091\n",
      "F1 Score:\t0.092\n",
      "Accuracy:\t0.091\n"
     ]
    }
   ],
   "source": [
    "#def dnn (feats,labels):\n",
    "#estimate glass-box word count (make sure to add one to your estimation)\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_dim=feat_len))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(20, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_feats,train_wc, epochs=50,batch_size=32)\n",
    "model.save('./my_model.h5', overwrite=True)\n",
    "\n",
    "report (test1_feats,test1_wc,'test1.black','wc')\n",
    "report (test2_feats,test2_wc,'test2.black','wc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5842/5842 [==============================] - 17s - loss: 2.5242 - acc: 0.1588    \n",
      "Epoch 2/50\n",
      "5842/5842 [==============================] - 17s - loss: 2.2504 - acc: 0.2071    \n",
      "Epoch 3/50\n",
      "5842/5842 [==============================] - 17s - loss: 2.1288 - acc: 0.2362    \n",
      "Epoch 4/50\n",
      "5842/5842 [==============================] - 17s - loss: 2.0478 - acc: 0.2566    \n",
      "Epoch 5/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.9632 - acc: 0.2775    \n",
      "Epoch 6/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.8785 - acc: 0.3172    \n",
      "Epoch 7/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.8115 - acc: 0.3429    \n",
      "Epoch 8/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.7184 - acc: 0.3797    \n",
      "Epoch 9/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.6469 - acc: 0.4178    \n",
      "Epoch 10/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.5619 - acc: 0.4418    \n",
      "Epoch 11/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.4616 - acc: 0.4750    \n",
      "Epoch 12/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.4042 - acc: 0.5067    \n",
      "Epoch 13/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.2982 - acc: 0.5488    \n",
      "Epoch 14/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.2516 - acc: 0.5709    \n",
      "Epoch 15/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.1615 - acc: 0.5996    \n",
      "Epoch 16/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.0782 - acc: 0.6323    \n",
      "Epoch 17/50\n",
      "5842/5842 [==============================] - 17s - loss: 1.0257 - acc: 0.6470    \n",
      "Epoch 18/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.9716 - acc: 0.6664    \n",
      "Epoch 19/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.9106 - acc: 0.6931    \n",
      "Epoch 20/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.8624 - acc: 0.7081    \n",
      "Epoch 21/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.8031 - acc: 0.7321    \n",
      "Epoch 22/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.7793 - acc: 0.7333    \n",
      "Epoch 23/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.7581 - acc: 0.7426    \n",
      "Epoch 24/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.7007 - acc: 0.7602    \n",
      "Epoch 25/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.6751 - acc: 0.7749    \n",
      "Epoch 26/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.6344 - acc: 0.7879    \n",
      "Epoch 27/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.6145 - acc: 0.7954    \n",
      "Epoch 28/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.5907 - acc: 0.7996    \n",
      "Epoch 29/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.5663 - acc: 0.8146    \n",
      "Epoch 30/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.5499 - acc: 0.8156    \n",
      "Epoch 31/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.5289 - acc: 0.8211    \n",
      "Epoch 32/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.4974 - acc: 0.8326    \n",
      "Epoch 33/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.4834 - acc: 0.8418    \n",
      "Epoch 34/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.4714 - acc: 0.8435    \n",
      "Epoch 35/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.4509 - acc: 0.8516    \n",
      "Epoch 36/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.4582 - acc: 0.8495    \n",
      "Epoch 37/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.4384 - acc: 0.8543    \n",
      "Epoch 38/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.4265 - acc: 0.8593    \n",
      "Epoch 39/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.4131 - acc: 0.8629    \n",
      "Epoch 40/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.4133 - acc: 0.8656    \n",
      "Epoch 41/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.3956 - acc: 0.8754    \n",
      "Epoch 42/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.3937 - acc: 0.8680    \n",
      "Epoch 43/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.3710 - acc: 0.8809    \n",
      "Epoch 44/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.3730 - acc: 0.8793    \n",
      "Epoch 45/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.3583 - acc: 0.8805    \n",
      "Epoch 46/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.3632 - acc: 0.8846    \n",
      "Epoch 47/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.3443 - acc: 0.8898    \n",
      "Epoch 48/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.3380 - acc: 0.8898    \n",
      "Epoch 49/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.3287 - acc: 0.8942    \n",
      "Epoch 50/50\n",
      "5842/5842 [==============================] - 17s - loss: 0.3413 - acc: 0.8860    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/sls/qcri/asr/amali/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/data/sls/qcri/asr/amali/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/data/sls/qcri/asr/amali/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.39      0.10      0.15       619\n",
      "          1       0.29      0.13      0.18       886\n",
      "          2       0.21      0.45      0.29       868\n",
      "          3       0.18      0.06      0.09       800\n",
      "          4       0.13      0.07      0.09       588\n",
      "          5       0.11      0.03      0.05       498\n",
      "          6       0.09      0.24      0.13       358\n",
      "          7       0.08      0.09      0.09       217\n",
      "          8       0.06      0.16      0.09       208\n",
      "          9       0.18      0.11      0.14       160\n",
      "         10       0.10      0.24      0.14       106\n",
      "         11       0.10      0.11      0.10        89\n",
      "         12       0.08      0.02      0.03        60\n",
      "         13       0.10      0.21      0.13        39\n",
      "         14       0.12      0.42      0.18        31\n",
      "         15       0.00      0.00      0.00        29\n",
      "         16       0.00      0.00      0.00        18\n",
      "         17       0.50      0.12      0.19        17\n",
      "         18       0.25      0.07      0.11        14\n",
      "         19       0.00      0.00      0.00         7\n",
      "         20       0.81      0.81      0.81        43\n",
      "\n",
      "avg / total       0.20      0.16      0.15      5655\n",
      "\n",
      "Precision:\t0.198\n",
      "Recall:  \t0.164\n",
      "F1 Score:\t0.148\n",
      "Accuracy:\t0.164\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.21      0.04      0.07       200\n",
      "          1       0.20      0.09      0.12       256\n",
      "          2       0.18      0.35      0.24       228\n",
      "          3       0.22      0.08      0.11       197\n",
      "          4       0.15      0.07      0.09       136\n",
      "          5       0.03      0.01      0.02        88\n",
      "          6       0.06      0.25      0.09        51\n",
      "          7       0.07      0.07      0.07        41\n",
      "          8       0.07      0.23      0.11        35\n",
      "          9       0.00      0.00      0.00        23\n",
      "         10       0.16      0.50      0.24        24\n",
      "         11       0.09      0.17      0.12        18\n",
      "         12       0.00      0.00      0.00        14\n",
      "         13       0.05      0.29      0.09         7\n",
      "         14       0.09      0.25      0.13        16\n",
      "         15       0.20      0.20      0.20        10\n",
      "         16       0.67      0.15      0.25        13\n",
      "         17       0.00      0.00      0.00         9\n",
      "         18       0.00      0.00      0.00         8\n",
      "         19       0.00      0.00      0.00         7\n",
      "         20       0.84      0.72      0.78        29\n",
      "\n",
      "avg / total       0.18      0.15      0.13      1410\n",
      "\n",
      "Precision:\t0.178\n",
      "Recall:  \t0.147\n",
      "F1 Score:\t0.132\n",
      "Accuracy:\t0.147\n"
     ]
    }
   ],
   "source": [
    "#def dnn (feats,labels):\n",
    "#estimate black-box error count\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_dim=feat_len))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(21, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_feats,train_err, epochs=50,batch_size=32)\n",
    "model.save('./my_model.h5', overwrite=True)\n",
    "\n",
    "report (test1_feats,test1_err,'test1.black','err')\n",
    "report (test2_feats,test2_err,'test2.black','err')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis for:  1\n",
      "MAE: glass/black: WC : 1.89 2.56\n",
      "RMSE: glass/black: WC : 2.29 3.09 \n",
      "\n",
      "MAE: glass/black: ERR : 1.62 2.30\n",
      "RMSE: glass/black: ERR : 2.24 3.06 \n",
      "\n",
      "MAE: glass/black: WER : 13.94 27.75\n",
      "RMSE: glass/black: WER : 18.63 35.49 \n",
      "\n",
      "Overall WER: glass/black: 33.03 26.47 33.76\n",
      "###########\n",
      "\n",
      "\n",
      "Analysis for:  2\n",
      "MAE: glass/black: WC : 1.75 2.56\n",
      "RMSE: glass/black: WC : 2.20 3.11 \n",
      "\n",
      "MAE: glass/black: ERR : 1.74 2.60\n",
      "RMSE: glass/black: ERR : 2.43 3.47 \n",
      "\n",
      "MAE: glass/black: WER : 12.76 23.90\n",
      "RMSE: glass/black: WER : 17.70 34.40 \n",
      "\n",
      "Overall WER: glass/black: 28.51 22.98 32.53\n",
      "###########\n"
     ]
    }
   ],
   "source": [
    "#summary\n",
    "parse_results (1)\n",
    "print ('\\n')\n",
    "parse_results (2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
